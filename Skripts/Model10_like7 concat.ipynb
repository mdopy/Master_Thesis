{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "import yaml\n",
    "\n",
    "\n",
    "import importlib\n",
    "\n",
    "import Model10_OOP\n",
    "importlib.reload(Model10_OOP)\n",
    "from Model10_OOP import ConvModel\n",
    "\n",
    "\n",
    "import BaseData20Fold\n",
    "importlib.reload(BaseData20Fold)\n",
    "from BaseData20Fold import DataProcessor\n",
    "\n",
    "import Plots\n",
    "importlib.reload(Plots)\n",
    "from Plots import plot_CM\n",
    "\n",
    "# COntains 2stream Neural Network to process fine fatures and coarse features separate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "The version_information extension is already loaded. To reload it, use:\n",
      "  %reload_ext version_information\n"
     ]
    }
   ],
   "source": [
    "cwd = Path.cwd()\n",
    "\n",
    "%load_ext tensorboard\n",
    "%load_ext version_information\n",
    "#!rm -rf ./logs/\n",
    "\n",
    "logsdir = cwd / '..' / 'logs'\n",
    "# !rmdir /s /q {logsdir}\n",
    "#!tensorboard --logdir {logsdir} --host localhost --port 6006\n",
    "\n",
    "cfg = 'config_mdl10_concat.yaml'\n",
    "with open(cfg, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "seeds = config['seeds']\n",
    "\n",
    "folds = np.arange(1,21)\n",
    "\n",
    "datapath = cwd / '..' / 'Data' / 'DHG2016' / 'concat_sequences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permuting Samples using seed 26\n",
      "Make Windows and apply framreferences...\n",
      "Processing subject 2\n",
      "Processing subject 3\n",
      "Processing subject 4\n",
      "Processing subject 5\n",
      "Processing subject 6\n",
      "Processing subject 7\n",
      "Processing subject 8\n",
      "Processing subject 9\n",
      "Processing subject 10\n",
      "Processing subject 11\n",
      "Processing subject 13\n",
      "Processing subject 14\n",
      "Processing subject 15\n",
      "Processing subject 16\n",
      "Processing subject 17\n",
      "Processing subject 18\n",
      "Processing subject 19\n",
      "Processing subject 20\n",
      "Using seed 26\n",
      "Fold: 5\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resultsDFlong = pd.DataFrame()\n",
    "folder = 'concat_sequences'\n",
    "data_processor = DataProcessor(cfg)\n",
    "data_processor.load_handgestdata()\n",
    "data_processor.handangles2windows()\n",
    "data_processor.save_config(folder)\n",
    "data_processor.save_windowsets(folder)\n",
    "\n",
    "#folds = [5]\n",
    "    \n",
    "for fold in folds:\n",
    "    data_processor = DataProcessor(cfg, fold = fold)\n",
    "    # data_processor.load_handgestdata()\n",
    "    # data_processor.handangles2windows()\n",
    "    # data_processor.save_windowsets(folder)\n",
    "    data_processor.load_windows(folder)\n",
    "    data_processor.processwindows()\n",
    "    data_processor.save_windowsets_processed(folder, name='Fold'+str(fold))\n",
    "\n",
    "# 223 min\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating Fold 1\n",
      "Setting seed to 5\n",
      "Epoch 1/20\n",
      "1226/1226 - 60s - 49ms/step - NLL: 1.4320 - accuracy: 0.6004 - f1_score: 0.1233 - loss: 1.6652 - precision: 0.7551 - recall: 0.4483 - val_NLL: 1.4207 - val_accuracy: 0.5879 - val_f1_score: 0.1545 - val_loss: 1.5986 - val_precision: 0.7545 - val_recall: 0.4926\n",
      "Epoch 2/20\n",
      "1226/1226 - 56s - 45ms/step - NLL: 1.2049 - accuracy: 0.6337 - f1_score: 0.2249 - loss: 1.3852 - precision: 0.7839 - recall: 0.4969 - val_NLL: 1.2598 - val_accuracy: 0.6121 - val_f1_score: 0.2457 - val_loss: 1.4450 - val_precision: 0.7646 - val_recall: 0.5205\n",
      "Epoch 3/20\n",
      "1226/1226 - 54s - 44ms/step - NLL: 1.0959 - accuracy: 0.6598 - f1_score: 0.3021 - loss: 1.2855 - precision: 0.7968 - recall: 0.5329 - val_NLL: 1.2411 - val_accuracy: 0.6226 - val_f1_score: 0.2730 - val_loss: 1.4317 - val_precision: 0.7724 - val_recall: 0.5273\n",
      "Epoch 4/20\n",
      "1226/1226 - 54s - 44ms/step - NLL: 1.0379 - accuracy: 0.6746 - f1_score: 0.3424 - loss: 1.2306 - precision: 0.8040 - recall: 0.5543 - val_NLL: 1.1970 - val_accuracy: 0.6258 - val_f1_score: 0.2865 - val_loss: 1.3917 - val_precision: 0.7441 - val_recall: 0.5482\n",
      "Epoch 5/20\n",
      "1226/1226 - 56s - 46ms/step - NLL: 0.9977 - accuracy: 0.6846 - f1_score: 0.3715 - loss: 1.1935 - precision: 0.8080 - recall: 0.5668 - val_NLL: 1.1692 - val_accuracy: 0.6328 - val_f1_score: 0.3053 - val_loss: 1.3664 - val_precision: 0.7543 - val_recall: 0.5611\n",
      "Epoch 6/20\n",
      "1226/1226 - 52s - 43ms/step - NLL: 0.9683 - accuracy: 0.6927 - f1_score: 0.3913 - loss: 1.1676 - precision: 0.8115 - recall: 0.5795 - val_NLL: 1.1935 - val_accuracy: 0.6339 - val_f1_score: 0.3156 - val_loss: 1.3942 - val_precision: 0.7703 - val_recall: 0.5503\n",
      "Epoch 7/20\n",
      "1226/1226 - 51s - 42ms/step - NLL: 0.9455 - accuracy: 0.6980 - f1_score: 0.4074 - loss: 1.1480 - precision: 0.8135 - recall: 0.5899 - val_NLL: 1.1514 - val_accuracy: 0.6459 - val_f1_score: 0.3439 - val_loss: 1.3548 - val_precision: 0.7694 - val_recall: 0.5669\n",
      "Epoch 8/20\n",
      "1226/1226 - 50s - 41ms/step - NLL: 0.9300 - accuracy: 0.7028 - f1_score: 0.4237 - loss: 1.1343 - precision: 0.8172 - recall: 0.5972 - val_NLL: 1.1855 - val_accuracy: 0.6427 - val_f1_score: 0.3421 - val_loss: 1.3926 - val_precision: 0.7551 - val_recall: 0.5707\n",
      "Epoch 9/20\n",
      "1226/1226 - 53s - 43ms/step - NLL: 0.9150 - accuracy: 0.7078 - f1_score: 0.4372 - loss: 1.1208 - precision: 0.8181 - recall: 0.6024 - val_NLL: 1.2039 - val_accuracy: 0.6430 - val_f1_score: 0.3443 - val_loss: 1.4126 - val_precision: 0.7471 - val_recall: 0.5683\n",
      "Epoch 10/20\n",
      "1226/1226 - 54s - 44ms/step - NLL: 0.9023 - accuracy: 0.7121 - f1_score: 0.4454 - loss: 1.1097 - precision: 0.8211 - recall: 0.6100 - val_NLL: 1.1676 - val_accuracy: 0.6427 - val_f1_score: 0.3461 - val_loss: 1.3770 - val_precision: 0.7389 - val_recall: 0.5806\n",
      "Epoch 11/20\n",
      "1226/1226 - 51s - 41ms/step - NLL: 0.8898 - accuracy: 0.7147 - f1_score: 0.4532 - loss: 1.0981 - precision: 0.8219 - recall: 0.6127 - val_NLL: 1.1595 - val_accuracy: 0.6523 - val_f1_score: 0.3621 - val_loss: 1.3701 - val_precision: 0.7641 - val_recall: 0.5797\n",
      "Epoch 12/20\n",
      "1226/1226 - 51s - 41ms/step - NLL: 0.8801 - accuracy: 0.7168 - f1_score: 0.4583 - loss: 1.0888 - precision: 0.8234 - recall: 0.6193 - val_NLL: 1.1738 - val_accuracy: 0.6581 - val_f1_score: 0.3842 - val_loss: 1.3836 - val_precision: 0.7528 - val_recall: 0.5867\n",
      "Epoch 13/20\n",
      "1226/1226 - 51s - 42ms/step - NLL: 0.8713 - accuracy: 0.7192 - f1_score: 0.4660 - loss: 1.0822 - precision: 0.8249 - recall: 0.6219 - val_NLL: 1.1621 - val_accuracy: 0.6514 - val_f1_score: 0.3715 - val_loss: 1.3750 - val_precision: 0.7673 - val_recall: 0.5681\n",
      "Epoch 14/20\n",
      "1226/1226 - 51s - 41ms/step - NLL: 0.8633 - accuracy: 0.7216 - f1_score: 0.4718 - loss: 1.0753 - precision: 0.8261 - recall: 0.6259 - val_NLL: 1.1651 - val_accuracy: 0.6549 - val_f1_score: 0.3730 - val_loss: 1.3768 - val_precision: 0.7507 - val_recall: 0.5925\n",
      "Epoch 15/20\n",
      "1226/1226 - 51s - 41ms/step - NLL: 0.8563 - accuracy: 0.7248 - f1_score: 0.4812 - loss: 1.0695 - precision: 0.8279 - recall: 0.6299 - val_NLL: 1.1537 - val_accuracy: 0.6514 - val_f1_score: 0.3625 - val_loss: 1.3662 - val_precision: 0.7608 - val_recall: 0.5785\n",
      "Epoch 16/20\n",
      "1226/1226 - 51s - 42ms/step - NLL: 0.8478 - accuracy: 0.7266 - f1_score: 0.4851 - loss: 1.0615 - precision: 0.8274 - recall: 0.6313 - val_NLL: 1.1480 - val_accuracy: 0.6599 - val_f1_score: 0.3922 - val_loss: 1.3629 - val_precision: 0.7670 - val_recall: 0.5890\n",
      "Epoch 17/20\n",
      "1226/1226 - 51s - 42ms/step - NLL: 0.8393 - accuracy: 0.7288 - f1_score: 0.4893 - loss: 1.0535 - precision: 0.8283 - recall: 0.6351 - val_NLL: 1.2367 - val_accuracy: 0.6537 - val_f1_score: 0.3635 - val_loss: 1.4519 - val_precision: 0.7647 - val_recall: 0.5835\n",
      "Epoch 18/20\n",
      "1226/1226 - 51s - 41ms/step - NLL: 0.8362 - accuracy: 0.7293 - f1_score: 0.4924 - loss: 1.0500 - precision: 0.8280 - recall: 0.6364 - val_NLL: 1.1898 - val_accuracy: 0.6517 - val_f1_score: 0.3633 - val_loss: 1.4064 - val_precision: 0.7533 - val_recall: 0.5899\n",
      "Epoch 19/20\n",
      "1226/1226 - 51s - 41ms/step - NLL: 0.8294 - accuracy: 0.7309 - f1_score: 0.4950 - loss: 1.0435 - precision: 0.8319 - recall: 0.6392 - val_NLL: 1.1702 - val_accuracy: 0.6590 - val_f1_score: 0.3840 - val_loss: 1.3879 - val_precision: 0.7554 - val_recall: 0.5987\n",
      "Epoch 20/20\n",
      "1226/1226 - 51s - 42ms/step - NLL: 0.8271 - accuracy: 0.7316 - f1_score: 0.4959 - loss: 1.0420 - precision: 0.8289 - recall: 0.6418 - val_NLL: 1.1505 - val_accuracy: 0.6607 - val_f1_score: 0.3827 - val_loss: 1.3677 - val_precision: 0.7612 - val_recall: 0.5984\n",
      "\u001b[1m2451/2451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "NLL: 1.15\n",
      "Validation accuracy: 0.66\n",
      "Validation F1Score: 0.39\n",
      "evaluating Fold 2\n",
      "Setting seed to 26\n",
      "Epoch 1/20\n",
      "1211/1211 - 55s - 46ms/step - NLL: 1.3908 - accuracy: 0.6018 - f1_score: 0.1535 - loss: 1.6318 - precision: 0.7584 - recall: 0.4509 - val_NLL: 1.1656 - val_accuracy: 0.6628 - val_f1_score: 0.1438 - val_loss: 1.3542 - val_precision: 0.8223 - val_recall: 0.5324\n",
      "Epoch 2/20\n",
      "1211/1211 - 50s - 41ms/step - NLL: 1.1705 - accuracy: 0.6416 - f1_score: 0.2701 - loss: 1.3640 - precision: 0.7905 - recall: 0.5068 - val_NLL: 1.0683 - val_accuracy: 0.6730 - val_f1_score: 0.2167 - val_loss: 1.2650 - val_precision: 0.8213 - val_recall: 0.5528\n",
      "Epoch 3/20\n",
      "1211/1211 - 50s - 41ms/step - NLL: 1.0662 - accuracy: 0.6676 - f1_score: 0.3363 - loss: 1.2631 - precision: 0.7994 - recall: 0.5432 - val_NLL: 1.0592 - val_accuracy: 0.6780 - val_f1_score: 0.2596 - val_loss: 1.2567 - val_precision: 0.8071 - val_recall: 0.5598\n",
      "Epoch 4/20\n",
      "1211/1211 - 50s - 41ms/step - NLL: 1.0144 - accuracy: 0.6808 - f1_score: 0.3735 - loss: 1.2131 - precision: 0.8054 - recall: 0.5633 - val_NLL: 1.0433 - val_accuracy: 0.6762 - val_f1_score: 0.2644 - val_loss: 1.2415 - val_precision: 0.8035 - val_recall: 0.5666\n",
      "Epoch 5/20\n",
      "1211/1211 - 50s - 41ms/step - NLL: 0.9821 - accuracy: 0.6889 - f1_score: 0.3935 - loss: 1.1827 - precision: 0.8077 - recall: 0.5739 - val_NLL: 1.0221 - val_accuracy: 0.6873 - val_f1_score: 0.3170 - val_loss: 1.2236 - val_precision: 0.8099 - val_recall: 0.5790\n",
      "Epoch 6/20\n",
      "1211/1211 - 55s - 46ms/step - NLL: 0.9524 - accuracy: 0.6980 - f1_score: 0.4189 - loss: 1.1552 - precision: 0.8125 - recall: 0.5872 - val_NLL: 1.0191 - val_accuracy: 0.6920 - val_f1_score: 0.3070 - val_loss: 1.2222 - val_precision: 0.8094 - val_recall: 0.5876\n",
      "Epoch 7/20\n",
      "1211/1211 - 55s - 46ms/step - NLL: 0.9323 - accuracy: 0.7040 - f1_score: 0.4321 - loss: 1.1386 - precision: 0.8166 - recall: 0.5952 - val_NLL: 1.0008 - val_accuracy: 0.6957 - val_f1_score: 0.3365 - val_loss: 1.2075 - val_precision: 0.8178 - val_recall: 0.5906\n",
      "Epoch 8/20\n",
      "1211/1211 - 50s - 41ms/step - NLL: 0.9152 - accuracy: 0.7089 - f1_score: 0.4469 - loss: 1.1235 - precision: 0.8172 - recall: 0.6031 - val_NLL: 0.9997 - val_accuracy: 0.6990 - val_f1_score: 0.3357 - val_loss: 1.2078 - val_precision: 0.8175 - val_recall: 0.5956\n",
      "Epoch 9/20\n",
      "1211/1211 - 50s - 42ms/step - NLL: 0.8976 - accuracy: 0.7128 - f1_score: 0.4581 - loss: 1.1070 - precision: 0.8202 - recall: 0.6092 - val_NLL: 0.9951 - val_accuracy: 0.6936 - val_f1_score: 0.3351 - val_loss: 1.2045 - val_precision: 0.8025 - val_recall: 0.6139\n",
      "Epoch 10/20\n",
      "1211/1211 - 51s - 42ms/step - NLL: 0.8851 - accuracy: 0.7159 - f1_score: 0.4642 - loss: 1.0959 - precision: 0.8226 - recall: 0.6156 - val_NLL: 0.9978 - val_accuracy: 0.6916 - val_f1_score: 0.3274 - val_loss: 1.2084 - val_precision: 0.8009 - val_recall: 0.6139\n",
      "Epoch 11/20\n",
      "1211/1211 - 51s - 42ms/step - NLL: 0.8753 - accuracy: 0.7195 - f1_score: 0.4751 - loss: 1.0880 - precision: 0.8234 - recall: 0.6206 - val_NLL: 0.9948 - val_accuracy: 0.6929 - val_f1_score: 0.3417 - val_loss: 1.2075 - val_precision: 0.8109 - val_recall: 0.6175\n",
      "Epoch 12/20\n",
      "1211/1211 - 51s - 42ms/step - NLL: 0.8613 - accuracy: 0.7222 - f1_score: 0.4831 - loss: 1.0762 - precision: 0.8253 - recall: 0.6253 - val_NLL: 0.9963 - val_accuracy: 0.6907 - val_f1_score: 0.3257 - val_loss: 1.2117 - val_precision: 0.7944 - val_recall: 0.6135\n",
      "Epoch 13/20\n",
      "1211/1211 - 50s - 42ms/step - NLL: 0.8560 - accuracy: 0.7229 - f1_score: 0.4845 - loss: 1.0712 - precision: 0.8263 - recall: 0.6278 - val_NLL: 1.0012 - val_accuracy: 0.6884 - val_f1_score: 0.3262 - val_loss: 1.2166 - val_precision: 0.7958 - val_recall: 0.6193\n",
      "Epoch 14/20\n",
      "1211/1211 - 51s - 42ms/step - NLL: 0.8450 - accuracy: 0.7285 - f1_score: 0.4961 - loss: 1.0604 - precision: 0.8296 - recall: 0.6347 - val_NLL: 0.9998 - val_accuracy: 0.6986 - val_f1_score: 0.3490 - val_loss: 1.2155 - val_precision: 0.7997 - val_recall: 0.6257\n",
      "Epoch 15/20\n",
      "1211/1211 - 50s - 42ms/step - NLL: 0.8415 - accuracy: 0.7283 - f1_score: 0.4954 - loss: 1.0575 - precision: 0.8284 - recall: 0.6344 - val_NLL: 1.0207 - val_accuracy: 0.6927 - val_f1_score: 0.3212 - val_loss: 1.2376 - val_precision: 0.7897 - val_recall: 0.6268\n",
      "Epoch 16/20\n",
      "1211/1211 - 51s - 42ms/step - NLL: 0.8317 - accuracy: 0.7319 - f1_score: 0.5047 - loss: 1.0483 - precision: 0.8300 - recall: 0.6393 - val_NLL: 0.9915 - val_accuracy: 0.6954 - val_f1_score: 0.3578 - val_loss: 1.2087 - val_precision: 0.8118 - val_recall: 0.6223\n",
      "Epoch 17/20\n",
      "1211/1211 - 51s - 42ms/step - NLL: 0.8315 - accuracy: 0.7322 - f1_score: 0.5034 - loss: 1.0480 - precision: 0.8302 - recall: 0.6397 - val_NLL: 0.9945 - val_accuracy: 0.7009 - val_f1_score: 0.3467 - val_loss: 1.2099 - val_precision: 0.7844 - val_recall: 0.6452\n",
      "Epoch 18/20\n",
      "1211/1211 - 52s - 43ms/step - NLL: 0.8202 - accuracy: 0.7345 - f1_score: 0.5102 - loss: 1.0367 - precision: 0.8331 - recall: 0.6442 - val_NLL: 1.0102 - val_accuracy: 0.7018 - val_f1_score: 0.3437 - val_loss: 1.2263 - val_precision: 0.7890 - val_recall: 0.6384\n",
      "Epoch 19/20\n",
      "1211/1211 - 51s - 42ms/step - NLL: 0.8176 - accuracy: 0.7368 - f1_score: 0.5161 - loss: 1.0349 - precision: 0.8331 - recall: 0.6458 - val_NLL: 1.0168 - val_accuracy: 0.6966 - val_f1_score: 0.3442 - val_loss: 1.2343 - val_precision: 0.7884 - val_recall: 0.6320\n",
      "Epoch 20/20\n",
      "1211/1211 - 51s - 42ms/step - NLL: 0.8098 - accuracy: 0.7377 - f1_score: 0.5184 - loss: 1.0278 - precision: 0.8334 - recall: 0.6475 - val_NLL: 1.0112 - val_accuracy: 0.6891 - val_f1_score: 0.3313 - val_loss: 1.2293 - val_precision: 0.7930 - val_recall: 0.6334\n",
      "\u001b[1m2421/2421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "NLL: 0.99\n",
      "Validation accuracy: 0.70\n",
      "Validation F1Score: 0.36\n",
      "evaluating Fold 3\n",
      "Setting seed to 90\n",
      "Epoch 1/20\n",
      "1219/1219 - 59s - 48ms/step - NLL: 1.4275 - accuracy: 0.5995 - f1_score: 0.1215 - loss: 1.6630 - precision: 0.7557 - recall: 0.4482 - val_NLL: 1.3536 - val_accuracy: 0.5898 - val_f1_score: 0.2072 - val_loss: 1.5373 - val_precision: 0.8205 - val_recall: 0.4040\n",
      "Epoch 2/20\n",
      "1219/1219 - 52s - 43ms/step - NLL: 1.1772 - accuracy: 0.6414 - f1_score: 0.2595 - loss: 1.3691 - precision: 0.7894 - recall: 0.5049 - val_NLL: 1.2190 - val_accuracy: 0.6398 - val_f1_score: 0.3146 - val_loss: 1.4141 - val_precision: 0.8068 - val_recall: 0.4760\n",
      "Epoch 3/20\n",
      "1219/1219 - 52s - 43ms/step - NLL: 1.0742 - accuracy: 0.6664 - f1_score: 0.3222 - loss: 1.2697 - precision: 0.8015 - recall: 0.5392 - val_NLL: 1.1718 - val_accuracy: 0.6528 - val_f1_score: 0.3414 - val_loss: 1.3682 - val_precision: 0.8010 - val_recall: 0.5145\n",
      "Epoch 4/20\n",
      "1219/1219 - 52s - 43ms/step - NLL: 1.0214 - accuracy: 0.6797 - f1_score: 0.3566 - loss: 1.2174 - precision: 0.8069 - recall: 0.5589 - val_NLL: 1.1459 - val_accuracy: 0.6618 - val_f1_score: 0.3520 - val_loss: 1.3431 - val_precision: 0.8041 - val_recall: 0.5406\n",
      "Epoch 5/20\n",
      "1219/1219 - 53s - 43ms/step - NLL: 0.9884 - accuracy: 0.6874 - f1_score: 0.3775 - loss: 1.1856 - precision: 0.8112 - recall: 0.5710 - val_NLL: 1.1049 - val_accuracy: 0.6777 - val_f1_score: 0.4033 - val_loss: 1.3025 - val_precision: 0.8128 - val_recall: 0.5529\n",
      "Epoch 6/20\n",
      "1219/1219 - 53s - 43ms/step - NLL: 0.9623 - accuracy: 0.6939 - f1_score: 0.3995 - loss: 1.1612 - precision: 0.8136 - recall: 0.5822 - val_NLL: 1.1036 - val_accuracy: 0.6877 - val_f1_score: 0.4301 - val_loss: 1.3053 - val_precision: 0.8201 - val_recall: 0.5642\n",
      "Epoch 7/20\n",
      "1219/1219 - 53s - 44ms/step - NLL: 0.9417 - accuracy: 0.7014 - f1_score: 0.4162 - loss: 1.1421 - precision: 0.8167 - recall: 0.5900 - val_NLL: 1.1054 - val_accuracy: 0.6869 - val_f1_score: 0.4412 - val_loss: 1.3074 - val_precision: 0.7991 - val_recall: 0.5749\n",
      "Epoch 8/20\n",
      "1219/1219 - 54s - 44ms/step - NLL: 0.9235 - accuracy: 0.7045 - f1_score: 0.4278 - loss: 1.1264 - precision: 0.8165 - recall: 0.5962 - val_NLL: 1.0974 - val_accuracy: 0.6861 - val_f1_score: 0.4294 - val_loss: 1.3011 - val_precision: 0.8041 - val_recall: 0.5806\n",
      "Epoch 9/20\n",
      "1219/1219 - 53s - 43ms/step - NLL: 0.9084 - accuracy: 0.7094 - f1_score: 0.4391 - loss: 1.1138 - precision: 0.8211 - recall: 0.6031 - val_NLL: 1.0743 - val_accuracy: 0.6874 - val_f1_score: 0.4238 - val_loss: 1.2800 - val_precision: 0.7957 - val_recall: 0.5967\n",
      "Epoch 10/20\n",
      "1219/1219 - 54s - 44ms/step - NLL: 0.8945 - accuracy: 0.7129 - f1_score: 0.4500 - loss: 1.1008 - precision: 0.8222 - recall: 0.6093 - val_NLL: 1.0679 - val_accuracy: 0.7028 - val_f1_score: 0.4871 - val_loss: 1.2761 - val_precision: 0.8137 - val_recall: 0.5977\n",
      "Epoch 11/20\n",
      "1219/1219 - 53s - 43ms/step - NLL: 0.8830 - accuracy: 0.7153 - f1_score: 0.4554 - loss: 1.0918 - precision: 0.8242 - recall: 0.6140 - val_NLL: 1.0547 - val_accuracy: 0.6977 - val_f1_score: 0.4614 - val_loss: 1.2642 - val_precision: 0.8180 - val_recall: 0.6044\n",
      "Epoch 12/20\n",
      "1219/1219 - 53s - 43ms/step - NLL: 0.8704 - accuracy: 0.7215 - f1_score: 0.4723 - loss: 1.0796 - precision: 0.8261 - recall: 0.6213 - val_NLL: 1.0325 - val_accuracy: 0.7107 - val_f1_score: 0.4878 - val_loss: 1.2420 - val_precision: 0.8112 - val_recall: 0.6131\n",
      "Epoch 13/20\n",
      "1219/1219 - 54s - 44ms/step - NLL: 0.8653 - accuracy: 0.7226 - f1_score: 0.4742 - loss: 1.0762 - precision: 0.8257 - recall: 0.6233 - val_NLL: 1.0424 - val_accuracy: 0.7079 - val_f1_score: 0.4908 - val_loss: 1.2554 - val_precision: 0.8112 - val_recall: 0.6067\n",
      "Epoch 14/20\n",
      "1219/1219 - 53s - 44ms/step - NLL: 0.8508 - accuracy: 0.7265 - f1_score: 0.4831 - loss: 1.0644 - precision: 0.8290 - recall: 0.6288 - val_NLL: 1.0270 - val_accuracy: 0.7087 - val_f1_score: 0.4887 - val_loss: 1.2411 - val_precision: 0.8173 - val_recall: 0.6062\n",
      "Epoch 15/20\n",
      "1219/1219 - 53s - 44ms/step - NLL: 0.8454 - accuracy: 0.7266 - f1_score: 0.4850 - loss: 1.0593 - precision: 0.8293 - recall: 0.6313 - val_NLL: 1.0101 - val_accuracy: 0.7025 - val_f1_score: 0.4806 - val_loss: 1.2255 - val_precision: 0.8103 - val_recall: 0.6116\n",
      "Epoch 16/20\n",
      "1219/1219 - 53s - 44ms/step - NLL: 0.8406 - accuracy: 0.7285 - f1_score: 0.4897 - loss: 1.0560 - precision: 0.8280 - recall: 0.6323 - val_NLL: 1.0025 - val_accuracy: 0.7102 - val_f1_score: 0.4801 - val_loss: 1.2194 - val_precision: 0.8148 - val_recall: 0.6280\n",
      "Epoch 17/20\n",
      "1219/1219 - 54s - 44ms/step - NLL: 0.8298 - accuracy: 0.7313 - f1_score: 0.4960 - loss: 1.0473 - precision: 0.8315 - recall: 0.6385 - val_NLL: 1.0125 - val_accuracy: 0.7038 - val_f1_score: 0.4799 - val_loss: 1.2303 - val_precision: 0.8049 - val_recall: 0.6152\n",
      "Epoch 18/20\n",
      "1219/1219 - 54s - 44ms/step - NLL: 0.8242 - accuracy: 0.7329 - f1_score: 0.5007 - loss: 1.0426 - precision: 0.8305 - recall: 0.6410 - val_NLL: 1.0154 - val_accuracy: 0.7102 - val_f1_score: 0.4960 - val_loss: 1.2334 - val_precision: 0.8031 - val_recall: 0.6188\n",
      "Epoch 19/20\n",
      "1219/1219 - 54s - 44ms/step - NLL: 0.8188 - accuracy: 0.7343 - f1_score: 0.5028 - loss: 1.0376 - precision: 0.8316 - recall: 0.6424 - val_NLL: 0.9711 - val_accuracy: 0.7092 - val_f1_score: 0.4880 - val_loss: 1.1899 - val_precision: 0.8153 - val_recall: 0.6221\n",
      "Epoch 20/20\n",
      "1219/1219 - 54s - 44ms/step - NLL: 0.8159 - accuracy: 0.7364 - f1_score: 0.5081 - loss: 1.0350 - precision: 0.8328 - recall: 0.6458 - val_NLL: 0.9647 - val_accuracy: 0.7182 - val_f1_score: 0.5048 - val_loss: 1.1843 - val_precision: 0.8217 - val_recall: 0.6223\n",
      "\u001b[1m2437/2437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "NLL: 0.96\n",
      "Validation accuracy: 0.72\n",
      "Validation F1Score: 0.50\n",
      "evaluating Fold 4\n",
      "Setting seed to 232\n",
      "Epoch 1/20\n",
      "1223/1223 - 58s - 47ms/step - NLL: 1.4424 - accuracy: 0.5969 - f1_score: 0.1266 - loss: 1.6613 - precision: 0.7543 - recall: 0.4439 - val_NLL: 1.2493 - val_accuracy: 0.6692 - val_f1_score: 0.1457 - val_loss: 1.4181 - val_precision: 0.8171 - val_recall: 0.5543\n",
      "Epoch 2/20\n",
      "1223/1223 - 52s - 43ms/step - NLL: 1.2010 - accuracy: 0.6318 - f1_score: 0.2466 - loss: 1.3804 - precision: 0.7858 - recall: 0.4927 - val_NLL: 1.1378 - val_accuracy: 0.6983 - val_f1_score: 0.2475 - val_loss: 1.3195 - val_precision: 0.8425 - val_recall: 0.5734\n",
      "Epoch 3/20\n",
      "1223/1223 - 52s - 42ms/step - NLL: 1.0909 - accuracy: 0.6610 - f1_score: 0.3213 - loss: 1.2798 - precision: 0.7968 - recall: 0.5297 - val_NLL: 1.1376 - val_accuracy: 0.7024 - val_f1_score: 0.2879 - val_loss: 1.3258 - val_precision: 0.8368 - val_recall: 0.5963\n",
      "Epoch 4/20\n",
      "1223/1223 - 52s - 43ms/step - NLL: 1.0324 - accuracy: 0.6757 - f1_score: 0.3547 - loss: 1.2250 - precision: 0.8019 - recall: 0.5533 - val_NLL: 1.0518 - val_accuracy: 0.7049 - val_f1_score: 0.2946 - val_loss: 1.2407 - val_precision: 0.8413 - val_recall: 0.6062\n",
      "Epoch 5/20\n",
      "1223/1223 - 52s - 42ms/step - NLL: 0.9940 - accuracy: 0.6861 - f1_score: 0.3804 - loss: 1.1896 - precision: 0.8095 - recall: 0.5682 - val_NLL: 1.1148 - val_accuracy: 0.7052 - val_f1_score: 0.2929 - val_loss: 1.3095 - val_precision: 0.8368 - val_recall: 0.6051\n",
      "Epoch 6/20\n",
      "1223/1223 - 52s - 43ms/step - NLL: 0.9664 - accuracy: 0.6940 - f1_score: 0.4051 - loss: 1.1645 - precision: 0.8133 - recall: 0.5806 - val_NLL: 1.0786 - val_accuracy: 0.7096 - val_f1_score: 0.3061 - val_loss: 1.2734 - val_precision: 0.8270 - val_recall: 0.6237\n",
      "Epoch 7/20\n",
      "1223/1223 - 53s - 43ms/step - NLL: 0.9456 - accuracy: 0.6987 - f1_score: 0.4187 - loss: 1.1462 - precision: 0.8134 - recall: 0.5893 - val_NLL: 1.0747 - val_accuracy: 0.7074 - val_f1_score: 0.3064 - val_loss: 1.2719 - val_precision: 0.8325 - val_recall: 0.6123\n",
      "Epoch 8/20\n",
      "1223/1223 - 52s - 43ms/step - NLL: 0.9229 - accuracy: 0.7063 - f1_score: 0.4390 - loss: 1.1259 - precision: 0.8169 - recall: 0.5972 - val_NLL: 1.0882 - val_accuracy: 0.7057 - val_f1_score: 0.3119 - val_loss: 1.2875 - val_precision: 0.8311 - val_recall: 0.6228\n",
      "Epoch 9/20\n",
      "1223/1223 - 52s - 42ms/step - NLL: 0.9072 - accuracy: 0.7092 - f1_score: 0.4471 - loss: 1.1117 - precision: 0.8194 - recall: 0.6045 - val_NLL: 1.0407 - val_accuracy: 0.7135 - val_f1_score: 0.3391 - val_loss: 1.2422 - val_precision: 0.8245 - val_recall: 0.6231\n",
      "Epoch 10/20\n",
      "1223/1223 - 52s - 43ms/step - NLL: 0.8948 - accuracy: 0.7117 - f1_score: 0.4544 - loss: 1.1012 - precision: 0.8212 - recall: 0.6105 - val_NLL: 1.0639 - val_accuracy: 0.7096 - val_f1_score: 0.3348 - val_loss: 1.2676 - val_precision: 0.8255 - val_recall: 0.6234\n",
      "Epoch 11/20\n",
      "1223/1223 - 52s - 43ms/step - NLL: 0.8844 - accuracy: 0.7167 - f1_score: 0.4665 - loss: 1.0915 - precision: 0.8243 - recall: 0.6157 - val_NLL: 1.0454 - val_accuracy: 0.7132 - val_f1_score: 0.3611 - val_loss: 1.2504 - val_precision: 0.8195 - val_recall: 0.6308\n",
      "Epoch 12/20\n",
      "1223/1223 - 52s - 43ms/step - NLL: 0.8763 - accuracy: 0.7184 - f1_score: 0.4702 - loss: 1.0843 - precision: 0.8227 - recall: 0.6194 - val_NLL: 1.0333 - val_accuracy: 0.7198 - val_f1_score: 0.3538 - val_loss: 1.2394 - val_precision: 0.8219 - val_recall: 0.6297\n",
      "Epoch 13/20\n",
      "1223/1223 - 52s - 43ms/step - NLL: 0.8681 - accuracy: 0.7202 - f1_score: 0.4782 - loss: 1.0773 - precision: 0.8248 - recall: 0.6214 - val_NLL: 1.0516 - val_accuracy: 0.7082 - val_f1_score: 0.3297 - val_loss: 1.2593 - val_precision: 0.8204 - val_recall: 0.6275\n",
      "Epoch 14/20\n",
      "1223/1223 - 53s - 43ms/step - NLL: 0.8567 - accuracy: 0.7245 - f1_score: 0.4861 - loss: 1.0671 - precision: 0.8280 - recall: 0.6276 - val_NLL: 1.0835 - val_accuracy: 0.7140 - val_f1_score: 0.3204 - val_loss: 1.2944 - val_precision: 0.8228 - val_recall: 0.6234\n",
      "Epoch 15/20\n",
      "1223/1223 - 52s - 43ms/step - NLL: 0.8519 - accuracy: 0.7249 - f1_score: 0.4871 - loss: 1.0636 - precision: 0.8276 - recall: 0.6292 - val_NLL: 1.0373 - val_accuracy: 0.7165 - val_f1_score: 0.3585 - val_loss: 1.2449 - val_precision: 0.8264 - val_recall: 0.6366\n",
      "Epoch 16/20\n",
      "1223/1223 - 52s - 43ms/step - NLL: 0.8426 - accuracy: 0.7291 - f1_score: 0.4957 - loss: 1.0547 - precision: 0.8287 - recall: 0.6331 - val_NLL: 1.0798 - val_accuracy: 0.7159 - val_f1_score: 0.3522 - val_loss: 1.2904 - val_precision: 0.8213 - val_recall: 0.6300\n",
      "Epoch 17/20\n",
      "1223/1223 - 52s - 43ms/step - NLL: 0.8358 - accuracy: 0.7295 - f1_score: 0.4999 - loss: 1.0487 - precision: 0.8297 - recall: 0.6356 - val_NLL: 1.0478 - val_accuracy: 0.7157 - val_f1_score: 0.3624 - val_loss: 1.2599 - val_precision: 0.8166 - val_recall: 0.6322\n",
      "Epoch 18/20\n",
      "1223/1223 - 53s - 44ms/step - NLL: 0.8327 - accuracy: 0.7317 - f1_score: 0.5026 - loss: 1.0465 - precision: 0.8304 - recall: 0.6358 - val_NLL: 1.0509 - val_accuracy: 0.7154 - val_f1_score: 0.3461 - val_loss: 1.2622 - val_precision: 0.8198 - val_recall: 0.6361\n",
      "Epoch 19/20\n",
      "1223/1223 - 54s - 44ms/step - NLL: 0.8272 - accuracy: 0.7315 - f1_score: 0.5028 - loss: 1.0414 - precision: 0.8307 - recall: 0.6396 - val_NLL: 1.0417 - val_accuracy: 0.7190 - val_f1_score: 0.3373 - val_loss: 1.2533 - val_precision: 0.8254 - val_recall: 0.6477\n",
      "Epoch 20/20\n",
      "1223/1223 - 54s - 44ms/step - NLL: 0.8224 - accuracy: 0.7315 - f1_score: 0.5035 - loss: 1.0372 - precision: 0.8322 - recall: 0.6410 - val_NLL: 1.0592 - val_accuracy: 0.7256 - val_f1_score: 0.3838 - val_loss: 1.2719 - val_precision: 0.8205 - val_recall: 0.6455\n",
      "\u001b[1m2446/2446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "NLL: 1.03\n",
      "Validation accuracy: 0.72\n",
      "Validation F1Score: 0.35\n",
      "evaluating Fold 5\n",
      "Setting seed to 819\n",
      "Epoch 1/20\n",
      "1222/1222 - 58s - 48ms/step - NLL: 1.4149 - accuracy: 0.6026 - f1_score: 0.1433 - loss: 1.6371 - precision: 0.7605 - recall: 0.4491 - val_NLL: 1.2418 - val_accuracy: 0.6391 - val_f1_score: 0.1338 - val_loss: 1.4225 - val_precision: 0.7291 - val_recall: 0.5517\n",
      "Epoch 2/20\n",
      "1222/1222 - 54s - 44ms/step - NLL: 1.1761 - accuracy: 0.6411 - f1_score: 0.2561 - loss: 1.3619 - precision: 0.7886 - recall: 0.5062 - val_NLL: 1.1395 - val_accuracy: 0.6685 - val_f1_score: 0.2227 - val_loss: 1.3302 - val_precision: 0.7495 - val_recall: 0.5835\n",
      "Epoch 3/20\n",
      "1222/1222 - 55s - 45ms/step - NLL: 1.0774 - accuracy: 0.6640 - f1_score: 0.3168 - loss: 1.2703 - precision: 0.7973 - recall: 0.5371 - val_NLL: 1.0797 - val_accuracy: 0.6733 - val_f1_score: 0.2527 - val_loss: 1.2740 - val_precision: 0.7740 - val_recall: 0.5886\n",
      "Epoch 4/20\n",
      "1222/1222 - 55s - 45ms/step - NLL: 1.0223 - accuracy: 0.6781 - f1_score: 0.3546 - loss: 1.2189 - precision: 0.8060 - recall: 0.5590 - val_NLL: 1.0512 - val_accuracy: 0.6836 - val_f1_score: 0.2647 - val_loss: 1.2488 - val_precision: 0.7746 - val_recall: 0.6080\n",
      "Epoch 5/20\n",
      "1222/1222 - 55s - 45ms/step - NLL: 0.9870 - accuracy: 0.6883 - f1_score: 0.3843 - loss: 1.1862 - precision: 0.8111 - recall: 0.5725 - val_NLL: 1.0368 - val_accuracy: 0.6898 - val_f1_score: 0.3031 - val_loss: 1.2370 - val_precision: 0.7748 - val_recall: 0.6070\n",
      "Epoch 6/20\n",
      "1222/1222 - 54s - 44ms/step - NLL: 0.9554 - accuracy: 0.6959 - f1_score: 0.4078 - loss: 1.1571 - precision: 0.8157 - recall: 0.5861 - val_NLL: 1.0272 - val_accuracy: 0.6871 - val_f1_score: 0.2891 - val_loss: 1.2296 - val_precision: 0.7740 - val_recall: 0.6080\n",
      "Epoch 7/20\n",
      "1222/1222 - 54s - 45ms/step - NLL: 0.9344 - accuracy: 0.7029 - f1_score: 0.4299 - loss: 1.1375 - precision: 0.8177 - recall: 0.5946 - val_NLL: 1.0083 - val_accuracy: 0.6938 - val_f1_score: 0.3235 - val_loss: 1.2126 - val_precision: 0.7852 - val_recall: 0.6221\n",
      "Epoch 8/20\n",
      "1222/1222 - 55s - 45ms/step - NLL: 0.9148 - accuracy: 0.7069 - f1_score: 0.4410 - loss: 1.1192 - precision: 0.8186 - recall: 0.6031 - val_NLL: 1.0681 - val_accuracy: 0.6814 - val_f1_score: 0.2846 - val_loss: 1.2738 - val_precision: 0.7530 - val_recall: 0.6218\n",
      "Epoch 9/20\n",
      "1222/1222 - 55s - 45ms/step - NLL: 0.9001 - accuracy: 0.7106 - f1_score: 0.4495 - loss: 1.1058 - precision: 0.8224 - recall: 0.6084 - val_NLL: 1.0019 - val_accuracy: 0.6900 - val_f1_score: 0.3158 - val_loss: 1.2084 - val_precision: 0.7956 - val_recall: 0.5975\n",
      "Epoch 10/20\n",
      "1222/1222 - 55s - 45ms/step - NLL: 0.8903 - accuracy: 0.7123 - f1_score: 0.4556 - loss: 1.0976 - precision: 0.8213 - recall: 0.6123 - val_NLL: 1.0324 - val_accuracy: 0.6868 - val_f1_score: 0.3012 - val_loss: 1.2421 - val_precision: 0.7680 - val_recall: 0.6288\n",
      "Epoch 11/20\n",
      "1222/1222 - 55s - 45ms/step - NLL: 0.8758 - accuracy: 0.7185 - f1_score: 0.4713 - loss: 1.0853 - precision: 0.8237 - recall: 0.6196 - val_NLL: 0.9804 - val_accuracy: 0.7054 - val_f1_score: 0.3391 - val_loss: 1.1916 - val_precision: 0.8033 - val_recall: 0.6280\n",
      "Epoch 12/20\n",
      "1222/1222 - 55s - 45ms/step - NLL: 0.8695 - accuracy: 0.7200 - f1_score: 0.4759 - loss: 1.0806 - precision: 0.8251 - recall: 0.6205 - val_NLL: 0.9809 - val_accuracy: 0.6973 - val_f1_score: 0.3275 - val_loss: 1.1932 - val_precision: 0.7967 - val_recall: 0.6164\n",
      "Epoch 13/20\n",
      "1222/1222 - 55s - 45ms/step - NLL: 0.8599 - accuracy: 0.7233 - f1_score: 0.4841 - loss: 1.0717 - precision: 0.8259 - recall: 0.6243 - val_NLL: 0.9932 - val_accuracy: 0.7016 - val_f1_score: 0.3402 - val_loss: 1.2056 - val_precision: 0.7980 - val_recall: 0.6383\n",
      "Epoch 14/20\n",
      "1222/1222 - 56s - 46ms/step - NLL: 0.8536 - accuracy: 0.7244 - f1_score: 0.4886 - loss: 1.0663 - precision: 0.8281 - recall: 0.6283 - val_NLL: 0.9997 - val_accuracy: 0.7022 - val_f1_score: 0.3572 - val_loss: 1.2138 - val_precision: 0.7813 - val_recall: 0.6186\n",
      "Epoch 15/20\n",
      "1222/1222 - 56s - 46ms/step - NLL: 0.8441 - accuracy: 0.7255 - f1_score: 0.4921 - loss: 1.0576 - precision: 0.8284 - recall: 0.6311 - val_NLL: 1.0113 - val_accuracy: 0.6971 - val_f1_score: 0.3355 - val_loss: 1.2252 - val_precision: 0.7756 - val_recall: 0.6264\n",
      "Epoch 16/20\n",
      "1222/1222 - 56s - 46ms/step - NLL: 0.8394 - accuracy: 0.7277 - f1_score: 0.4959 - loss: 1.0544 - precision: 0.8281 - recall: 0.6335 - val_NLL: 0.9826 - val_accuracy: 0.7014 - val_f1_score: 0.3377 - val_loss: 1.1975 - val_precision: 0.7840 - val_recall: 0.6345\n",
      "Epoch 17/20\n",
      "1222/1222 - 57s - 46ms/step - NLL: 0.8285 - accuracy: 0.7304 - f1_score: 0.5024 - loss: 1.0442 - precision: 0.8304 - recall: 0.6383 - val_NLL: 1.0027 - val_accuracy: 0.6984 - val_f1_score: 0.3421 - val_loss: 1.2192 - val_precision: 0.7755 - val_recall: 0.6347\n",
      "Epoch 18/20\n",
      "1222/1222 - 56s - 46ms/step - NLL: 0.8241 - accuracy: 0.7335 - f1_score: 0.5066 - loss: 1.0400 - precision: 0.8308 - recall: 0.6421 - val_NLL: 0.9772 - val_accuracy: 0.6989 - val_f1_score: 0.3438 - val_loss: 1.1941 - val_precision: 0.7848 - val_recall: 0.6285\n",
      "Epoch 19/20\n",
      "1222/1222 - 57s - 46ms/step - NLL: 0.8186 - accuracy: 0.7352 - f1_score: 0.5138 - loss: 1.0353 - precision: 0.8324 - recall: 0.6447 - val_NLL: 0.9673 - val_accuracy: 0.7043 - val_f1_score: 0.3597 - val_loss: 1.1842 - val_precision: 0.7997 - val_recall: 0.6388\n",
      "Epoch 20/20\n",
      "1222/1222 - 56s - 46ms/step - NLL: 0.8159 - accuracy: 0.7354 - f1_score: 0.5150 - loss: 1.0322 - precision: 0.8315 - recall: 0.6437 - val_NLL: 0.9896 - val_accuracy: 0.6930 - val_f1_score: 0.3350 - val_loss: 1.2053 - val_precision: 0.7848 - val_recall: 0.6315\n",
      "\u001b[1m2443/2443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step\n",
      "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "NLL: 0.97\n",
      "Validation accuracy: 0.70\n",
      "Validation F1Score: 0.36\n",
      "evaluating Fold 6\n",
      "Setting seed to 1027\n",
      "Epoch 1/20\n",
      "1194/1194 - 59s - 50ms/step - NLL: 1.4410 - accuracy: 0.5930 - f1_score: 0.1293 - loss: 1.6667 - precision: 0.7528 - recall: 0.4358 - val_NLL: 1.0708 - val_accuracy: 0.6815 - val_f1_score: 0.1733 - val_loss: 1.2438 - val_precision: 0.8408 - val_recall: 0.5455\n",
      "Epoch 2/20\n",
      "1194/1194 - 54s - 45ms/step - NLL: 1.2314 - accuracy: 0.6248 - f1_score: 0.2333 - loss: 1.4034 - precision: 0.7834 - recall: 0.4813 - val_NLL: 0.9993 - val_accuracy: 0.7010 - val_f1_score: 0.2495 - val_loss: 1.1840 - val_precision: 0.8676 - val_recall: 0.5603\n",
      "Epoch 3/20\n",
      "1194/1194 - 54s - 45ms/step - NLL: 1.1237 - accuracy: 0.6511 - f1_score: 0.3016 - loss: 1.3074 - precision: 0.7928 - recall: 0.5174 - val_NLL: 0.9711 - val_accuracy: 0.7127 - val_f1_score: 0.2706 - val_loss: 1.1614 - val_precision: 0.8602 - val_recall: 0.5835\n",
      "Epoch 4/20\n",
      "1194/1194 - 53s - 45ms/step - NLL: 1.0588 - accuracy: 0.6684 - f1_score: 0.3464 - loss: 1.2483 - precision: 0.7987 - recall: 0.5394 - val_NLL: 0.9276 - val_accuracy: 0.7188 - val_f1_score: 0.2949 - val_loss: 1.1229 - val_precision: 0.8315 - val_recall: 0.6089\n",
      "Epoch 5/20\n",
      "1194/1194 - 53s - 45ms/step - NLL: 1.0161 - accuracy: 0.6803 - f1_score: 0.3741 - loss: 1.2100 - precision: 0.8047 - recall: 0.5580 - val_NLL: 0.9438 - val_accuracy: 0.7144 - val_f1_score: 0.2862 - val_loss: 1.1422 - val_precision: 0.8219 - val_recall: 0.6171\n",
      "Epoch 6/20\n",
      "1194/1194 - 53s - 44ms/step - NLL: 0.9853 - accuracy: 0.6881 - f1_score: 0.3969 - loss: 1.1819 - precision: 0.8066 - recall: 0.5706 - val_NLL: 0.9412 - val_accuracy: 0.7177 - val_f1_score: 0.2860 - val_loss: 1.1434 - val_precision: 0.8397 - val_recall: 0.6144\n",
      "Epoch 7/20\n",
      "1194/1194 - 53s - 44ms/step - NLL: 0.9637 - accuracy: 0.6923 - f1_score: 0.4060 - loss: 1.1633 - precision: 0.8100 - recall: 0.5801 - val_NLL: 0.9441 - val_accuracy: 0.7191 - val_f1_score: 0.2938 - val_loss: 1.1472 - val_precision: 0.8288 - val_recall: 0.6177\n",
      "Epoch 8/20\n",
      "1194/1194 - 56s - 47ms/step - NLL: 0.9474 - accuracy: 0.6974 - f1_score: 0.4197 - loss: 1.1499 - precision: 0.8133 - recall: 0.5874 - val_NLL: 0.9197 - val_accuracy: 0.7202 - val_f1_score: 0.3011 - val_loss: 1.1261 - val_precision: 0.8249 - val_recall: 0.6285\n",
      "Epoch 9/20\n",
      "1194/1194 - 54s - 45ms/step - NLL: 0.9271 - accuracy: 0.7036 - f1_score: 0.4375 - loss: 1.1313 - precision: 0.8148 - recall: 0.5968 - val_NLL: 0.9303 - val_accuracy: 0.7264 - val_f1_score: 0.3267 - val_loss: 1.1370 - val_precision: 0.8299 - val_recall: 0.6349\n",
      "Epoch 10/20\n",
      "1194/1194 - 54s - 45ms/step - NLL: 0.9126 - accuracy: 0.7077 - f1_score: 0.4457 - loss: 1.1176 - precision: 0.8180 - recall: 0.6032 - val_NLL: 0.9220 - val_accuracy: 0.7292 - val_f1_score: 0.3425 - val_loss: 1.1329 - val_precision: 0.8399 - val_recall: 0.6310\n",
      "Epoch 11/20\n",
      "1194/1194 - 55s - 46ms/step - NLL: 0.9014 - accuracy: 0.7097 - f1_score: 0.4518 - loss: 1.1086 - precision: 0.8176 - recall: 0.6055 - val_NLL: 0.9430 - val_accuracy: 0.7284 - val_f1_score: 0.3492 - val_loss: 1.1546 - val_precision: 0.8331 - val_recall: 0.6356\n",
      "Epoch 12/20\n",
      "1194/1194 - 54s - 45ms/step - NLL: 0.8918 - accuracy: 0.7137 - f1_score: 0.4609 - loss: 1.0995 - precision: 0.8212 - recall: 0.6126 - val_NLL: 0.9129 - val_accuracy: 0.7275 - val_f1_score: 0.3429 - val_loss: 1.1232 - val_precision: 0.8293 - val_recall: 0.6418\n",
      "Epoch 13/20\n",
      "1194/1194 - 54s - 45ms/step - NLL: 0.8786 - accuracy: 0.7161 - f1_score: 0.4674 - loss: 1.0879 - precision: 0.8211 - recall: 0.6162 - val_NLL: 0.9369 - val_accuracy: 0.7261 - val_f1_score: 0.3310 - val_loss: 1.1509 - val_precision: 0.8225 - val_recall: 0.6409\n",
      "Epoch 14/20\n",
      "1194/1194 - 56s - 47ms/step - NLL: 0.8702 - accuracy: 0.7193 - f1_score: 0.4742 - loss: 1.0806 - precision: 0.8239 - recall: 0.6220 - val_NLL: 0.9202 - val_accuracy: 0.7315 - val_f1_score: 0.3542 - val_loss: 1.1334 - val_precision: 0.8361 - val_recall: 0.6460\n",
      "Epoch 15/20\n",
      "1194/1194 - 54s - 45ms/step - NLL: 0.8649 - accuracy: 0.7219 - f1_score: 0.4832 - loss: 1.0756 - precision: 0.8258 - recall: 0.6256 - val_NLL: 0.9124 - val_accuracy: 0.7368 - val_f1_score: 0.3590 - val_loss: 1.1271 - val_precision: 0.8418 - val_recall: 0.6387\n",
      "Epoch 16/20\n",
      "1194/1194 - 55s - 46ms/step - NLL: 0.8543 - accuracy: 0.7238 - f1_score: 0.4855 - loss: 1.0653 - precision: 0.8264 - recall: 0.6282 - val_NLL: 0.9159 - val_accuracy: 0.7299 - val_f1_score: 0.3497 - val_loss: 1.1296 - val_precision: 0.8386 - val_recall: 0.6391\n",
      "Epoch 17/20\n",
      "1194/1194 - 55s - 46ms/step - NLL: 0.8494 - accuracy: 0.7257 - f1_score: 0.4908 - loss: 1.0606 - precision: 0.8254 - recall: 0.6298 - val_NLL: 0.9068 - val_accuracy: 0.7337 - val_f1_score: 0.3530 - val_loss: 1.1207 - val_precision: 0.8355 - val_recall: 0.6405\n",
      "Epoch 18/20\n",
      "1194/1194 - 55s - 46ms/step - NLL: 0.8432 - accuracy: 0.7266 - f1_score: 0.4910 - loss: 1.0543 - precision: 0.8278 - recall: 0.6339 - val_NLL: 0.9712 - val_accuracy: 0.7240 - val_f1_score: 0.3406 - val_loss: 1.1852 - val_precision: 0.8191 - val_recall: 0.6489\n",
      "Epoch 19/20\n",
      "1194/1194 - 54s - 45ms/step - NLL: 0.8370 - accuracy: 0.7299 - f1_score: 0.4980 - loss: 1.0484 - precision: 0.8281 - recall: 0.6376 - val_NLL: 0.9397 - val_accuracy: 0.7319 - val_f1_score: 0.3602 - val_loss: 1.1544 - val_precision: 0.8198 - val_recall: 0.6517\n",
      "Epoch 20/20\n",
      "1194/1194 - 54s - 46ms/step - NLL: 0.8336 - accuracy: 0.7294 - f1_score: 0.5015 - loss: 1.0454 - precision: 0.8278 - recall: 0.6375 - val_NLL: 0.9305 - val_accuracy: 0.7304 - val_f1_score: 0.3410 - val_loss: 1.1461 - val_precision: 0.8204 - val_recall: 0.6619\n",
      "\u001b[1m2388/2388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "NLL: 0.91\n",
      "Validation accuracy: 0.73\n",
      "Validation F1Score: 0.35\n",
      "evaluating Fold 7\n",
      "Setting seed to 5825\n",
      "Epoch 1/20\n",
      "1217/1217 - 61s - 50ms/step - NLL: 1.4076 - accuracy: 0.6020 - f1_score: 0.1415 - loss: 1.6385 - precision: 0.7565 - recall: 0.4520 - val_NLL: 1.3344 - val_accuracy: 0.6129 - val_f1_score: 0.1576 - val_loss: 1.5201 - val_precision: 0.7481 - val_recall: 0.5017\n",
      "Epoch 2/20\n",
      "1217/1217 - 64s - 52ms/step - NLL: 1.1904 - accuracy: 0.6363 - f1_score: 0.2568 - loss: 1.3807 - precision: 0.7899 - recall: 0.5003 - val_NLL: 1.2593 - val_accuracy: 0.6321 - val_f1_score: 0.2349 - val_loss: 1.4565 - val_precision: 0.7523 - val_recall: 0.5229\n",
      "Epoch 3/20\n",
      "1217/1217 - 63s - 52ms/step - NLL: 1.0761 - accuracy: 0.6654 - f1_score: 0.3324 - loss: 1.2747 - precision: 0.8022 - recall: 0.5367 - val_NLL: 1.2177 - val_accuracy: 0.6378 - val_f1_score: 0.2548 - val_loss: 1.4191 - val_precision: 0.7458 - val_recall: 0.5488\n",
      "Epoch 4/20\n",
      "1217/1217 - 65s - 54ms/step - NLL: 1.0169 - accuracy: 0.6825 - f1_score: 0.3785 - loss: 1.2189 - precision: 0.8104 - recall: 0.5616 - val_NLL: 1.1919 - val_accuracy: 0.6453 - val_f1_score: 0.2868 - val_loss: 1.3956 - val_precision: 0.7555 - val_recall: 0.5550\n",
      "Epoch 5/20\n",
      "1217/1217 - 63s - 52ms/step - NLL: 0.9773 - accuracy: 0.6915 - f1_score: 0.4035 - loss: 1.1821 - precision: 0.8136 - recall: 0.5769 - val_NLL: 1.1589 - val_accuracy: 0.6388 - val_f1_score: 0.2891 - val_loss: 1.3662 - val_precision: 0.7443 - val_recall: 0.5525\n",
      "Epoch 6/20\n",
      "1217/1217 - 65s - 53ms/step - NLL: 0.9465 - accuracy: 0.6997 - f1_score: 0.4210 - loss: 1.1547 - precision: 0.8148 - recall: 0.5908 - val_NLL: 1.1427 - val_accuracy: 0.6415 - val_f1_score: 0.2760 - val_loss: 1.3521 - val_precision: 0.7546 - val_recall: 0.5669\n",
      "Epoch 7/20\n",
      "1217/1217 - 63s - 52ms/step - NLL: 0.9235 - accuracy: 0.7072 - f1_score: 0.4426 - loss: 1.1338 - precision: 0.8187 - recall: 0.6001 - val_NLL: 1.1623 - val_accuracy: 0.6520 - val_f1_score: 0.2987 - val_loss: 1.3760 - val_precision: 0.7529 - val_recall: 0.5784\n",
      "Epoch 8/20\n",
      "1217/1217 - 66s - 54ms/step - NLL: 0.9036 - accuracy: 0.7123 - f1_score: 0.4551 - loss: 1.1160 - precision: 0.8203 - recall: 0.6083 - val_NLL: 1.1642 - val_accuracy: 0.6490 - val_f1_score: 0.3042 - val_loss: 1.3785 - val_precision: 0.7326 - val_recall: 0.5786\n",
      "Epoch 9/20\n",
      "1217/1217 - 60s - 49ms/step - NLL: 0.8866 - accuracy: 0.7162 - f1_score: 0.4664 - loss: 1.1011 - precision: 0.8225 - recall: 0.6151 - val_NLL: 1.1121 - val_accuracy: 0.6575 - val_f1_score: 0.3316 - val_loss: 1.3284 - val_precision: 0.7427 - val_recall: 0.5823\n",
      "Epoch 10/20\n",
      "1217/1217 - 57s - 47ms/step - NLL: 0.8740 - accuracy: 0.7207 - f1_score: 0.4724 - loss: 1.0890 - precision: 0.8248 - recall: 0.6215 - val_NLL: 1.1292 - val_accuracy: 0.6602 - val_f1_score: 0.3440 - val_loss: 1.3457 - val_precision: 0.7587 - val_recall: 0.5779\n",
      "Epoch 11/20\n",
      "1217/1217 - 57s - 47ms/step - NLL: 0.8602 - accuracy: 0.7240 - f1_score: 0.4833 - loss: 1.0773 - precision: 0.8288 - recall: 0.6276 - val_NLL: 1.1213 - val_accuracy: 0.6522 - val_f1_score: 0.3281 - val_loss: 1.3418 - val_precision: 0.7554 - val_recall: 0.5709\n",
      "Epoch 12/20\n",
      "1217/1217 - 56s - 46ms/step - NLL: 0.8513 - accuracy: 0.7271 - f1_score: 0.4939 - loss: 1.0700 - precision: 0.8277 - recall: 0.6311 - val_NLL: 1.0909 - val_accuracy: 0.6602 - val_f1_score: 0.3406 - val_loss: 1.3121 - val_precision: 0.7519 - val_recall: 0.5866\n",
      "Epoch 13/20\n",
      "1217/1217 - 56s - 46ms/step - NLL: 0.8428 - accuracy: 0.7289 - f1_score: 0.4964 - loss: 1.0624 - precision: 0.8299 - recall: 0.6341 - val_NLL: 1.1088 - val_accuracy: 0.6652 - val_f1_score: 0.3532 - val_loss: 1.3298 - val_precision: 0.7553 - val_recall: 0.5836\n",
      "Epoch 14/20\n",
      "1217/1217 - 57s - 47ms/step - NLL: 0.8309 - accuracy: 0.7322 - f1_score: 0.5017 - loss: 1.0515 - precision: 0.8313 - recall: 0.6408 - val_NLL: 1.1406 - val_accuracy: 0.6502 - val_f1_score: 0.3214 - val_loss: 1.3635 - val_precision: 0.7425 - val_recall: 0.5746\n",
      "Epoch 15/20\n",
      "1217/1217 - 57s - 47ms/step - NLL: 0.8248 - accuracy: 0.7355 - f1_score: 0.5081 - loss: 1.0460 - precision: 0.8318 - recall: 0.6430 - val_NLL: 1.1187 - val_accuracy: 0.6525 - val_f1_score: 0.3406 - val_loss: 1.3404 - val_precision: 0.7480 - val_recall: 0.5833\n",
      "Epoch 16/20\n",
      "1217/1217 - 58s - 48ms/step - NLL: 0.8182 - accuracy: 0.7353 - f1_score: 0.5091 - loss: 1.0399 - precision: 0.8326 - recall: 0.6454 - val_NLL: 1.1043 - val_accuracy: 0.6555 - val_f1_score: 0.3427 - val_loss: 1.3282 - val_precision: 0.7643 - val_recall: 0.5744\n",
      "Epoch 17/20\n",
      "1217/1217 - 57s - 47ms/step - NLL: 0.8129 - accuracy: 0.7390 - f1_score: 0.5198 - loss: 1.0355 - precision: 0.8335 - recall: 0.6497 - val_NLL: 1.1118 - val_accuracy: 0.6672 - val_f1_score: 0.3734 - val_loss: 1.3361 - val_precision: 0.7639 - val_recall: 0.5828\n",
      "Epoch 18/20\n",
      "1217/1217 - 57s - 47ms/step - NLL: 0.8061 - accuracy: 0.7386 - f1_score: 0.5175 - loss: 1.0292 - precision: 0.8333 - recall: 0.6508 - val_NLL: 1.1001 - val_accuracy: 0.6590 - val_f1_score: 0.3415 - val_loss: 1.3244 - val_precision: 0.7425 - val_recall: 0.5903\n",
      "Epoch 19/20\n",
      "1217/1217 - 62s - 51ms/step - NLL: 0.7977 - accuracy: 0.7428 - f1_score: 0.5249 - loss: 1.0211 - precision: 0.8355 - recall: 0.6549 - val_NLL: 1.0837 - val_accuracy: 0.6682 - val_f1_score: 0.3553 - val_loss: 1.3105 - val_precision: 0.7657 - val_recall: 0.5853\n",
      "Epoch 20/20\n",
      "1217/1217 - 63s - 52ms/step - NLL: 0.7955 - accuracy: 0.7415 - f1_score: 0.5237 - loss: 1.0206 - precision: 0.8345 - recall: 0.6534 - val_NLL: 1.1030 - val_accuracy: 0.6639 - val_f1_score: 0.3559 - val_loss: 1.3293 - val_precision: 0.7548 - val_recall: 0.5905\n",
      "\u001b[1m2433/2433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "NLL: 1.08\n",
      "Validation accuracy: 0.67\n",
      "Validation F1Score: 0.36\n",
      "evaluating Fold 8\n",
      "Setting seed to 52408\n",
      "Epoch 1/20\n",
      "1215/1215 - 65s - 53ms/step - NLL: 1.4567 - accuracy: 0.5969 - f1_score: 0.1099 - loss: 1.6626 - precision: 0.7568 - recall: 0.4418 - val_NLL: 1.3573 - val_accuracy: 0.5815 - val_f1_score: 0.1650 - val_loss: 1.5167 - val_precision: 0.7744 - val_recall: 0.4492\n",
      "Epoch 2/20\n",
      "1215/1215 - 60s - 50ms/step - NLL: 1.2251 - accuracy: 0.6301 - f1_score: 0.2186 - loss: 1.3900 - precision: 0.7879 - recall: 0.4871 - val_NLL: 1.2020 - val_accuracy: 0.6257 - val_f1_score: 0.2572 - val_loss: 1.3735 - val_precision: 0.8014 - val_recall: 0.4815\n",
      "Epoch 3/20\n",
      "1215/1215 - 59s - 48ms/step - NLL: 1.1167 - accuracy: 0.6549 - f1_score: 0.2862 - loss: 1.2907 - precision: 0.7983 - recall: 0.5208 - val_NLL: 1.1090 - val_accuracy: 0.6491 - val_f1_score: 0.3013 - val_loss: 1.2834 - val_precision: 0.8089 - val_recall: 0.5245\n",
      "Epoch 4/20\n",
      "1215/1215 - 58s - 48ms/step - NLL: 1.0586 - accuracy: 0.6685 - f1_score: 0.3221 - loss: 1.2357 - precision: 0.8032 - recall: 0.5401 - val_NLL: 1.0880 - val_accuracy: 0.6556 - val_f1_score: 0.3189 - val_loss: 1.2673 - val_precision: 0.8151 - val_recall: 0.5388\n",
      "Epoch 5/20\n",
      "1215/1215 - 63s - 52ms/step - NLL: 1.0211 - accuracy: 0.6789 - f1_score: 0.3450 - loss: 1.2022 - precision: 0.8089 - recall: 0.5582 - val_NLL: 1.0477 - val_accuracy: 0.6696 - val_f1_score: 0.3417 - val_loss: 1.2300 - val_precision: 0.8176 - val_recall: 0.5641\n",
      "Epoch 6/20\n",
      "1215/1215 - 57s - 47ms/step - NLL: 0.9888 - accuracy: 0.6885 - f1_score: 0.3751 - loss: 1.1735 - precision: 0.8103 - recall: 0.5685 - val_NLL: 1.0349 - val_accuracy: 0.6701 - val_f1_score: 0.3398 - val_loss: 1.2228 - val_precision: 0.8144 - val_recall: 0.5817\n",
      "Epoch 7/20\n",
      "1215/1215 - 58s - 48ms/step - NLL: 0.9664 - accuracy: 0.6934 - f1_score: 0.3901 - loss: 1.1550 - precision: 0.8132 - recall: 0.5779 - val_NLL: 1.0031 - val_accuracy: 0.6834 - val_f1_score: 0.3652 - val_loss: 1.1939 - val_precision: 0.8197 - val_recall: 0.5883\n",
      "Epoch 8/20\n",
      "1215/1215 - 64s - 52ms/step - NLL: 0.9431 - accuracy: 0.6974 - f1_score: 0.4055 - loss: 1.1330 - precision: 0.8148 - recall: 0.5864 - val_NLL: 0.9832 - val_accuracy: 0.6863 - val_f1_score: 0.3739 - val_loss: 1.1738 - val_precision: 0.8218 - val_recall: 0.5960\n",
      "Epoch 9/20\n",
      "1215/1215 - 58s - 47ms/step - NLL: 0.9274 - accuracy: 0.7044 - f1_score: 0.4224 - loss: 1.1194 - precision: 0.8184 - recall: 0.5935 - val_NLL: 0.9754 - val_accuracy: 0.6894 - val_f1_score: 0.3848 - val_loss: 1.1688 - val_precision: 0.8178 - val_recall: 0.6071\n",
      "Epoch 10/20\n",
      "1215/1215 - 62s - 51ms/step - NLL: 0.9116 - accuracy: 0.7089 - f1_score: 0.4360 - loss: 1.1060 - precision: 0.8200 - recall: 0.6026 - val_NLL: 0.9521 - val_accuracy: 0.7001 - val_f1_score: 0.4081 - val_loss: 1.1467 - val_precision: 0.8309 - val_recall: 0.6100\n",
      "Epoch 11/20\n",
      "1215/1215 - 61s - 50ms/step - NLL: 0.9010 - accuracy: 0.7108 - f1_score: 0.4407 - loss: 1.0961 - precision: 0.8201 - recall: 0.6066 - val_NLL: 0.9804 - val_accuracy: 0.6943 - val_f1_score: 0.3947 - val_loss: 1.1757 - val_precision: 0.8276 - val_recall: 0.6088\n",
      "Epoch 12/20\n",
      "1215/1215 - 62s - 51ms/step - NLL: 0.8891 - accuracy: 0.7141 - f1_score: 0.4519 - loss: 1.0856 - precision: 0.8226 - recall: 0.6114 - val_NLL: 0.9617 - val_accuracy: 0.7073 - val_f1_score: 0.4235 - val_loss: 1.1580 - val_precision: 0.8212 - val_recall: 0.6187\n",
      "Epoch 13/20\n",
      "1215/1215 - 63s - 52ms/step - NLL: 0.8773 - accuracy: 0.7190 - f1_score: 0.4612 - loss: 1.0742 - precision: 0.8248 - recall: 0.6184 - val_NLL: 0.9457 - val_accuracy: 0.6981 - val_f1_score: 0.4134 - val_loss: 1.1431 - val_precision: 0.8214 - val_recall: 0.6131\n",
      "Epoch 14/20\n",
      "1215/1215 - 58s - 48ms/step - NLL: 0.8732 - accuracy: 0.7193 - f1_score: 0.4663 - loss: 1.0702 - precision: 0.8258 - recall: 0.6196 - val_NLL: 0.9306 - val_accuracy: 0.7090 - val_f1_score: 0.4383 - val_loss: 1.1269 - val_precision: 0.8310 - val_recall: 0.6257\n",
      "Epoch 15/20\n",
      "1215/1215 - 62s - 51ms/step - NLL: 0.8664 - accuracy: 0.7215 - f1_score: 0.4709 - loss: 1.0637 - precision: 0.8259 - recall: 0.6217 - val_NLL: 0.9486 - val_accuracy: 0.7032 - val_f1_score: 0.4138 - val_loss: 1.1459 - val_precision: 0.8231 - val_recall: 0.6271\n",
      "Epoch 16/20\n",
      "1215/1215 - 61s - 50ms/step - NLL: 0.8555 - accuracy: 0.7246 - f1_score: 0.4765 - loss: 1.0529 - precision: 0.8282 - recall: 0.6281 - val_NLL: 0.9253 - val_accuracy: 0.7121 - val_f1_score: 0.4336 - val_loss: 1.1228 - val_precision: 0.8363 - val_recall: 0.6255\n",
      "Epoch 17/20\n",
      "1215/1215 - 61s - 50ms/step - NLL: 0.8496 - accuracy: 0.7259 - f1_score: 0.4800 - loss: 1.0471 - precision: 0.8273 - recall: 0.6293 - val_NLL: 0.9350 - val_accuracy: 0.7010 - val_f1_score: 0.4295 - val_loss: 1.1327 - val_precision: 0.8322 - val_recall: 0.6238\n",
      "Epoch 18/20\n",
      "1215/1215 - 64s - 52ms/step - NLL: 0.8454 - accuracy: 0.7278 - f1_score: 0.4858 - loss: 1.0434 - precision: 0.8282 - recall: 0.6329 - val_NLL: 0.9167 - val_accuracy: 0.7134 - val_f1_score: 0.4393 - val_loss: 1.1156 - val_precision: 0.8332 - val_recall: 0.6308\n",
      "Epoch 19/20\n",
      "1215/1215 - 62s - 51ms/step - NLL: 0.8416 - accuracy: 0.7275 - f1_score: 0.4828 - loss: 1.0403 - precision: 0.8284 - recall: 0.6330 - val_NLL: 0.9364 - val_accuracy: 0.7138 - val_f1_score: 0.4399 - val_loss: 1.1357 - val_precision: 0.8319 - val_recall: 0.6228\n",
      "Epoch 20/20\n",
      "1215/1215 - 61s - 50ms/step - NLL: 0.8321 - accuracy: 0.7326 - f1_score: 0.4966 - loss: 1.0310 - precision: 0.8301 - recall: 0.6385 - val_NLL: 0.9365 - val_accuracy: 0.7085 - val_f1_score: 0.4372 - val_loss: 1.1352 - val_precision: 0.8320 - val_recall: 0.6206\n",
      "\u001b[1m2429/2429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "NLL: 0.92\n",
      "Validation accuracy: 0.71\n",
      "Validation F1Score: 0.44\n",
      "evaluating Fold 9\n",
      "Setting seed to 88243\n",
      "Epoch 1/20\n",
      "1194/1194 - 66s - 55ms/step - NLL: 1.4286 - accuracy: 0.5993 - f1_score: 0.1318 - loss: 1.6591 - precision: 0.7580 - recall: 0.4474 - val_NLL: 1.2926 - val_accuracy: 0.6112 - val_f1_score: 0.1456 - val_loss: 1.4833 - val_precision: 0.7409 - val_recall: 0.5298\n",
      "Epoch 2/20\n",
      "1194/1194 - 61s - 51ms/step - NLL: 1.1705 - accuracy: 0.6436 - f1_score: 0.2717 - loss: 1.3661 - precision: 0.7888 - recall: 0.5081 - val_NLL: 1.2400 - val_accuracy: 0.6309 - val_f1_score: 0.2307 - val_loss: 1.4414 - val_precision: 0.7307 - val_recall: 0.5448\n",
      "Epoch 3/20\n",
      "1194/1194 - 60s - 50ms/step - NLL: 1.0703 - accuracy: 0.6658 - f1_score: 0.3358 - loss: 1.2696 - precision: 0.7974 - recall: 0.5399 - val_NLL: 1.1688 - val_accuracy: 0.6450 - val_f1_score: 0.2470 - val_loss: 1.3707 - val_precision: 0.7392 - val_recall: 0.5688\n",
      "Epoch 4/20\n",
      "1194/1194 - 60s - 50ms/step - NLL: 1.0204 - accuracy: 0.6798 - f1_score: 0.3714 - loss: 1.2202 - precision: 0.8033 - recall: 0.5577 - val_NLL: 1.1535 - val_accuracy: 0.6565 - val_f1_score: 0.2728 - val_loss: 1.3565 - val_precision: 0.7515 - val_recall: 0.5834\n",
      "Epoch 5/20\n",
      "1194/1194 - 60s - 50ms/step - NLL: 0.9806 - accuracy: 0.6902 - f1_score: 0.3994 - loss: 1.1828 - precision: 0.8111 - recall: 0.5754 - val_NLL: 1.2100 - val_accuracy: 0.6454 - val_f1_score: 0.2754 - val_loss: 1.4141 - val_precision: 0.7390 - val_recall: 0.5748\n",
      "Epoch 6/20\n",
      "1194/1194 - 61s - 51ms/step - NLL: 0.9569 - accuracy: 0.6958 - f1_score: 0.4164 - loss: 1.1602 - precision: 0.8123 - recall: 0.5847 - val_NLL: 1.1616 - val_accuracy: 0.6527 - val_f1_score: 0.2894 - val_loss: 1.3646 - val_precision: 0.7289 - val_recall: 0.5821\n",
      "Epoch 7/20\n",
      "1194/1194 - 61s - 51ms/step - NLL: 0.9346 - accuracy: 0.7025 - f1_score: 0.4316 - loss: 1.1394 - precision: 0.8155 - recall: 0.5933 - val_NLL: 1.1444 - val_accuracy: 0.6551 - val_f1_score: 0.2963 - val_loss: 1.3510 - val_precision: 0.7467 - val_recall: 0.5850\n",
      "Epoch 8/20\n",
      "1194/1194 - 62s - 52ms/step - NLL: 0.9144 - accuracy: 0.7077 - f1_score: 0.4438 - loss: 1.1213 - precision: 0.8159 - recall: 0.6015 - val_NLL: 1.1263 - val_accuracy: 0.6602 - val_f1_score: 0.3037 - val_loss: 1.3348 - val_precision: 0.7431 - val_recall: 0.5898\n",
      "Epoch 9/20\n",
      "1194/1194 - 68s - 57ms/step - NLL: 0.9005 - accuracy: 0.7114 - f1_score: 0.4533 - loss: 1.1084 - precision: 0.8206 - recall: 0.6083 - val_NLL: 1.1116 - val_accuracy: 0.6626 - val_f1_score: 0.3061 - val_loss: 1.3200 - val_precision: 0.7420 - val_recall: 0.5975\n",
      "Epoch 10/20\n",
      "1194/1194 - 63s - 53ms/step - NLL: 0.8877 - accuracy: 0.7129 - f1_score: 0.4578 - loss: 1.0971 - precision: 0.8203 - recall: 0.6116 - val_NLL: 1.1323 - val_accuracy: 0.6576 - val_f1_score: 0.2996 - val_loss: 1.3420 - val_precision: 0.7411 - val_recall: 0.5869\n",
      "Epoch 11/20\n",
      "1194/1194 - 60s - 50ms/step - NLL: 0.8765 - accuracy: 0.7172 - f1_score: 0.4702 - loss: 1.0864 - precision: 0.8225 - recall: 0.6174 - val_NLL: 1.1331 - val_accuracy: 0.6589 - val_f1_score: 0.3004 - val_loss: 1.3435 - val_precision: 0.7469 - val_recall: 0.5889\n",
      "Epoch 12/20\n",
      "1194/1194 - 61s - 51ms/step - NLL: 0.8659 - accuracy: 0.7218 - f1_score: 0.4785 - loss: 1.0771 - precision: 0.8248 - recall: 0.6241 - val_NLL: 1.1628 - val_accuracy: 0.6591 - val_f1_score: 0.3104 - val_loss: 1.3763 - val_precision: 0.7406 - val_recall: 0.6042\n",
      "Epoch 13/20\n",
      "1194/1194 - 66s - 55ms/step - NLL: 0.8598 - accuracy: 0.7232 - f1_score: 0.4837 - loss: 1.0707 - precision: 0.8255 - recall: 0.6258 - val_NLL: 1.1067 - val_accuracy: 0.6609 - val_f1_score: 0.3147 - val_loss: 1.3204 - val_precision: 0.7462 - val_recall: 0.5946\n",
      "Epoch 14/20\n",
      "1194/1194 - 68s - 57ms/step - NLL: 0.8500 - accuracy: 0.7232 - f1_score: 0.4845 - loss: 1.0614 - precision: 0.8262 - recall: 0.6297 - val_NLL: 1.1313 - val_accuracy: 0.6662 - val_f1_score: 0.3171 - val_loss: 1.3451 - val_precision: 0.7511 - val_recall: 0.5989\n",
      "Epoch 15/20\n",
      "1194/1194 - 65s - 54ms/step - NLL: 0.8439 - accuracy: 0.7264 - f1_score: 0.4905 - loss: 1.0566 - precision: 0.8279 - recall: 0.6303 - val_NLL: 1.1349 - val_accuracy: 0.6615 - val_f1_score: 0.3136 - val_loss: 1.3521 - val_precision: 0.7495 - val_recall: 0.5997\n",
      "Epoch 16/20\n",
      "1194/1194 - 66s - 55ms/step - NLL: 0.8351 - accuracy: 0.7285 - f1_score: 0.4948 - loss: 1.0491 - precision: 0.8282 - recall: 0.6357 - val_NLL: 1.0869 - val_accuracy: 0.6757 - val_f1_score: 0.3374 - val_loss: 1.3031 - val_precision: 0.7506 - val_recall: 0.6138\n",
      "Epoch 17/20\n",
      "1194/1194 - 77s - 64ms/step - NLL: 0.8303 - accuracy: 0.7309 - f1_score: 0.5016 - loss: 1.0448 - precision: 0.8300 - recall: 0.6382 - val_NLL: 1.0880 - val_accuracy: 0.6752 - val_f1_score: 0.3445 - val_loss: 1.3040 - val_precision: 0.7522 - val_recall: 0.6063\n",
      "Epoch 18/20\n",
      "1194/1194 - 66s - 55ms/step - NLL: 0.8218 - accuracy: 0.7325 - f1_score: 0.5053 - loss: 1.0365 - precision: 0.8313 - recall: 0.6399 - val_NLL: 1.1474 - val_accuracy: 0.6624 - val_f1_score: 0.3149 - val_loss: 1.3633 - val_precision: 0.7521 - val_recall: 0.6013\n",
      "Epoch 19/20\n",
      "1194/1194 - 65s - 54ms/step - NLL: 0.8154 - accuracy: 0.7370 - f1_score: 0.5123 - loss: 1.0319 - precision: 0.8326 - recall: 0.6461 - val_NLL: 1.1145 - val_accuracy: 0.6701 - val_f1_score: 0.3343 - val_loss: 1.3332 - val_precision: 0.7491 - val_recall: 0.5978\n",
      "Epoch 20/20\n",
      "1194/1194 - 67s - 56ms/step - NLL: 0.8099 - accuracy: 0.7357 - f1_score: 0.5136 - loss: 1.0281 - precision: 0.8318 - recall: 0.6461 - val_NLL: 1.1214 - val_accuracy: 0.6730 - val_f1_score: 0.3439 - val_loss: 1.3387 - val_precision: 0.7537 - val_recall: 0.6055\n",
      "\u001b[1m2388/2388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 11ms/step\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step\n",
      "NLL: 1.09\n",
      "Validation accuracy: 0.68\n",
      "Validation F1Score: 0.34\n",
      "evaluating Fold 10\n",
      "Setting seed to 419748\n",
      "Epoch 1/20\n",
      "1197/1197 - 70s - 58ms/step - NLL: 1.4503 - accuracy: 0.5943 - f1_score: 0.1246 - loss: 1.6857 - precision: 0.7547 - recall: 0.4356 - val_NLL: 1.1174 - val_accuracy: 0.6545 - val_f1_score: 0.1837 - val_loss: 1.2894 - val_precision: 0.8138 - val_recall: 0.5257\n",
      "Epoch 2/20\n",
      "1197/1197 - 66s - 55ms/step - NLL: 1.2260 - accuracy: 0.6293 - f1_score: 0.2338 - loss: 1.4019 - precision: 0.7820 - recall: 0.4892 - val_NLL: 0.9443 - val_accuracy: 0.7021 - val_f1_score: 0.3039 - val_loss: 1.1266 - val_precision: 0.8241 - val_recall: 0.5820\n",
      "Epoch 3/20\n",
      "1197/1197 - 64s - 54ms/step - NLL: 1.1158 - accuracy: 0.6569 - f1_score: 0.3089 - loss: 1.2990 - precision: 0.7945 - recall: 0.5265 - val_NLL: 0.8704 - val_accuracy: 0.7226 - val_f1_score: 0.3694 - val_loss: 1.0559 - val_precision: 0.8357 - val_recall: 0.6176\n",
      "Epoch 4/20\n",
      "1197/1197 - 64s - 54ms/step - NLL: 1.0507 - accuracy: 0.6705 - f1_score: 0.3466 - loss: 1.2405 - precision: 0.8000 - recall: 0.5476 - val_NLL: 0.8296 - val_accuracy: 0.7340 - val_f1_score: 0.3883 - val_loss: 1.0230 - val_precision: 0.8267 - val_recall: 0.6535\n",
      "Epoch 5/20\n",
      "1197/1197 - 64s - 54ms/step - NLL: 1.0059 - accuracy: 0.6837 - f1_score: 0.3815 - loss: 1.2006 - precision: 0.8043 - recall: 0.5661 - val_NLL: 0.8100 - val_accuracy: 0.7386 - val_f1_score: 0.4037 - val_loss: 1.0060 - val_precision: 0.8303 - val_recall: 0.6598\n",
      "Epoch 6/20\n",
      "1197/1197 - 64s - 53ms/step - NLL: 0.9780 - accuracy: 0.6913 - f1_score: 0.3984 - loss: 1.1761 - precision: 0.8100 - recall: 0.5792 - val_NLL: 0.8029 - val_accuracy: 0.7371 - val_f1_score: 0.4043 - val_loss: 0.9982 - val_precision: 0.8267 - val_recall: 0.6707\n",
      "Epoch 7/20\n",
      "1197/1197 - 64s - 53ms/step - NLL: 0.9512 - accuracy: 0.6970 - f1_score: 0.4132 - loss: 1.1512 - precision: 0.8098 - recall: 0.5886 - val_NLL: 0.7953 - val_accuracy: 0.7367 - val_f1_score: 0.4073 - val_loss: 0.9954 - val_precision: 0.8348 - val_recall: 0.6661\n",
      "Epoch 8/20\n",
      "1197/1197 - 79s - 66ms/step - NLL: 0.9325 - accuracy: 0.7022 - f1_score: 0.4299 - loss: 1.1356 - precision: 0.8141 - recall: 0.5956 - val_NLL: 0.7890 - val_accuracy: 0.7300 - val_f1_score: 0.4112 - val_loss: 0.9939 - val_precision: 0.8243 - val_recall: 0.6661\n",
      "Epoch 9/20\n",
      "1197/1197 - 58s - 48ms/step - NLL: 0.9145 - accuracy: 0.7074 - f1_score: 0.4428 - loss: 1.1189 - precision: 0.8173 - recall: 0.6048 - val_NLL: 0.7925 - val_accuracy: 0.7388 - val_f1_score: 0.4211 - val_loss: 0.9978 - val_precision: 0.8297 - val_recall: 0.6676\n",
      "Epoch 10/20\n",
      "1197/1197 - 58s - 48ms/step - NLL: 0.9011 - accuracy: 0.7127 - f1_score: 0.4535 - loss: 1.1078 - precision: 0.8186 - recall: 0.6126 - val_NLL: 0.7846 - val_accuracy: 0.7369 - val_f1_score: 0.4251 - val_loss: 0.9925 - val_precision: 0.8277 - val_recall: 0.6735\n",
      "Epoch 11/20\n",
      "1197/1197 - 57s - 48ms/step - NLL: 0.8872 - accuracy: 0.7155 - f1_score: 0.4613 - loss: 1.0952 - precision: 0.8234 - recall: 0.6178 - val_NLL: 0.7806 - val_accuracy: 0.7365 - val_f1_score: 0.4169 - val_loss: 0.9910 - val_precision: 0.8174 - val_recall: 0.6781\n",
      "Epoch 12/20\n",
      "1197/1197 - 57s - 48ms/step - NLL: 0.8754 - accuracy: 0.7213 - f1_score: 0.4731 - loss: 1.0842 - precision: 0.8233 - recall: 0.6226 - val_NLL: 0.7892 - val_accuracy: 0.7346 - val_f1_score: 0.4130 - val_loss: 0.9978 - val_precision: 0.8229 - val_recall: 0.6699\n",
      "Epoch 13/20\n",
      "1197/1197 - 57s - 48ms/step - NLL: 0.8703 - accuracy: 0.7204 - f1_score: 0.4744 - loss: 1.0803 - precision: 0.8231 - recall: 0.6243 - val_NLL: 0.7842 - val_accuracy: 0.7451 - val_f1_score: 0.4379 - val_loss: 0.9937 - val_precision: 0.8220 - val_recall: 0.6904\n",
      "Epoch 14/20\n",
      "1197/1197 - 58s - 48ms/step - NLL: 0.8611 - accuracy: 0.7235 - f1_score: 0.4806 - loss: 1.0716 - precision: 0.8243 - recall: 0.6299 - val_NLL: 0.7746 - val_accuracy: 0.7409 - val_f1_score: 0.4236 - val_loss: 0.9849 - val_precision: 0.8225 - val_recall: 0.6834\n",
      "Epoch 15/20\n",
      "1197/1197 - 58s - 49ms/step - NLL: 0.8511 - accuracy: 0.7270 - f1_score: 0.4897 - loss: 1.0627 - precision: 0.8260 - recall: 0.6343 - val_NLL: 0.7647 - val_accuracy: 0.7462 - val_f1_score: 0.4439 - val_loss: 0.9727 - val_precision: 0.8242 - val_recall: 0.6975\n",
      "Epoch 16/20\n",
      "1197/1197 - 57s - 48ms/step - NLL: 0.8458 - accuracy: 0.7281 - f1_score: 0.4926 - loss: 1.0577 - precision: 0.8275 - recall: 0.6339 - val_NLL: 0.7807 - val_accuracy: 0.7483 - val_f1_score: 0.4407 - val_loss: 0.9908 - val_precision: 0.8248 - val_recall: 0.6998\n",
      "Epoch 17/20\n",
      "1197/1197 - 57s - 48ms/step - NLL: 0.8396 - accuracy: 0.7302 - f1_score: 0.4979 - loss: 1.0517 - precision: 0.8289 - recall: 0.6384 - val_NLL: 0.7729 - val_accuracy: 0.7435 - val_f1_score: 0.4516 - val_loss: 0.9850 - val_precision: 0.8196 - val_recall: 0.6846\n",
      "Epoch 18/20\n",
      "1197/1197 - 57s - 48ms/step - NLL: 0.8341 - accuracy: 0.7328 - f1_score: 0.5015 - loss: 1.0471 - precision: 0.8298 - recall: 0.6411 - val_NLL: 0.7450 - val_accuracy: 0.7490 - val_f1_score: 0.4660 - val_loss: 0.9539 - val_precision: 0.8296 - val_recall: 0.7021\n",
      "Epoch 19/20\n",
      "1197/1197 - 58s - 48ms/step - NLL: 0.8274 - accuracy: 0.7325 - f1_score: 0.5023 - loss: 1.0413 - precision: 0.8299 - recall: 0.6430 - val_NLL: 0.7606 - val_accuracy: 0.7481 - val_f1_score: 0.4448 - val_loss: 0.9726 - val_precision: 0.8208 - val_recall: 0.6952\n",
      "Epoch 20/20\n",
      "1197/1197 - 58s - 48ms/step - NLL: 0.8217 - accuracy: 0.7364 - f1_score: 0.5109 - loss: 1.0366 - precision: 0.8321 - recall: 0.6464 - val_NLL: 0.7489 - val_accuracy: 0.7483 - val_f1_score: 0.4653 - val_loss: 0.9606 - val_precision: 0.8183 - val_recall: 0.7036\n",
      "\u001b[1m2394/2394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 10ms/step\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "NLL: 0.75\n",
      "Validation accuracy: 0.75\n",
      "Validation F1Score: 0.47\n",
      "evaluating Fold 11\n",
      "Setting seed to 786191\n",
      "Epoch 1/20\n",
      "1207/1207 - 63s - 52ms/step - NLL: 1.4456 - accuracy: 0.5976 - f1_score: 0.1148 - loss: 1.6531 - precision: 0.7607 - recall: 0.4451 - val_NLL: 1.3092 - val_accuracy: 0.6068 - val_f1_score: 0.1262 - val_loss: 1.4718 - val_precision: 0.7287 - val_recall: 0.4964\n",
      "Epoch 2/20\n",
      "1207/1207 - 58s - 48ms/step - NLL: 1.2117 - accuracy: 0.6339 - f1_score: 0.2296 - loss: 1.3792 - precision: 0.7904 - recall: 0.4954 - val_NLL: 1.1723 - val_accuracy: 0.6244 - val_f1_score: 0.2065 - val_loss: 1.3473 - val_precision: 0.7533 - val_recall: 0.5092\n",
      "Epoch 3/20\n",
      "1207/1207 - 58s - 48ms/step - NLL: 1.1081 - accuracy: 0.6575 - f1_score: 0.2936 - loss: 1.2862 - precision: 0.7983 - recall: 0.5257 - val_NLL: 1.0793 - val_accuracy: 0.6438 - val_f1_score: 0.2736 - val_loss: 1.2602 - val_precision: 0.7716 - val_recall: 0.5285\n",
      "Epoch 4/20\n",
      "1207/1207 - 58s - 48ms/step - NLL: 1.0550 - accuracy: 0.6713 - f1_score: 0.3347 - loss: 1.2376 - precision: 0.8056 - recall: 0.5450 - val_NLL: 1.0295 - val_accuracy: 0.6596 - val_f1_score: 0.3077 - val_loss: 1.2134 - val_precision: 0.7845 - val_recall: 0.5492\n",
      "Epoch 5/20\n",
      "1207/1207 - 59s - 48ms/step - NLL: 1.0163 - accuracy: 0.6809 - f1_score: 0.3631 - loss: 1.2026 - precision: 0.8089 - recall: 0.5579 - val_NLL: 1.0222 - val_accuracy: 0.6621 - val_f1_score: 0.3405 - val_loss: 1.2125 - val_precision: 0.7766 - val_recall: 0.5581\n",
      "Epoch 6/20\n",
      "1207/1207 - 58s - 48ms/step - NLL: 0.9879 - accuracy: 0.6865 - f1_score: 0.3801 - loss: 1.1775 - precision: 0.8127 - recall: 0.5697 - val_NLL: 1.0062 - val_accuracy: 0.6673 - val_f1_score: 0.3471 - val_loss: 1.1991 - val_precision: 0.7881 - val_recall: 0.5553\n",
      "Epoch 7/20\n",
      "1207/1207 - 58s - 48ms/step - NLL: 0.9658 - accuracy: 0.6942 - f1_score: 0.3994 - loss: 1.1576 - precision: 0.8156 - recall: 0.5776 - val_NLL: 0.9652 - val_accuracy: 0.6805 - val_f1_score: 0.3613 - val_loss: 1.1610 - val_precision: 0.7877 - val_recall: 0.5813\n",
      "Epoch 8/20\n",
      "1207/1207 - 58s - 48ms/step - NLL: 0.9470 - accuracy: 0.6985 - f1_score: 0.4153 - loss: 1.1420 - precision: 0.8167 - recall: 0.5869 - val_NLL: 0.9577 - val_accuracy: 0.6837 - val_f1_score: 0.3975 - val_loss: 1.1546 - val_precision: 0.7901 - val_recall: 0.5760\n",
      "Epoch 9/20\n",
      "1207/1207 - 59s - 49ms/step - NLL: 0.9296 - accuracy: 0.7032 - f1_score: 0.4268 - loss: 1.1270 - precision: 0.8184 - recall: 0.5940 - val_NLL: 0.9487 - val_accuracy: 0.6930 - val_f1_score: 0.4109 - val_loss: 1.1505 - val_precision: 0.7940 - val_recall: 0.5807\n",
      "Epoch 10/20\n",
      "1207/1207 - 59s - 49ms/step - NLL: 0.9165 - accuracy: 0.7061 - f1_score: 0.4326 - loss: 1.1164 - precision: 0.8201 - recall: 0.5987 - val_NLL: 0.9722 - val_accuracy: 0.6809 - val_f1_score: 0.3911 - val_loss: 1.1747 - val_precision: 0.7785 - val_recall: 0.5876\n",
      "Epoch 11/20\n",
      "1207/1207 - 59s - 49ms/step - NLL: 0.9023 - accuracy: 0.7119 - f1_score: 0.4509 - loss: 1.1034 - precision: 0.8227 - recall: 0.6067 - val_NLL: 0.9365 - val_accuracy: 0.6869 - val_f1_score: 0.4053 - val_loss: 1.1395 - val_precision: 0.7903 - val_recall: 0.5872\n",
      "Epoch 12/20\n",
      "1207/1207 - 60s - 50ms/step - NLL: 0.8906 - accuracy: 0.7148 - f1_score: 0.4585 - loss: 1.0931 - precision: 0.8249 - recall: 0.6120 - val_NLL: 0.9488 - val_accuracy: 0.6902 - val_f1_score: 0.4234 - val_loss: 1.1572 - val_precision: 0.7836 - val_recall: 0.5945\n",
      "Epoch 13/20\n",
      "1207/1207 - 59s - 49ms/step - NLL: 0.8833 - accuracy: 0.7162 - f1_score: 0.4618 - loss: 1.0870 - precision: 0.8262 - recall: 0.6156 - val_NLL: 0.9144 - val_accuracy: 0.6925 - val_f1_score: 0.4255 - val_loss: 1.1228 - val_precision: 0.7944 - val_recall: 0.5979\n",
      "Epoch 14/20\n",
      "1207/1207 - 59s - 49ms/step - NLL: 0.8766 - accuracy: 0.7195 - f1_score: 0.4686 - loss: 1.0812 - precision: 0.8264 - recall: 0.6175 - val_NLL: 0.9218 - val_accuracy: 0.6949 - val_f1_score: 0.4391 - val_loss: 1.1345 - val_precision: 0.7916 - val_recall: 0.6040\n",
      "Epoch 15/20\n",
      "1207/1207 - 59s - 49ms/step - NLL: 0.8668 - accuracy: 0.7230 - f1_score: 0.4741 - loss: 1.0716 - precision: 0.8298 - recall: 0.6242 - val_NLL: 0.9273 - val_accuracy: 0.6891 - val_f1_score: 0.4305 - val_loss: 1.1366 - val_precision: 0.7826 - val_recall: 0.6050\n",
      "Epoch 16/20\n",
      "1207/1207 - 59s - 48ms/step - NLL: 0.8609 - accuracy: 0.7234 - f1_score: 0.4778 - loss: 1.0664 - precision: 0.8289 - recall: 0.6268 - val_NLL: 0.9427 - val_accuracy: 0.6882 - val_f1_score: 0.4293 - val_loss: 1.1564 - val_precision: 0.7845 - val_recall: 0.6150\n",
      "Epoch 17/20\n",
      "1207/1207 - 61s - 50ms/step - NLL: 0.8505 - accuracy: 0.7265 - f1_score: 0.4849 - loss: 1.0559 - precision: 0.8307 - recall: 0.6315 - val_NLL: 0.9248 - val_accuracy: 0.6973 - val_f1_score: 0.4471 - val_loss: 1.1344 - val_precision: 0.7862 - val_recall: 0.6203\n",
      "Epoch 18/20\n",
      "1207/1207 - 59s - 49ms/step - NLL: 0.8491 - accuracy: 0.7269 - f1_score: 0.4856 - loss: 1.0545 - precision: 0.8294 - recall: 0.6307 - val_NLL: 0.8828 - val_accuracy: 0.7031 - val_f1_score: 0.4583 - val_loss: 1.0920 - val_precision: 0.7927 - val_recall: 0.6270\n",
      "Epoch 19/20\n",
      "1207/1207 - 59s - 49ms/step - NLL: 0.8433 - accuracy: 0.7282 - f1_score: 0.4884 - loss: 1.0488 - precision: 0.8304 - recall: 0.6341 - val_NLL: 0.8857 - val_accuracy: 0.7093 - val_f1_score: 0.4821 - val_loss: 1.0969 - val_precision: 0.8049 - val_recall: 0.6346\n",
      "Epoch 20/20\n",
      "1207/1207 - 59s - 49ms/step - NLL: 0.8329 - accuracy: 0.7327 - f1_score: 0.4991 - loss: 1.0392 - precision: 0.8328 - recall: 0.6387 - val_NLL: 0.8674 - val_accuracy: 0.7126 - val_f1_score: 0.4827 - val_loss: 1.0818 - val_precision: 0.8157 - val_recall: 0.6266\n",
      "\u001b[1m2414/2414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 10ms/step\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "NLL: 0.87\n",
      "Validation accuracy: 0.71\n",
      "Validation F1Score: 0.48\n",
      "evaluating Fold 12\n",
      "Setting seed to 3907426\n",
      "Epoch 1/20\n",
      "1210/1210 - 63s - 52ms/step - NLL: 1.4211 - accuracy: 0.6016 - f1_score: 0.1336 - loss: 1.6670 - precision: 0.7583 - recall: 0.4490 - val_NLL: 1.3405 - val_accuracy: 0.5890 - val_f1_score: 0.1327 - val_loss: 1.5321 - val_precision: 0.7346 - val_recall: 0.4807\n",
      "Epoch 2/20\n",
      "1210/1210 - 59s - 49ms/step - NLL: 1.1858 - accuracy: 0.6391 - f1_score: 0.2544 - loss: 1.3778 - precision: 0.7901 - recall: 0.5034 - val_NLL: 1.2885 - val_accuracy: 0.6097 - val_f1_score: 0.1586 - val_loss: 1.4796 - val_precision: 0.7223 - val_recall: 0.5204\n",
      "Epoch 3/20\n",
      "1210/1210 - 60s - 50ms/step - NLL: 1.0794 - accuracy: 0.6643 - f1_score: 0.3194 - loss: 1.2729 - precision: 0.8012 - recall: 0.5369 - val_NLL: 1.2513 - val_accuracy: 0.6182 - val_f1_score: 0.1908 - val_loss: 1.4467 - val_precision: 0.7116 - val_recall: 0.5432\n",
      "Epoch 4/20\n",
      "1210/1210 - 61s - 50ms/step - NLL: 1.0234 - accuracy: 0.6796 - f1_score: 0.3639 - loss: 1.2193 - precision: 0.8056 - recall: 0.5572 - val_NLL: 1.1979 - val_accuracy: 0.6345 - val_f1_score: 0.2276 - val_loss: 1.3938 - val_precision: 0.7436 - val_recall: 0.5387\n",
      "Epoch 5/20\n",
      "1210/1210 - 59s - 49ms/step - NLL: 0.9837 - accuracy: 0.6897 - f1_score: 0.3901 - loss: 1.1820 - precision: 0.8104 - recall: 0.5725 - val_NLL: 1.2139 - val_accuracy: 0.6238 - val_f1_score: 0.2107 - val_loss: 1.4130 - val_precision: 0.7227 - val_recall: 0.5354\n",
      "Epoch 6/20\n",
      "1210/1210 - 58s - 48ms/step - NLL: 0.9519 - accuracy: 0.6973 - f1_score: 0.4140 - loss: 1.1531 - precision: 0.8139 - recall: 0.5860 - val_NLL: 1.2602 - val_accuracy: 0.6173 - val_f1_score: 0.2084 - val_loss: 1.4627 - val_precision: 0.7027 - val_recall: 0.5492\n",
      "Epoch 7/20\n",
      "1210/1210 - 59s - 49ms/step - NLL: 0.9266 - accuracy: 0.7043 - f1_score: 0.4306 - loss: 1.1303 - precision: 0.8178 - recall: 0.5974 - val_NLL: 1.2057 - val_accuracy: 0.6269 - val_f1_score: 0.2297 - val_loss: 1.4095 - val_precision: 0.7115 - val_recall: 0.5506\n",
      "Epoch 8/20\n",
      "1210/1210 - 59s - 49ms/step - NLL: 0.9098 - accuracy: 0.7112 - f1_score: 0.4489 - loss: 1.1152 - precision: 0.8190 - recall: 0.6047 - val_NLL: 1.2183 - val_accuracy: 0.6202 - val_f1_score: 0.2220 - val_loss: 1.4242 - val_precision: 0.7258 - val_recall: 0.5361\n",
      "Epoch 9/20\n",
      "1210/1210 - 59s - 49ms/step - NLL: 0.8946 - accuracy: 0.7145 - f1_score: 0.4579 - loss: 1.1015 - precision: 0.8224 - recall: 0.6107 - val_NLL: 1.1638 - val_accuracy: 0.6428 - val_f1_score: 0.2579 - val_loss: 1.3708 - val_precision: 0.7481 - val_recall: 0.5582\n",
      "Epoch 10/20\n",
      "1210/1210 - 60s - 50ms/step - NLL: 0.8832 - accuracy: 0.7157 - f1_score: 0.4635 - loss: 1.0912 - precision: 0.8240 - recall: 0.6165 - val_NLL: 1.1517 - val_accuracy: 0.6419 - val_f1_score: 0.2580 - val_loss: 1.3593 - val_precision: 0.7444 - val_recall: 0.5553\n",
      "Epoch 11/20\n",
      "1210/1210 - 58s - 48ms/step - NLL: 0.8706 - accuracy: 0.7204 - f1_score: 0.4741 - loss: 1.0794 - precision: 0.8250 - recall: 0.6222 - val_NLL: 1.1702 - val_accuracy: 0.6421 - val_f1_score: 0.2652 - val_loss: 1.3792 - val_precision: 0.7406 - val_recall: 0.5577\n",
      "Epoch 12/20\n",
      "1210/1210 - 59s - 49ms/step - NLL: 0.8586 - accuracy: 0.7227 - f1_score: 0.4835 - loss: 1.0695 - precision: 0.8259 - recall: 0.6261 - val_NLL: 1.1274 - val_accuracy: 0.6519 - val_f1_score: 0.2885 - val_loss: 1.3385 - val_precision: 0.7524 - val_recall: 0.5604\n",
      "Epoch 13/20\n",
      "1210/1210 - 59s - 49ms/step - NLL: 0.8526 - accuracy: 0.7244 - f1_score: 0.4824 - loss: 1.0639 - precision: 0.8267 - recall: 0.6288 - val_NLL: 1.1538 - val_accuracy: 0.6452 - val_f1_score: 0.2652 - val_loss: 1.3661 - val_precision: 0.7426 - val_recall: 0.5622\n",
      "Epoch 14/20\n",
      "1210/1210 - 59s - 49ms/step - NLL: 0.8431 - accuracy: 0.7283 - f1_score: 0.4940 - loss: 1.0549 - precision: 0.8282 - recall: 0.6327 - val_NLL: 1.1325 - val_accuracy: 0.6542 - val_f1_score: 0.2989 - val_loss: 1.3449 - val_precision: 0.7333 - val_recall: 0.5820\n",
      "Epoch 15/20\n",
      "1210/1210 - 58s - 48ms/step - NLL: 0.8376 - accuracy: 0.7310 - f1_score: 0.5009 - loss: 1.0491 - precision: 0.8291 - recall: 0.6358 - val_NLL: 1.1469 - val_accuracy: 0.6468 - val_f1_score: 0.2834 - val_loss: 1.3570 - val_precision: 0.7231 - val_recall: 0.5713\n",
      "Epoch 16/20\n",
      "1210/1210 - 58s - 48ms/step - NLL: 0.8317 - accuracy: 0.7311 - f1_score: 0.5017 - loss: 1.0427 - precision: 0.8311 - recall: 0.6388 - val_NLL: 1.1377 - val_accuracy: 0.6562 - val_f1_score: 0.3048 - val_loss: 1.3490 - val_precision: 0.7538 - val_recall: 0.5729\n",
      "Epoch 17/20\n",
      "1210/1210 - 59s - 49ms/step - NLL: 0.8216 - accuracy: 0.7339 - f1_score: 0.5085 - loss: 1.0334 - precision: 0.8316 - recall: 0.6405 - val_NLL: 1.1224 - val_accuracy: 0.6560 - val_f1_score: 0.3043 - val_loss: 1.3345 - val_precision: 0.7491 - val_recall: 0.5653\n",
      "Epoch 18/20\n",
      "1210/1210 - 59s - 49ms/step - NLL: 0.8175 - accuracy: 0.7352 - f1_score: 0.5117 - loss: 1.0301 - precision: 0.8338 - recall: 0.6440 - val_NLL: 1.1454 - val_accuracy: 0.6544 - val_f1_score: 0.2964 - val_loss: 1.3574 - val_precision: 0.7463 - val_recall: 0.5689\n",
      "Epoch 19/20\n",
      "1210/1210 - 60s - 50ms/step - NLL: 0.8154 - accuracy: 0.7363 - f1_score: 0.5133 - loss: 1.0283 - precision: 0.8334 - recall: 0.6443 - val_NLL: 1.1271 - val_accuracy: 0.6544 - val_f1_score: 0.2858 - val_loss: 1.3401 - val_precision: 0.7499 - val_recall: 0.5662\n",
      "Epoch 20/20\n",
      "1210/1210 - 59s - 49ms/step - NLL: 0.8108 - accuracy: 0.7374 - f1_score: 0.5164 - loss: 1.0240 - precision: 0.8354 - recall: 0.6470 - val_NLL: 1.1798 - val_accuracy: 0.6437 - val_f1_score: 0.2626 - val_loss: 1.3939 - val_precision: 0.7316 - val_recall: 0.5695\n",
      "\u001b[1m2419/2419\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11ms/step\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n",
      "NLL: 1.12\n",
      "Validation accuracy: 0.66\n",
      "Validation F1Score: 0.30\n",
      "evaluating Fold 13\n",
      "Setting seed to 9741265\n",
      "Epoch 1/20\n",
      "1224/1224 - 67s - 55ms/step - NLL: 1.4290 - accuracy: 0.5983 - f1_score: 0.1286 - loss: 1.6487 - precision: 0.7598 - recall: 0.4460 - val_NLL: 1.5144 - val_accuracy: 0.5894 - val_f1_score: 0.1040 - val_loss: 1.6846 - val_precision: 0.7736 - val_recall: 0.4607\n",
      "Epoch 2/20\n",
      "1224/1224 - 62s - 50ms/step - NLL: 1.2066 - accuracy: 0.6332 - f1_score: 0.2370 - loss: 1.3833 - precision: 0.7859 - recall: 0.4960 - val_NLL: 1.4251 - val_accuracy: 0.6232 - val_f1_score: 0.1884 - val_loss: 1.6086 - val_precision: 0.7733 - val_recall: 0.5038\n",
      "Epoch 3/20\n",
      "1224/1224 - 62s - 50ms/step - NLL: 1.0861 - accuracy: 0.6621 - f1_score: 0.3142 - loss: 1.2716 - precision: 0.7978 - recall: 0.5342 - val_NLL: 1.3699 - val_accuracy: 0.6425 - val_f1_score: 0.2371 - val_loss: 1.5555 - val_precision: 0.7558 - val_recall: 0.5368\n",
      "Epoch 4/20\n",
      "1224/1224 - 61s - 50ms/step - NLL: 1.0279 - accuracy: 0.6746 - f1_score: 0.3498 - loss: 1.2155 - precision: 0.8045 - recall: 0.5550 - val_NLL: 1.3239 - val_accuracy: 0.6587 - val_f1_score: 0.2566 - val_loss: 1.5115 - val_precision: 0.7685 - val_recall: 0.5664\n",
      "Epoch 5/20\n",
      "1224/1224 - 61s - 50ms/step - NLL: 0.9936 - accuracy: 0.6839 - f1_score: 0.3741 - loss: 1.1842 - precision: 0.8078 - recall: 0.5667 - val_NLL: 1.2577 - val_accuracy: 0.6694 - val_f1_score: 0.2995 - val_loss: 1.4484 - val_precision: 0.7898 - val_recall: 0.5611\n",
      "Epoch 6/20\n",
      "1224/1224 - 62s - 51ms/step - NLL: 0.9639 - accuracy: 0.6926 - f1_score: 0.4009 - loss: 1.1560 - precision: 0.8133 - recall: 0.5793 - val_NLL: 1.3189 - val_accuracy: 0.6618 - val_f1_score: 0.2816 - val_loss: 1.5119 - val_precision: 0.7644 - val_recall: 0.5810\n",
      "Epoch 7/20\n",
      "1224/1224 - 62s - 50ms/step - NLL: 0.9393 - accuracy: 0.6984 - f1_score: 0.4180 - loss: 1.1351 - precision: 0.8153 - recall: 0.5897 - val_NLL: 1.2373 - val_accuracy: 0.6733 - val_f1_score: 0.3138 - val_loss: 1.4356 - val_precision: 0.7872 - val_recall: 0.5754\n",
      "Epoch 8/20\n",
      "1224/1224 - 62s - 51ms/step - NLL: 0.9207 - accuracy: 0.7042 - f1_score: 0.4311 - loss: 1.1193 - precision: 0.8151 - recall: 0.5971 - val_NLL: 1.2124 - val_accuracy: 0.6722 - val_f1_score: 0.3129 - val_loss: 1.4100 - val_precision: 0.7770 - val_recall: 0.5905\n",
      "Epoch 9/20\n",
      "1224/1224 - 62s - 51ms/step - NLL: 0.9054 - accuracy: 0.7075 - f1_score: 0.4410 - loss: 1.1056 - precision: 0.8176 - recall: 0.6034 - val_NLL: 1.1959 - val_accuracy: 0.6792 - val_f1_score: 0.3301 - val_loss: 1.3987 - val_precision: 0.7808 - val_recall: 0.5877\n",
      "Epoch 10/20\n",
      "1224/1224 - 62s - 50ms/step - NLL: 0.8973 - accuracy: 0.7113 - f1_score: 0.4506 - loss: 1.0996 - precision: 0.8193 - recall: 0.6092 - val_NLL: 1.1770 - val_accuracy: 0.6811 - val_f1_score: 0.3290 - val_loss: 1.3788 - val_precision: 0.7856 - val_recall: 0.5936\n",
      "Epoch 11/20\n",
      "1224/1224 - 62s - 51ms/step - NLL: 0.8837 - accuracy: 0.7146 - f1_score: 0.4613 - loss: 1.0871 - precision: 0.8200 - recall: 0.6153 - val_NLL: 1.1895 - val_accuracy: 0.6873 - val_f1_score: 0.3394 - val_loss: 1.3909 - val_precision: 0.7928 - val_recall: 0.5950\n",
      "Epoch 12/20\n",
      "1224/1224 - 60s - 49ms/step - NLL: 0.8754 - accuracy: 0.7169 - f1_score: 0.4678 - loss: 1.0787 - precision: 0.8220 - recall: 0.6180 - val_NLL: 1.1959 - val_accuracy: 0.6755 - val_f1_score: 0.3212 - val_loss: 1.3990 - val_precision: 0.7715 - val_recall: 0.5997\n",
      "Epoch 13/20\n",
      "1224/1224 - 58s - 48ms/step - NLL: 0.8617 - accuracy: 0.7201 - f1_score: 0.4728 - loss: 1.0667 - precision: 0.8228 - recall: 0.6244 - val_NLL: 1.1721 - val_accuracy: 0.6831 - val_f1_score: 0.3465 - val_loss: 1.3757 - val_precision: 0.7875 - val_recall: 0.6022\n",
      "Epoch 14/20\n",
      "1224/1224 - 58s - 47ms/step - NLL: 0.8575 - accuracy: 0.7237 - f1_score: 0.4812 - loss: 1.0629 - precision: 0.8253 - recall: 0.6283 - val_NLL: 1.1528 - val_accuracy: 0.6929 - val_f1_score: 0.3557 - val_loss: 1.3569 - val_precision: 0.7955 - val_recall: 0.6126\n",
      "Epoch 15/20\n",
      "1224/1224 - 58s - 47ms/step - NLL: 0.8494 - accuracy: 0.7250 - f1_score: 0.4878 - loss: 1.0554 - precision: 0.8254 - recall: 0.6302 - val_NLL: 1.1682 - val_accuracy: 0.6920 - val_f1_score: 0.3705 - val_loss: 1.3725 - val_precision: 0.7882 - val_recall: 0.6036\n",
      "Epoch 16/20\n",
      "1224/1224 - 58s - 48ms/step - NLL: 0.8422 - accuracy: 0.7261 - f1_score: 0.4882 - loss: 1.0498 - precision: 0.8264 - recall: 0.6320 - val_NLL: 1.1932 - val_accuracy: 0.6901 - val_f1_score: 0.3457 - val_loss: 1.4012 - val_precision: 0.7759 - val_recall: 0.6218\n",
      "Epoch 17/20\n",
      "1224/1224 - 60s - 49ms/step - NLL: 0.8302 - accuracy: 0.7312 - f1_score: 0.4993 - loss: 1.0396 - precision: 0.8273 - recall: 0.6386 - val_NLL: 1.1650 - val_accuracy: 0.6898 - val_f1_score: 0.3529 - val_loss: 1.3737 - val_precision: 0.7904 - val_recall: 0.6076\n",
      "Epoch 18/20\n",
      "1224/1224 - 59s - 48ms/step - NLL: 0.8256 - accuracy: 0.7321 - f1_score: 0.5037 - loss: 1.0362 - precision: 0.8284 - recall: 0.6386 - val_NLL: 1.1414 - val_accuracy: 0.6923 - val_f1_score: 0.3626 - val_loss: 1.3521 - val_precision: 0.7862 - val_recall: 0.6162\n",
      "Epoch 19/20\n",
      "1224/1224 - 58s - 48ms/step - NLL: 0.8204 - accuracy: 0.7330 - f1_score: 0.5042 - loss: 1.0329 - precision: 0.8302 - recall: 0.6432 - val_NLL: 1.1451 - val_accuracy: 0.6878 - val_f1_score: 0.3602 - val_loss: 1.3554 - val_precision: 0.7903 - val_recall: 0.6137\n",
      "Epoch 20/20\n",
      "1224/1224 - 58s - 48ms/step - NLL: 0.8124 - accuracy: 0.7355 - f1_score: 0.5109 - loss: 1.0245 - precision: 0.8301 - recall: 0.6461 - val_NLL: 1.1341 - val_accuracy: 0.6979 - val_f1_score: 0.3826 - val_loss: 1.3465 - val_precision: 0.7967 - val_recall: 0.6162\n",
      "\u001b[1m2447/2447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "NLL: 1.13\n",
      "Validation accuracy: 0.70\n",
      "Validation F1Score: 0.38\n",
      "evaluating Fold 14\n",
      "Setting seed to 20465670\n",
      "Epoch 1/20\n",
      "1228/1228 - 62s - 50ms/step - NLL: 1.4173 - accuracy: 0.6021 - f1_score: 0.1356 - loss: 1.6466 - precision: 0.7617 - recall: 0.4513 - val_NLL: 1.3177 - val_accuracy: 0.6203 - val_f1_score: 0.1683 - val_loss: 1.5052 - val_precision: 0.7852 - val_recall: 0.4465\n",
      "Epoch 2/20\n",
      "1228/1228 - 59s - 48ms/step - NLL: 1.1715 - accuracy: 0.6424 - f1_score: 0.2642 - loss: 1.3649 - precision: 0.7911 - recall: 0.5068 - val_NLL: 1.2213 - val_accuracy: 0.6363 - val_f1_score: 0.2241 - val_loss: 1.4184 - val_precision: 0.7863 - val_recall: 0.4970\n",
      "Epoch 3/20\n",
      "1228/1228 - 57s - 47ms/step - NLL: 1.0684 - accuracy: 0.6672 - f1_score: 0.3333 - loss: 1.2675 - precision: 0.8024 - recall: 0.5404 - val_NLL: 1.1461 - val_accuracy: 0.6516 - val_f1_score: 0.2692 - val_loss: 1.3473 - val_precision: 0.8009 - val_recall: 0.4997\n",
      "Epoch 4/20\n",
      "1228/1228 - 62s - 50ms/step - NLL: 1.0165 - accuracy: 0.6808 - f1_score: 0.3699 - loss: 1.2167 - precision: 0.8067 - recall: 0.5612 - val_NLL: 1.0846 - val_accuracy: 0.6718 - val_f1_score: 0.3096 - val_loss: 1.2857 - val_precision: 0.8275 - val_recall: 0.5165\n",
      "Epoch 5/20\n",
      "1228/1228 - 58s - 47ms/step - NLL: 0.9777 - accuracy: 0.6916 - f1_score: 0.3976 - loss: 1.1798 - precision: 0.8108 - recall: 0.5763 - val_NLL: 1.0839 - val_accuracy: 0.6643 - val_f1_score: 0.3060 - val_loss: 1.2870 - val_precision: 0.8065 - val_recall: 0.5367\n",
      "Epoch 6/20\n",
      "1228/1228 - 59s - 48ms/step - NLL: 0.9498 - accuracy: 0.6959 - f1_score: 0.4122 - loss: 1.1540 - precision: 0.8121 - recall: 0.5857 - val_NLL: 1.0522 - val_accuracy: 0.6790 - val_f1_score: 0.3291 - val_loss: 1.2592 - val_precision: 0.7996 - val_recall: 0.5665\n",
      "Epoch 7/20\n",
      "1228/1228 - 59s - 48ms/step - NLL: 0.9280 - accuracy: 0.7026 - f1_score: 0.4307 - loss: 1.1337 - precision: 0.8160 - recall: 0.5954 - val_NLL: 1.0381 - val_accuracy: 0.6838 - val_f1_score: 0.3431 - val_loss: 1.2444 - val_precision: 0.8238 - val_recall: 0.5614\n",
      "Epoch 8/20\n",
      "1228/1228 - 63s - 52ms/step - NLL: 0.9118 - accuracy: 0.7089 - f1_score: 0.4449 - loss: 1.1189 - precision: 0.8198 - recall: 0.6028 - val_NLL: 1.0339 - val_accuracy: 0.6865 - val_f1_score: 0.3267 - val_loss: 1.2423 - val_precision: 0.8043 - val_recall: 0.5713\n",
      "Epoch 9/20\n",
      "1228/1228 - 59s - 48ms/step - NLL: 0.8997 - accuracy: 0.7105 - f1_score: 0.4494 - loss: 1.1066 - precision: 0.8193 - recall: 0.6075 - val_NLL: 0.9960 - val_accuracy: 0.6992 - val_f1_score: 0.3612 - val_loss: 1.2022 - val_precision: 0.8329 - val_recall: 0.5758\n",
      "Epoch 10/20\n",
      "1228/1228 - 59s - 48ms/step - NLL: 0.8901 - accuracy: 0.7144 - f1_score: 0.4596 - loss: 1.0963 - precision: 0.8217 - recall: 0.6135 - val_NLL: 1.0015 - val_accuracy: 0.6971 - val_f1_score: 0.3655 - val_loss: 1.2087 - val_precision: 0.8184 - val_recall: 0.5830\n",
      "Epoch 11/20\n",
      "1228/1228 - 61s - 50ms/step - NLL: 0.8771 - accuracy: 0.7168 - f1_score: 0.4640 - loss: 1.0842 - precision: 0.8226 - recall: 0.6181 - val_NLL: 1.0110 - val_accuracy: 0.6974 - val_f1_score: 0.3555 - val_loss: 1.2186 - val_precision: 0.8128 - val_recall: 0.5957\n",
      "Epoch 12/20\n",
      "1228/1228 - 60s - 49ms/step - NLL: 0.8696 - accuracy: 0.7203 - f1_score: 0.4728 - loss: 1.0769 - precision: 0.8259 - recall: 0.6214 - val_NLL: 0.9734 - val_accuracy: 0.7022 - val_f1_score: 0.3633 - val_loss: 1.1803 - val_precision: 0.8271 - val_recall: 0.5960\n",
      "Epoch 13/20\n",
      "1228/1228 - 64s - 52ms/step - NLL: 0.8589 - accuracy: 0.7227 - f1_score: 0.4770 - loss: 1.0670 - precision: 0.8268 - recall: 0.6257 - val_NLL: 0.9779 - val_accuracy: 0.7040 - val_f1_score: 0.3731 - val_loss: 1.1856 - val_precision: 0.8268 - val_recall: 0.5857\n",
      "Epoch 14/20\n",
      "1228/1228 - 68s - 55ms/step - NLL: 0.8524 - accuracy: 0.7241 - f1_score: 0.4816 - loss: 1.0610 - precision: 0.8281 - recall: 0.6290 - val_NLL: 0.9888 - val_accuracy: 0.6995 - val_f1_score: 0.3643 - val_loss: 1.1984 - val_precision: 0.8368 - val_recall: 0.5972\n",
      "Epoch 15/20\n",
      "1228/1228 - 64s - 52ms/step - NLL: 0.8463 - accuracy: 0.7260 - f1_score: 0.4885 - loss: 1.0550 - precision: 0.8276 - recall: 0.6311 - val_NLL: 0.9944 - val_accuracy: 0.6971 - val_f1_score: 0.3558 - val_loss: 1.2032 - val_precision: 0.8146 - val_recall: 0.6002\n",
      "Epoch 16/20\n",
      "1228/1228 - 65s - 53ms/step - NLL: 0.8399 - accuracy: 0.7278 - f1_score: 0.4927 - loss: 1.0492 - precision: 0.8285 - recall: 0.6339 - val_NLL: 0.9858 - val_accuracy: 0.6949 - val_f1_score: 0.3580 - val_loss: 1.1965 - val_precision: 0.8197 - val_recall: 0.6005\n",
      "Epoch 17/20\n",
      "1228/1228 - 64s - 52ms/step - NLL: 0.8316 - accuracy: 0.7288 - f1_score: 0.4941 - loss: 1.0414 - precision: 0.8306 - recall: 0.6378 - val_NLL: 0.9700 - val_accuracy: 0.7169 - val_f1_score: 0.4053 - val_loss: 1.1795 - val_precision: 0.8243 - val_recall: 0.6197\n",
      "Epoch 18/20\n",
      "1228/1228 - 64s - 52ms/step - NLL: 0.8292 - accuracy: 0.7309 - f1_score: 0.4983 - loss: 1.0385 - precision: 0.8299 - recall: 0.6393 - val_NLL: 0.9767 - val_accuracy: 0.7022 - val_f1_score: 0.3672 - val_loss: 1.1868 - val_precision: 0.8180 - val_recall: 0.6002\n",
      "Epoch 19/20\n",
      "1228/1228 - 64s - 52ms/step - NLL: 0.8259 - accuracy: 0.7318 - f1_score: 0.5015 - loss: 1.0357 - precision: 0.8317 - recall: 0.6405 - val_NLL: 0.9886 - val_accuracy: 0.7013 - val_f1_score: 0.3673 - val_loss: 1.1993 - val_precision: 0.8146 - val_recall: 0.5975\n",
      "Epoch 20/20\n",
      "1228/1228 - 65s - 53ms/step - NLL: 0.8211 - accuracy: 0.7342 - f1_score: 0.5075 - loss: 1.0308 - precision: 0.8320 - recall: 0.6426 - val_NLL: 0.9599 - val_accuracy: 0.7067 - val_f1_score: 0.3642 - val_loss: 1.1702 - val_precision: 0.8234 - val_recall: 0.6212\n",
      "\u001b[1m2455/2455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 10ms/step\n",
      "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "NLL: 0.96\n",
      "Validation accuracy: 0.71\n",
      "Validation F1Score: 0.36\n",
      "evaluating Fold 15\n",
      "Setting seed to 80337754\n",
      "Epoch 1/20\n",
      "1227/1227 - 78s - 64ms/step - NLL: 1.4368 - accuracy: 0.6005 - f1_score: 0.1139 - loss: 1.6488 - precision: 0.7591 - recall: 0.4495 - val_NLL: 1.4980 - val_accuracy: 0.5611 - val_f1_score: 0.2079 - val_loss: 1.6651 - val_precision: 0.7642 - val_recall: 0.3880\n",
      "Epoch 2/20\n",
      "1227/1227 - 65s - 53ms/step - NLL: 1.1975 - accuracy: 0.6390 - f1_score: 0.2399 - loss: 1.3735 - precision: 0.7873 - recall: 0.5003 - val_NLL: 1.3259 - val_accuracy: 0.6111 - val_f1_score: 0.3018 - val_loss: 1.5048 - val_precision: 0.7609 - val_recall: 0.4810\n",
      "Epoch 3/20\n",
      "1227/1227 - 65s - 53ms/step - NLL: 1.0854 - accuracy: 0.6642 - f1_score: 0.3102 - loss: 1.2685 - precision: 0.7982 - recall: 0.5363 - val_NLL: 1.2746 - val_accuracy: 0.6224 - val_f1_score: 0.3268 - val_loss: 1.4561 - val_precision: 0.7451 - val_recall: 0.5199\n",
      "Epoch 4/20\n",
      "1227/1227 - 62s - 50ms/step - NLL: 1.0307 - accuracy: 0.6766 - f1_score: 0.3439 - loss: 1.2163 - precision: 0.8063 - recall: 0.5559 - val_NLL: 1.2567 - val_accuracy: 0.6381 - val_f1_score: 0.3656 - val_loss: 1.4412 - val_precision: 0.7455 - val_recall: 0.5323\n",
      "Epoch 5/20\n",
      "1227/1227 - 65s - 53ms/step - NLL: 0.9998 - accuracy: 0.6829 - f1_score: 0.3645 - loss: 1.1872 - precision: 0.8066 - recall: 0.5657 - val_NLL: 1.1994 - val_accuracy: 0.6532 - val_f1_score: 0.3902 - val_loss: 1.3846 - val_precision: 0.7568 - val_recall: 0.5572\n",
      "Epoch 6/20\n",
      "1227/1227 - 65s - 53ms/step - NLL: 0.9724 - accuracy: 0.6929 - f1_score: 0.3908 - loss: 1.1608 - precision: 0.8126 - recall: 0.5792 - val_NLL: 1.1882 - val_accuracy: 0.6544 - val_f1_score: 0.3962 - val_loss: 1.3754 - val_precision: 0.7594 - val_recall: 0.5705\n",
      "Epoch 7/20\n",
      "1227/1227 - 66s - 54ms/step - NLL: 0.9515 - accuracy: 0.6974 - f1_score: 0.4033 - loss: 1.1415 - precision: 0.8143 - recall: 0.5865 - val_NLL: 1.1683 - val_accuracy: 0.6538 - val_f1_score: 0.4127 - val_loss: 1.3573 - val_precision: 0.7448 - val_recall: 0.5699\n",
      "Epoch 8/20\n",
      "1227/1227 - 59s - 48ms/step - NLL: 0.9356 - accuracy: 0.7015 - f1_score: 0.4147 - loss: 1.1275 - precision: 0.8171 - recall: 0.5919 - val_NLL: 1.1488 - val_accuracy: 0.6692 - val_f1_score: 0.4259 - val_loss: 1.3413 - val_precision: 0.7648 - val_recall: 0.5842\n",
      "Epoch 9/20\n",
      "1227/1227 - 62s - 51ms/step - NLL: 0.9205 - accuracy: 0.7055 - f1_score: 0.4267 - loss: 1.1143 - precision: 0.8188 - recall: 0.5988 - val_NLL: 1.1267 - val_accuracy: 0.6755 - val_f1_score: 0.4472 - val_loss: 1.3192 - val_precision: 0.7658 - val_recall: 0.5833\n",
      "Epoch 10/20\n",
      "1227/1227 - 60s - 49ms/step - NLL: 0.9035 - accuracy: 0.7101 - f1_score: 0.4386 - loss: 1.0983 - precision: 0.8212 - recall: 0.6068 - val_NLL: 1.1225 - val_accuracy: 0.6689 - val_f1_score: 0.4442 - val_loss: 1.3170 - val_precision: 0.7607 - val_recall: 0.5777\n",
      "Epoch 11/20\n",
      "1227/1227 - 60s - 49ms/step - NLL: 0.8950 - accuracy: 0.7128 - f1_score: 0.4457 - loss: 1.0912 - precision: 0.8233 - recall: 0.6095 - val_NLL: 1.1027 - val_accuracy: 0.6722 - val_f1_score: 0.4603 - val_loss: 1.2993 - val_precision: 0.7703 - val_recall: 0.5984\n",
      "Epoch 12/20\n",
      "1227/1227 - 59s - 48ms/step - NLL: 0.8850 - accuracy: 0.7169 - f1_score: 0.4581 - loss: 1.0820 - precision: 0.8234 - recall: 0.6136 - val_NLL: 1.0637 - val_accuracy: 0.6864 - val_f1_score: 0.4688 - val_loss: 1.2593 - val_precision: 0.7820 - val_recall: 0.6040\n",
      "Epoch 13/20\n",
      "1227/1227 - 61s - 50ms/step - NLL: 0.8770 - accuracy: 0.7183 - f1_score: 0.4619 - loss: 1.0746 - precision: 0.8242 - recall: 0.6181 - val_NLL: 1.0750 - val_accuracy: 0.6835 - val_f1_score: 0.4662 - val_loss: 1.2731 - val_precision: 0.7695 - val_recall: 0.6135\n",
      "Epoch 14/20\n",
      "1227/1227 - 65s - 53ms/step - NLL: 0.8651 - accuracy: 0.7216 - f1_score: 0.4714 - loss: 1.0638 - precision: 0.8262 - recall: 0.6230 - val_NLL: 1.0839 - val_accuracy: 0.6882 - val_f1_score: 0.4841 - val_loss: 1.2838 - val_precision: 0.7749 - val_recall: 0.6153\n",
      "Epoch 15/20\n",
      "1227/1227 - 60s - 49ms/step - NLL: 0.8585 - accuracy: 0.7233 - f1_score: 0.4759 - loss: 1.0569 - precision: 0.8276 - recall: 0.6265 - val_NLL: 1.0640 - val_accuracy: 0.6838 - val_f1_score: 0.4816 - val_loss: 1.2627 - val_precision: 0.7722 - val_recall: 0.6200\n",
      "Epoch 16/20\n",
      "1227/1227 - 61s - 50ms/step - NLL: 0.8518 - accuracy: 0.7257 - f1_score: 0.4818 - loss: 1.0511 - precision: 0.8283 - recall: 0.6306 - val_NLL: 1.0154 - val_accuracy: 0.6841 - val_f1_score: 0.4844 - val_loss: 1.2148 - val_precision: 0.7890 - val_recall: 0.5928\n",
      "Epoch 17/20\n",
      "1227/1227 - 60s - 49ms/step - NLL: 0.8444 - accuracy: 0.7277 - f1_score: 0.4855 - loss: 1.0451 - precision: 0.8282 - recall: 0.6313 - val_NLL: 1.0409 - val_accuracy: 0.6846 - val_f1_score: 0.4703 - val_loss: 1.2412 - val_precision: 0.7756 - val_recall: 0.6117\n",
      "Epoch 18/20\n",
      "1227/1227 - 60s - 49ms/step - NLL: 0.8381 - accuracy: 0.7293 - f1_score: 0.4897 - loss: 1.0399 - precision: 0.8295 - recall: 0.6355 - val_NLL: 1.0453 - val_accuracy: 0.6891 - val_f1_score: 0.5023 - val_loss: 1.2472 - val_precision: 0.7810 - val_recall: 0.6215\n",
      "Epoch 19/20\n",
      "1227/1227 - 66s - 53ms/step - NLL: 0.8339 - accuracy: 0.7309 - f1_score: 0.4948 - loss: 1.0362 - precision: 0.8316 - recall: 0.6382 - val_NLL: 1.0420 - val_accuracy: 0.6906 - val_f1_score: 0.4840 - val_loss: 1.2433 - val_precision: 0.7813 - val_recall: 0.6215\n",
      "Epoch 20/20\n",
      "1227/1227 - 64s - 52ms/step - NLL: 0.8287 - accuracy: 0.7312 - f1_score: 0.4951 - loss: 1.0310 - precision: 0.8323 - recall: 0.6384 - val_NLL: 1.0232 - val_accuracy: 0.6947 - val_f1_score: 0.5008 - val_loss: 1.2259 - val_precision: 0.7873 - val_recall: 0.6221\n",
      "\u001b[1m2453/2453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 11ms/step\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step\n",
      "NLL: 1.02\n",
      "Validation accuracy: 0.68\n",
      "Validation F1Score: 0.48\n",
      "evaluating Fold 16\n",
      "Setting seed to 123456789\n",
      "Epoch 1/20\n",
      "1231/1231 - 81s - 65ms/step - NLL: 1.4324 - accuracy: 0.5994 - f1_score: 0.1261 - loss: 1.6586 - precision: 0.7551 - recall: 0.4444 - val_NLL: 1.3765 - val_accuracy: 0.6085 - val_f1_score: 0.1594 - val_loss: 1.5562 - val_precision: 0.8026 - val_recall: 0.4516\n",
      "Epoch 2/20\n",
      "1231/1231 - 61s - 50ms/step - NLL: 1.1822 - accuracy: 0.6387 - f1_score: 0.2513 - loss: 1.3645 - precision: 0.7891 - recall: 0.5010 - val_NLL: 1.2179 - val_accuracy: 0.6401 - val_f1_score: 0.2514 - val_loss: 1.4150 - val_precision: 0.7952 - val_recall: 0.5291\n",
      "Epoch 3/20\n",
      "1231/1231 - 59s - 48ms/step - NLL: 1.0858 - accuracy: 0.6617 - f1_score: 0.3120 - loss: 1.2723 - precision: 0.7968 - recall: 0.5317 - val_NLL: 1.1971 - val_accuracy: 0.6527 - val_f1_score: 0.2784 - val_loss: 1.3963 - val_precision: 0.7852 - val_recall: 0.5665\n",
      "Epoch 4/20\n",
      "1231/1231 - 63s - 51ms/step - NLL: 1.0326 - accuracy: 0.6743 - f1_score: 0.3449 - loss: 1.2209 - precision: 0.8043 - recall: 0.5526 - val_NLL: 1.1174 - val_accuracy: 0.6669 - val_f1_score: 0.3017 - val_loss: 1.3172 - val_precision: 0.7803 - val_recall: 0.5917\n",
      "Epoch 5/20\n",
      "1231/1231 - 60s - 49ms/step - NLL: 0.9951 - accuracy: 0.6838 - f1_score: 0.3689 - loss: 1.1847 - precision: 0.8103 - recall: 0.5679 - val_NLL: 1.1238 - val_accuracy: 0.6669 - val_f1_score: 0.3004 - val_loss: 1.3261 - val_precision: 0.7802 - val_recall: 0.5968\n",
      "Epoch 6/20\n",
      "1231/1231 - 59s - 48ms/step - NLL: 0.9725 - accuracy: 0.6907 - f1_score: 0.3856 - loss: 1.1649 - precision: 0.8133 - recall: 0.5756 - val_NLL: 1.1008 - val_accuracy: 0.6808 - val_f1_score: 0.3457 - val_loss: 1.3069 - val_precision: 0.7914 - val_recall: 0.6014\n",
      "Epoch 7/20\n",
      "1231/1231 - 59s - 48ms/step - NLL: 0.9494 - accuracy: 0.6974 - f1_score: 0.4075 - loss: 1.1427 - precision: 0.8161 - recall: 0.5866 - val_NLL: 1.0742 - val_accuracy: 0.6917 - val_f1_score: 0.3747 - val_loss: 1.2826 - val_precision: 0.7892 - val_recall: 0.6294\n",
      "Epoch 8/20\n",
      "1231/1231 - 63s - 51ms/step - NLL: 0.9311 - accuracy: 0.7019 - f1_score: 0.4218 - loss: 1.1269 - precision: 0.8188 - recall: 0.5933 - val_NLL: 1.0794 - val_accuracy: 0.6908 - val_f1_score: 0.3678 - val_loss: 1.2911 - val_precision: 0.7946 - val_recall: 0.6320\n",
      "Epoch 9/20\n",
      "1231/1231 - 66s - 54ms/step - NLL: 0.9165 - accuracy: 0.7055 - f1_score: 0.4331 - loss: 1.1154 - precision: 0.8191 - recall: 0.5994 - val_NLL: 1.0736 - val_accuracy: 0.6892 - val_f1_score: 0.3811 - val_loss: 1.2889 - val_precision: 0.7902 - val_recall: 0.6152\n",
      "Epoch 10/20\n",
      "1231/1231 - 62s - 50ms/step - NLL: 0.9049 - accuracy: 0.7084 - f1_score: 0.4365 - loss: 1.1055 - precision: 0.8216 - recall: 0.6042 - val_NLL: 1.0537 - val_accuracy: 0.6866 - val_f1_score: 0.3598 - val_loss: 1.2679 - val_precision: 0.7842 - val_recall: 0.6275\n",
      "Epoch 11/20\n",
      "1231/1231 - 60s - 48ms/step - NLL: 0.8943 - accuracy: 0.7125 - f1_score: 0.4499 - loss: 1.0962 - precision: 0.8221 - recall: 0.6088 - val_NLL: 1.0667 - val_accuracy: 0.6934 - val_f1_score: 0.3888 - val_loss: 1.2866 - val_precision: 0.7861 - val_recall: 0.6262\n",
      "Epoch 12/20\n",
      "1231/1231 - 60s - 48ms/step - NLL: 0.8817 - accuracy: 0.7149 - f1_score: 0.4563 - loss: 1.0855 - precision: 0.8226 - recall: 0.6134 - val_NLL: 1.0676 - val_accuracy: 0.6911 - val_f1_score: 0.3743 - val_loss: 1.2896 - val_precision: 0.7927 - val_recall: 0.6281\n",
      "Epoch 13/20\n",
      "1231/1231 - 59s - 48ms/step - NLL: 0.8740 - accuracy: 0.7178 - f1_score: 0.4641 - loss: 1.0793 - precision: 0.8234 - recall: 0.6176 - val_NLL: 1.0538 - val_accuracy: 0.6937 - val_f1_score: 0.3794 - val_loss: 1.2767 - val_precision: 0.7871 - val_recall: 0.6288\n",
      "Epoch 14/20\n",
      "1231/1231 - 59s - 48ms/step - NLL: 0.8667 - accuracy: 0.7184 - f1_score: 0.4637 - loss: 1.0726 - precision: 0.8248 - recall: 0.6208 - val_NLL: 1.0263 - val_accuracy: 0.7046 - val_f1_score: 0.3940 - val_loss: 1.2498 - val_precision: 0.7901 - val_recall: 0.6536\n",
      "Epoch 15/20\n",
      "1231/1231 - 59s - 48ms/step - NLL: 0.8579 - accuracy: 0.7234 - f1_score: 0.4787 - loss: 1.0637 - precision: 0.8279 - recall: 0.6261 - val_NLL: 1.0387 - val_accuracy: 0.6982 - val_f1_score: 0.3956 - val_loss: 1.2613 - val_precision: 0.7778 - val_recall: 0.6440\n",
      "Epoch 16/20\n",
      "1231/1231 - 59s - 48ms/step - NLL: 0.8532 - accuracy: 0.7245 - f1_score: 0.4805 - loss: 1.0602 - precision: 0.8283 - recall: 0.6277 - val_NLL: 1.0331 - val_accuracy: 0.7072 - val_f1_score: 0.3933 - val_loss: 1.2606 - val_precision: 0.7967 - val_recall: 0.6630\n",
      "Epoch 17/20\n",
      "1231/1231 - 59s - 48ms/step - NLL: 0.8493 - accuracy: 0.7259 - f1_score: 0.4872 - loss: 1.0567 - precision: 0.8285 - recall: 0.6285 - val_NLL: 1.0321 - val_accuracy: 0.7014 - val_f1_score: 0.3918 - val_loss: 1.2584 - val_precision: 0.7816 - val_recall: 0.6536\n",
      "Epoch 18/20\n",
      "1231/1231 - 59s - 48ms/step - NLL: 0.8397 - accuracy: 0.7268 - f1_score: 0.4885 - loss: 1.0486 - precision: 0.8293 - recall: 0.6330 - val_NLL: 1.0450 - val_accuracy: 0.6975 - val_f1_score: 0.3948 - val_loss: 1.2709 - val_precision: 0.7834 - val_recall: 0.6540\n",
      "Epoch 19/20\n",
      "1231/1231 - 61s - 50ms/step - NLL: 0.8356 - accuracy: 0.7291 - f1_score: 0.4931 - loss: 1.0453 - precision: 0.8321 - recall: 0.6361 - val_NLL: 0.9910 - val_accuracy: 0.7127 - val_f1_score: 0.4235 - val_loss: 1.2175 - val_precision: 0.8022 - val_recall: 0.6585\n",
      "Epoch 20/20\n",
      "1231/1231 - 64s - 52ms/step - NLL: 0.8316 - accuracy: 0.7296 - f1_score: 0.4963 - loss: 1.0430 - precision: 0.8304 - recall: 0.6369 - val_NLL: 0.9874 - val_accuracy: 0.7121 - val_f1_score: 0.4098 - val_loss: 1.2143 - val_precision: 0.7869 - val_recall: 0.6627\n",
      "\u001b[1m2462/2462\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 21ms/step\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step\n",
      "NLL: 0.99\n",
      "Validation accuracy: 0.71\n",
      "Validation F1Score: 0.41\n",
      "evaluating Fold 17\n",
      "Setting seed to 966726221\n",
      "Epoch 1/20\n",
      "1227/1227 - 129s - 105ms/step - NLL: 1.4013 - accuracy: 0.6022 - f1_score: 0.1359 - loss: 1.6211 - precision: 0.7615 - recall: 0.4514 - val_NLL: 1.4953 - val_accuracy: 0.5843 - val_f1_score: 0.1303 - val_loss: 1.6671 - val_precision: 0.7562 - val_recall: 0.4228\n",
      "Epoch 2/20\n",
      "1227/1227 - 133s - 108ms/step - NLL: 1.1777 - accuracy: 0.6414 - f1_score: 0.2549 - loss: 1.3563 - precision: 0.7927 - recall: 0.5011 - val_NLL: 1.3824 - val_accuracy: 0.6098 - val_f1_score: 0.2164 - val_loss: 1.5583 - val_precision: 0.7823 - val_recall: 0.4418\n",
      "Epoch 3/20\n",
      "1227/1227 - 99s - 81ms/step - NLL: 1.0894 - accuracy: 0.6606 - f1_score: 0.3111 - loss: 1.2719 - precision: 0.8018 - recall: 0.5319 - val_NLL: 1.3385 - val_accuracy: 0.6204 - val_f1_score: 0.2462 - val_loss: 1.5169 - val_precision: 0.7851 - val_recall: 0.4471\n",
      "Epoch 4/20\n",
      "1227/1227 - 63s - 51ms/step - NLL: 1.0410 - accuracy: 0.6745 - f1_score: 0.3439 - loss: 1.2254 - precision: 0.8064 - recall: 0.5493 - val_NLL: 1.3283 - val_accuracy: 0.6234 - val_f1_score: 0.2642 - val_loss: 1.5081 - val_precision: 0.7790 - val_recall: 0.4836\n",
      "Epoch 5/20\n",
      "1227/1227 - 60s - 49ms/step - NLL: 1.0082 - accuracy: 0.6819 - f1_score: 0.3664 - loss: 1.1954 - precision: 0.8103 - recall: 0.5598 - val_NLL: 1.3056 - val_accuracy: 0.6382 - val_f1_score: 0.2891 - val_loss: 1.4871 - val_precision: 0.7657 - val_recall: 0.5093\n",
      "Epoch 6/20\n",
      "1227/1227 - 61s - 50ms/step - NLL: 0.9837 - accuracy: 0.6878 - f1_score: 0.3842 - loss: 1.1718 - precision: 0.8127 - recall: 0.5698 - val_NLL: 1.3110 - val_accuracy: 0.6314 - val_f1_score: 0.2793 - val_loss: 1.4948 - val_precision: 0.7661 - val_recall: 0.5191\n",
      "Epoch 7/20\n",
      "1227/1227 - 60s - 49ms/step - NLL: 0.9619 - accuracy: 0.6937 - f1_score: 0.4027 - loss: 1.1515 - precision: 0.8144 - recall: 0.5782 - val_NLL: 1.2653 - val_accuracy: 0.6468 - val_f1_score: 0.3107 - val_loss: 1.4510 - val_precision: 0.7690 - val_recall: 0.5327\n",
      "Epoch 8/20\n",
      "1227/1227 - 61s - 49ms/step - NLL: 0.9446 - accuracy: 0.6994 - f1_score: 0.4131 - loss: 1.1368 - precision: 0.8190 - recall: 0.5882 - val_NLL: 1.2862 - val_accuracy: 0.6441 - val_f1_score: 0.3188 - val_loss: 1.4739 - val_precision: 0.7647 - val_recall: 0.5268\n",
      "Epoch 9/20\n",
      "1227/1227 - 68s - 55ms/step - NLL: 0.9313 - accuracy: 0.7019 - f1_score: 0.4232 - loss: 1.1251 - precision: 0.8197 - recall: 0.5912 - val_NLL: 1.2540 - val_accuracy: 0.6530 - val_f1_score: 0.3297 - val_loss: 1.4442 - val_precision: 0.7675 - val_recall: 0.5479\n",
      "Epoch 10/20\n",
      "1227/1227 - 130s - 106ms/step - NLL: 0.9138 - accuracy: 0.7081 - f1_score: 0.4411 - loss: 1.1090 - precision: 0.8213 - recall: 0.6004 - val_NLL: 1.2459 - val_accuracy: 0.6521 - val_f1_score: 0.3329 - val_loss: 1.4376 - val_precision: 0.7629 - val_recall: 0.5490\n",
      "Epoch 11/20\n",
      "1227/1227 - 118s - 96ms/step - NLL: 0.9062 - accuracy: 0.7101 - f1_score: 0.4435 - loss: 1.1033 - precision: 0.8219 - recall: 0.6031 - val_NLL: 1.2050 - val_accuracy: 0.6590 - val_f1_score: 0.3293 - val_loss: 1.3977 - val_precision: 0.7721 - val_recall: 0.5461\n",
      "Epoch 12/20\n",
      "1227/1227 - 144s - 117ms/step - NLL: 0.8950 - accuracy: 0.7124 - f1_score: 0.4503 - loss: 1.0934 - precision: 0.8219 - recall: 0.6078 - val_NLL: 1.2497 - val_accuracy: 0.6566 - val_f1_score: 0.3513 - val_loss: 1.4431 - val_precision: 0.7566 - val_recall: 0.5627\n",
      "Epoch 13/20\n",
      "1227/1227 - 137s - 111ms/step - NLL: 0.8872 - accuracy: 0.7150 - f1_score: 0.4588 - loss: 1.0868 - precision: 0.8249 - recall: 0.6128 - val_NLL: 1.1945 - val_accuracy: 0.6569 - val_f1_score: 0.3666 - val_loss: 1.3898 - val_precision: 0.7769 - val_recall: 0.5550\n",
      "Epoch 14/20\n",
      "1227/1227 - 115s - 94ms/step - NLL: 0.8762 - accuracy: 0.7178 - f1_score: 0.4655 - loss: 1.0769 - precision: 0.8254 - recall: 0.6172 - val_NLL: 1.2002 - val_accuracy: 0.6578 - val_f1_score: 0.3550 - val_loss: 1.3957 - val_precision: 0.7556 - val_recall: 0.5606\n",
      "Epoch 15/20\n",
      "1227/1227 - 110s - 89ms/step - NLL: 0.8657 - accuracy: 0.7201 - f1_score: 0.4708 - loss: 1.0676 - precision: 0.8256 - recall: 0.6201 - val_NLL: 1.2300 - val_accuracy: 0.6551 - val_f1_score: 0.3587 - val_loss: 1.4266 - val_precision: 0.7448 - val_recall: 0.5733\n",
      "Epoch 16/20\n",
      "1227/1227 - 140s - 114ms/step - NLL: 0.8576 - accuracy: 0.7227 - f1_score: 0.4800 - loss: 1.0609 - precision: 0.8280 - recall: 0.6238 - val_NLL: 1.2277 - val_accuracy: 0.6569 - val_f1_score: 0.3689 - val_loss: 1.4262 - val_precision: 0.7605 - val_recall: 0.5653\n",
      "Epoch 17/20\n",
      "1227/1227 - 110s - 90ms/step - NLL: 0.8498 - accuracy: 0.7235 - f1_score: 0.4800 - loss: 1.0539 - precision: 0.8283 - recall: 0.6280 - val_NLL: 1.2293 - val_accuracy: 0.6619 - val_f1_score: 0.3814 - val_loss: 1.4294 - val_precision: 0.7565 - val_recall: 0.5716\n",
      "Epoch 18/20\n",
      "1227/1227 - 111s - 90ms/step - NLL: 0.8418 - accuracy: 0.7265 - f1_score: 0.4868 - loss: 1.0476 - precision: 0.8293 - recall: 0.6313 - val_NLL: 1.2334 - val_accuracy: 0.6673 - val_f1_score: 0.3704 - val_loss: 1.4336 - val_precision: 0.7593 - val_recall: 0.5730\n",
      "Epoch 19/20\n",
      "1227/1227 - 139s - 113ms/step - NLL: 0.8366 - accuracy: 0.7286 - f1_score: 0.4938 - loss: 1.0424 - precision: 0.8315 - recall: 0.6346 - val_NLL: 1.2209 - val_accuracy: 0.6622 - val_f1_score: 0.3760 - val_loss: 1.4217 - val_precision: 0.7629 - val_recall: 0.5710\n",
      "Epoch 20/20\n",
      "1227/1227 - 104s - 85ms/step - NLL: 0.8309 - accuracy: 0.7302 - f1_score: 0.4980 - loss: 1.0376 - precision: 0.8322 - recall: 0.6363 - val_NLL: 1.2171 - val_accuracy: 0.6596 - val_f1_score: 0.3569 - val_loss: 1.4189 - val_precision: 0.7462 - val_recall: 0.5801\n",
      "\u001b[1m2453/2453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 36ms/step\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "NLL: 1.19\n",
      "Validation accuracy: 0.66\n",
      "Validation F1Score: 0.37\n",
      "evaluating Fold 18\n",
      "Setting seed to 1625494306\n",
      "Epoch 1/20\n",
      "1236/1236 - 138s - 111ms/step - NLL: 1.4282 - accuracy: 0.6000 - f1_score: 0.1302 - loss: 1.6483 - precision: 0.7548 - recall: 0.4491 - val_NLL: 1.2965 - val_accuracy: 0.6161 - val_f1_score: 0.1254 - val_loss: 1.4750 - val_precision: 0.7684 - val_recall: 0.4781\n",
      "Epoch 2/20\n",
      "1236/1236 - 117s - 95ms/step - NLL: 1.1980 - accuracy: 0.6358 - f1_score: 0.2421 - loss: 1.3791 - precision: 0.7845 - recall: 0.5001 - val_NLL: 1.1482 - val_accuracy: 0.6563 - val_f1_score: 0.2421 - val_loss: 1.3364 - val_precision: 0.7971 - val_recall: 0.5168\n",
      "Epoch 3/20\n",
      "1236/1236 - 143s - 115ms/step - NLL: 1.0909 - accuracy: 0.6615 - f1_score: 0.3094 - loss: 1.2819 - precision: 0.7957 - recall: 0.5352 - val_NLL: 1.1141 - val_accuracy: 0.6581 - val_f1_score: 0.2497 - val_loss: 1.3040 - val_precision: 0.7835 - val_recall: 0.5616\n",
      "Epoch 4/20\n",
      "1236/1236 - 107s - 87ms/step - NLL: 1.0354 - accuracy: 0.6756 - f1_score: 0.3493 - loss: 1.2288 - precision: 0.8052 - recall: 0.5534 - val_NLL: 1.0394 - val_accuracy: 0.6763 - val_f1_score: 0.2964 - val_loss: 1.2319 - val_precision: 0.7806 - val_recall: 0.5789\n",
      "Epoch 5/20\n",
      "1236/1236 - 121s - 98ms/step - NLL: 0.9996 - accuracy: 0.6843 - f1_score: 0.3723 - loss: 1.1947 - precision: 0.8088 - recall: 0.5662 - val_NLL: 1.0112 - val_accuracy: 0.6821 - val_f1_score: 0.3057 - val_loss: 1.2058 - val_precision: 0.7900 - val_recall: 0.6029\n",
      "Epoch 6/20\n",
      "1236/1236 - 127s - 103ms/step - NLL: 0.9708 - accuracy: 0.6914 - f1_score: 0.3943 - loss: 1.1680 - precision: 0.8107 - recall: 0.5762 - val_NLL: 1.0121 - val_accuracy: 0.6713 - val_f1_score: 0.3037 - val_loss: 1.2094 - val_precision: 0.7869 - val_recall: 0.5835\n",
      "Epoch 7/20\n",
      "1236/1236 - 110s - 89ms/step - NLL: 0.9490 - accuracy: 0.6958 - f1_score: 0.4039 - loss: 1.1475 - precision: 0.8140 - recall: 0.5876 - val_NLL: 0.9869 - val_accuracy: 0.6821 - val_f1_score: 0.3288 - val_loss: 1.1854 - val_precision: 0.8029 - val_recall: 0.5914\n",
      "Epoch 8/20\n",
      "1236/1236 - 130s - 105ms/step - NLL: 0.9321 - accuracy: 0.7016 - f1_score: 0.4182 - loss: 1.1315 - precision: 0.8159 - recall: 0.5944 - val_NLL: 0.9502 - val_accuracy: 0.6953 - val_f1_score: 0.3438 - val_loss: 1.1490 - val_precision: 0.8008 - val_recall: 0.6111\n",
      "Epoch 9/20\n",
      "1236/1236 - 107s - 87ms/step - NLL: 0.9145 - accuracy: 0.7055 - f1_score: 0.4310 - loss: 1.1144 - precision: 0.8195 - recall: 0.6006 - val_NLL: 0.9379 - val_accuracy: 0.6950 - val_f1_score: 0.3658 - val_loss: 1.1387 - val_precision: 0.7996 - val_recall: 0.6108\n",
      "Epoch 10/20\n",
      "1236/1236 - 113s - 92ms/step - NLL: 0.9050 - accuracy: 0.7090 - f1_score: 0.4402 - loss: 1.1064 - precision: 0.8196 - recall: 0.6034 - val_NLL: 0.9144 - val_accuracy: 0.6928 - val_f1_score: 0.3666 - val_loss: 1.1165 - val_precision: 0.7949 - val_recall: 0.6111\n",
      "Epoch 11/20\n",
      "1236/1236 - 132s - 107ms/step - NLL: 0.8927 - accuracy: 0.7129 - f1_score: 0.4501 - loss: 1.0947 - precision: 0.8225 - recall: 0.6103 - val_NLL: 0.9334 - val_accuracy: 0.6846 - val_f1_score: 0.3498 - val_loss: 1.1359 - val_precision: 0.7952 - val_recall: 0.6136\n",
      "Epoch 12/20\n",
      "1236/1236 - 97s - 78ms/step - NLL: 0.8840 - accuracy: 0.7148 - f1_score: 0.4557 - loss: 1.0866 - precision: 0.8239 - recall: 0.6129 - val_NLL: 0.9340 - val_accuracy: 0.6896 - val_f1_score: 0.3578 - val_loss: 1.1377 - val_precision: 0.7954 - val_recall: 0.6061\n",
      "Epoch 13/20\n",
      "1236/1236 - 132s - 106ms/step - NLL: 0.8760 - accuracy: 0.7174 - f1_score: 0.4602 - loss: 1.0798 - precision: 0.8249 - recall: 0.6177 - val_NLL: 0.8968 - val_accuracy: 0.7036 - val_f1_score: 0.3770 - val_loss: 1.1010 - val_precision: 0.7946 - val_recall: 0.6294\n",
      "Epoch 14/20\n",
      "1236/1236 - 107s - 87ms/step - NLL: 0.8670 - accuracy: 0.7209 - f1_score: 0.4691 - loss: 1.0715 - precision: 0.8274 - recall: 0.6225 - val_NLL: 0.9277 - val_accuracy: 0.6932 - val_f1_score: 0.3576 - val_loss: 1.1331 - val_precision: 0.7966 - val_recall: 0.6147\n",
      "Epoch 15/20\n",
      "1236/1236 - 130s - 105ms/step - NLL: 0.8582 - accuracy: 0.7214 - f1_score: 0.4745 - loss: 1.0645 - precision: 0.8274 - recall: 0.6240 - val_NLL: 0.9280 - val_accuracy: 0.7000 - val_f1_score: 0.3785 - val_loss: 1.1359 - val_precision: 0.7826 - val_recall: 0.6348\n",
      "Epoch 16/20\n",
      "1236/1236 - 114s - 92ms/step - NLL: 0.8525 - accuracy: 0.7236 - f1_score: 0.4781 - loss: 1.0585 - precision: 0.8289 - recall: 0.6275 - val_NLL: 0.9398 - val_accuracy: 0.7050 - val_f1_score: 0.4011 - val_loss: 1.1486 - val_precision: 0.7814 - val_recall: 0.6405\n",
      "Epoch 17/20\n",
      "1236/1236 - 106s - 86ms/step - NLL: 0.8446 - accuracy: 0.7270 - f1_score: 0.4858 - loss: 1.0512 - precision: 0.8291 - recall: 0.6306 - val_NLL: 0.9014 - val_accuracy: 0.7068 - val_f1_score: 0.3929 - val_loss: 1.1108 - val_precision: 0.7979 - val_recall: 0.6240\n",
      "Epoch 18/20\n",
      "1236/1236 - 136s - 110ms/step - NLL: 0.8399 - accuracy: 0.7268 - f1_score: 0.4866 - loss: 1.0460 - precision: 0.8292 - recall: 0.6334 - val_NLL: 0.8939 - val_accuracy: 0.6989 - val_f1_score: 0.3905 - val_loss: 1.1024 - val_precision: 0.7984 - val_recall: 0.6176\n",
      "Epoch 19/20\n",
      "1236/1236 - 74s - 60ms/step - NLL: 0.8384 - accuracy: 0.7275 - f1_score: 0.4880 - loss: 1.0454 - precision: 0.8300 - recall: 0.6342 - val_NLL: 0.8975 - val_accuracy: 0.7032 - val_f1_score: 0.3973 - val_loss: 1.1057 - val_precision: 0.7876 - val_recall: 0.6380\n",
      "Epoch 20/20\n",
      "1236/1236 - 59s - 47ms/step - NLL: 0.8321 - accuracy: 0.7302 - f1_score: 0.4941 - loss: 1.0390 - precision: 0.8312 - recall: 0.6363 - val_NLL: 0.9143 - val_accuracy: 0.7004 - val_f1_score: 0.4019 - val_loss: 1.1223 - val_precision: 0.7800 - val_recall: 0.6330\n",
      "\u001b[1m2472/2472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "NLL: 0.89\n",
      "Validation accuracy: 0.70\n",
      "Validation F1Score: 0.39\n",
      "evaluating Fold 19\n",
      "Setting seed to 3063573539\n",
      "Epoch 1/20\n",
      "1188/1188 - 62s - 52ms/step - NLL: 1.4436 - accuracy: 0.5969 - f1_score: 0.1174 - loss: 1.6636 - precision: 0.7592 - recall: 0.4437 - val_NLL: 1.3046 - val_accuracy: 0.6216 - val_f1_score: 0.1902 - val_loss: 1.4721 - val_precision: 0.7888 - val_recall: 0.3550\n",
      "Epoch 2/20\n",
      "1188/1188 - 57s - 48ms/step - NLL: 1.2333 - accuracy: 0.6261 - f1_score: 0.2173 - loss: 1.4014 - precision: 0.7893 - recall: 0.4848 - val_NLL: 1.1535 - val_accuracy: 0.6522 - val_f1_score: 0.2481 - val_loss: 1.3324 - val_precision: 0.7844 - val_recall: 0.4540\n",
      "Epoch 3/20\n",
      "1188/1188 - 58s - 49ms/step - NLL: 1.1290 - accuracy: 0.6498 - f1_score: 0.2852 - loss: 1.3059 - precision: 0.8007 - recall: 0.5178 - val_NLL: 1.0889 - val_accuracy: 0.6720 - val_f1_score: 0.3071 - val_loss: 1.2736 - val_precision: 0.8125 - val_recall: 0.4828\n",
      "Epoch 4/20\n",
      "1188/1188 - 57s - 48ms/step - NLL: 1.0695 - accuracy: 0.6664 - f1_score: 0.3268 - loss: 1.2522 - precision: 0.8090 - recall: 0.5383 - val_NLL: 1.0098 - val_accuracy: 0.6909 - val_f1_score: 0.3369 - val_loss: 1.1977 - val_precision: 0.7976 - val_recall: 0.5373\n",
      "Epoch 5/20\n",
      "1188/1188 - 57s - 48ms/step - NLL: 1.0301 - accuracy: 0.6749 - f1_score: 0.3549 - loss: 1.2171 - precision: 0.8112 - recall: 0.5531 - val_NLL: 1.0098 - val_accuracy: 0.6948 - val_f1_score: 0.3479 - val_loss: 1.2013 - val_precision: 0.8084 - val_recall: 0.5272\n",
      "Epoch 6/20\n",
      "1188/1188 - 57s - 48ms/step - NLL: 0.9971 - accuracy: 0.6832 - f1_score: 0.3784 - loss: 1.1883 - precision: 0.8131 - recall: 0.5643 - val_NLL: 0.9583 - val_accuracy: 0.7064 - val_f1_score: 0.3724 - val_loss: 1.1538 - val_precision: 0.8089 - val_recall: 0.5511\n",
      "Epoch 7/20\n",
      "1188/1188 - 57s - 48ms/step - NLL: 0.9737 - accuracy: 0.6914 - f1_score: 0.3951 - loss: 1.1680 - precision: 0.8148 - recall: 0.5745 - val_NLL: 1.0008 - val_accuracy: 0.6894 - val_f1_score: 0.3650 - val_loss: 1.1988 - val_precision: 0.8120 - val_recall: 0.5272\n",
      "Epoch 8/20\n",
      "1188/1188 - 58s - 48ms/step - NLL: 0.9543 - accuracy: 0.6969 - f1_score: 0.4095 - loss: 1.1509 - precision: 0.8187 - recall: 0.5845 - val_NLL: 0.9735 - val_accuracy: 0.7046 - val_f1_score: 0.3898 - val_loss: 1.1738 - val_precision: 0.8019 - val_recall: 0.5615\n",
      "Epoch 9/20\n",
      "1188/1188 - 58s - 49ms/step - NLL: 0.9364 - accuracy: 0.7012 - f1_score: 0.4218 - loss: 1.1340 - precision: 0.8188 - recall: 0.5907 - val_NLL: 0.9663 - val_accuracy: 0.7056 - val_f1_score: 0.3956 - val_loss: 1.1685 - val_precision: 0.8034 - val_recall: 0.5581\n",
      "Epoch 10/20\n",
      "1188/1188 - 57s - 48ms/step - NLL: 0.9230 - accuracy: 0.7058 - f1_score: 0.4350 - loss: 1.1230 - precision: 0.8221 - recall: 0.5971 - val_NLL: 0.9576 - val_accuracy: 0.7085 - val_f1_score: 0.3888 - val_loss: 1.1624 - val_precision: 0.7852 - val_recall: 0.5952\n",
      "Epoch 11/20\n",
      "1188/1188 - 57s - 48ms/step - NLL: 0.9092 - accuracy: 0.7077 - f1_score: 0.4441 - loss: 1.1117 - precision: 0.8215 - recall: 0.6021 - val_NLL: 0.9433 - val_accuracy: 0.7090 - val_f1_score: 0.4126 - val_loss: 1.1498 - val_precision: 0.8080 - val_recall: 0.5839\n",
      "Epoch 12/20\n",
      "1188/1188 - 58s - 49ms/step - NLL: 0.8959 - accuracy: 0.7115 - f1_score: 0.4534 - loss: 1.1000 - precision: 0.8235 - recall: 0.6077 - val_NLL: 0.9461 - val_accuracy: 0.7083 - val_f1_score: 0.4142 - val_loss: 1.1542 - val_precision: 0.8026 - val_recall: 0.5740\n",
      "Epoch 13/20\n",
      "1188/1188 - 59s - 50ms/step - NLL: 0.8897 - accuracy: 0.7138 - f1_score: 0.4567 - loss: 1.0940 - precision: 0.8251 - recall: 0.6101 - val_NLL: 0.9366 - val_accuracy: 0.7093 - val_f1_score: 0.4125 - val_loss: 1.1459 - val_precision: 0.8065 - val_recall: 0.5870\n",
      "Epoch 14/20\n",
      "1188/1188 - 58s - 49ms/step - NLL: 0.8833 - accuracy: 0.7162 - f1_score: 0.4636 - loss: 1.0897 - precision: 0.8259 - recall: 0.6125 - val_NLL: 0.9075 - val_accuracy: 0.7151 - val_f1_score: 0.4275 - val_loss: 1.1184 - val_precision: 0.7969 - val_recall: 0.5953\n",
      "Epoch 15/20\n",
      "1188/1188 - 58s - 49ms/step - NLL: 0.8727 - accuracy: 0.7185 - f1_score: 0.4713 - loss: 1.0809 - precision: 0.8268 - recall: 0.6165 - val_NLL: 0.9396 - val_accuracy: 0.7025 - val_f1_score: 0.3989 - val_loss: 1.1543 - val_precision: 0.7881 - val_recall: 0.5808\n",
      "Epoch 16/20\n",
      "1188/1188 - 58s - 49ms/step - NLL: 0.8647 - accuracy: 0.7210 - f1_score: 0.4762 - loss: 1.0739 - precision: 0.8287 - recall: 0.6208 - val_NLL: 0.9414 - val_accuracy: 0.7064 - val_f1_score: 0.4253 - val_loss: 1.1546 - val_precision: 0.8015 - val_recall: 0.5735\n",
      "Epoch 17/20\n",
      "1188/1188 - 58s - 49ms/step - NLL: 0.8563 - accuracy: 0.7233 - f1_score: 0.4843 - loss: 1.0666 - precision: 0.8287 - recall: 0.6254 - val_NLL: 0.9132 - val_accuracy: 0.7097 - val_f1_score: 0.4232 - val_loss: 1.1295 - val_precision: 0.7896 - val_recall: 0.6020\n",
      "Epoch 18/20\n",
      "1188/1188 - 58s - 49ms/step - NLL: 0.8535 - accuracy: 0.7240 - f1_score: 0.4868 - loss: 1.0640 - precision: 0.8299 - recall: 0.6262 - val_NLL: 0.9294 - val_accuracy: 0.7020 - val_f1_score: 0.4254 - val_loss: 1.1450 - val_precision: 0.7932 - val_recall: 0.5841\n",
      "Epoch 19/20\n",
      "1188/1188 - 58s - 49ms/step - NLL: 0.8447 - accuracy: 0.7276 - f1_score: 0.4922 - loss: 1.0566 - precision: 0.8297 - recall: 0.6296 - val_NLL: 0.9273 - val_accuracy: 0.7087 - val_f1_score: 0.4264 - val_loss: 1.1450 - val_precision: 0.8048 - val_recall: 0.5888\n",
      "Epoch 20/20\n",
      "1188/1188 - 58s - 49ms/step - NLL: 0.8424 - accuracy: 0.7259 - f1_score: 0.4895 - loss: 1.0544 - precision: 0.8298 - recall: 0.6300 - val_NLL: 0.9168 - val_accuracy: 0.7078 - val_f1_score: 0.4329 - val_loss: 1.1335 - val_precision: 0.7873 - val_recall: 0.5977\n",
      "\u001b[1m2376/2376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 10ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "NLL: 0.91\n",
      "Validation accuracy: 0.72\n",
      "Validation F1Score: 0.43\n",
      "evaluating Fold 20\n",
      "Setting seed to 1898784207\n",
      "Epoch 1/20\n",
      "1218/1218 - 63s - 51ms/step - NLL: 1.4161 - accuracy: 0.6029 - f1_score: 0.1233 - loss: 1.6364 - precision: 0.7597 - recall: 0.4529 - val_NLL: 1.7428 - val_accuracy: 0.5091 - val_f1_score: 0.0999 - val_loss: 1.9100 - val_precision: 0.6610 - val_recall: 0.4000\n",
      "Epoch 2/20\n",
      "1218/1218 - 59s - 49ms/step - NLL: 1.2046 - accuracy: 0.6336 - f1_score: 0.2163 - loss: 1.3737 - precision: 0.7902 - recall: 0.4970 - val_NLL: 1.6101 - val_accuracy: 0.5221 - val_f1_score: 0.1425 - val_loss: 1.7838 - val_precision: 0.6378 - val_recall: 0.4296\n",
      "Epoch 3/20\n",
      "1218/1218 - 59s - 48ms/step - NLL: 1.1023 - accuracy: 0.6595 - f1_score: 0.2924 - loss: 1.2813 - precision: 0.7997 - recall: 0.5280 - val_NLL: 1.5265 - val_accuracy: 0.5530 - val_f1_score: 0.2078 - val_loss: 1.7203 - val_precision: 0.6665 - val_recall: 0.4508\n",
      "Epoch 4/20\n",
      "1218/1218 - 58s - 48ms/step - NLL: 1.0392 - accuracy: 0.6753 - f1_score: 0.3364 - loss: 1.2229 - precision: 0.8075 - recall: 0.5538 - val_NLL: 1.4906 - val_accuracy: 0.5538 - val_f1_score: 0.2348 - val_loss: 1.6869 - val_precision: 0.6594 - val_recall: 0.4639\n",
      "Epoch 5/20\n",
      "1218/1218 - 58s - 48ms/step - NLL: 1.0013 - accuracy: 0.6865 - f1_score: 0.3684 - loss: 1.1893 - precision: 0.8139 - recall: 0.5678 - val_NLL: 1.4990 - val_accuracy: 0.5614 - val_f1_score: 0.2575 - val_loss: 1.7000 - val_precision: 0.6642 - val_recall: 0.4810\n",
      "Epoch 6/20\n",
      "1218/1218 - 58s - 48ms/step - NLL: 0.9682 - accuracy: 0.6939 - f1_score: 0.3878 - loss: 1.1590 - precision: 0.8160 - recall: 0.5812 - val_NLL: 1.4308 - val_accuracy: 0.5627 - val_f1_score: 0.2697 - val_loss: 1.6291 - val_precision: 0.6819 - val_recall: 0.4754\n",
      "Epoch 7/20\n",
      "1218/1218 - 59s - 48ms/step - NLL: 0.9430 - accuracy: 0.7014 - f1_score: 0.4111 - loss: 1.1371 - precision: 0.8184 - recall: 0.5917 - val_NLL: 1.4136 - val_accuracy: 0.5775 - val_f1_score: 0.2977 - val_loss: 1.6250 - val_precision: 0.6706 - val_recall: 0.5065\n",
      "Epoch 8/20\n",
      "1218/1218 - 59s - 48ms/step - NLL: 0.9238 - accuracy: 0.7064 - f1_score: 0.4252 - loss: 1.1206 - precision: 0.8205 - recall: 0.6002 - val_NLL: 1.3595 - val_accuracy: 0.5839 - val_f1_score: 0.3091 - val_loss: 1.5636 - val_precision: 0.6755 - val_recall: 0.5057\n",
      "Epoch 9/20\n",
      "1218/1218 - 58s - 48ms/step - NLL: 0.9056 - accuracy: 0.7112 - f1_score: 0.4394 - loss: 1.1049 - precision: 0.8232 - recall: 0.6070 - val_NLL: 1.3140 - val_accuracy: 0.5946 - val_f1_score: 0.3375 - val_loss: 1.5150 - val_precision: 0.6744 - val_recall: 0.5152\n",
      "Epoch 10/20\n",
      "1218/1218 - 58s - 48ms/step - NLL: 0.8876 - accuracy: 0.7160 - f1_score: 0.4500 - loss: 1.0884 - precision: 0.8234 - recall: 0.6146 - val_NLL: 1.3525 - val_accuracy: 0.5865 - val_f1_score: 0.3254 - val_loss: 1.5673 - val_precision: 0.6742 - val_recall: 0.5190\n",
      "Epoch 11/20\n",
      "1218/1218 - 59s - 48ms/step - NLL: 0.8772 - accuracy: 0.7177 - f1_score: 0.4556 - loss: 1.0787 - precision: 0.8245 - recall: 0.6192 - val_NLL: 1.3115 - val_accuracy: 0.5936 - val_f1_score: 0.3435 - val_loss: 1.5164 - val_precision: 0.6825 - val_recall: 0.5183\n",
      "Epoch 12/20\n",
      "1218/1218 - 59s - 48ms/step - NLL: 0.8636 - accuracy: 0.7247 - f1_score: 0.4720 - loss: 1.0668 - precision: 0.8300 - recall: 0.6281 - val_NLL: 1.3060 - val_accuracy: 0.6061 - val_f1_score: 0.3579 - val_loss: 1.5080 - val_precision: 0.6940 - val_recall: 0.5290\n",
      "Epoch 13/20\n",
      "1218/1218 - 59s - 48ms/step - NLL: 0.8532 - accuracy: 0.7270 - f1_score: 0.4773 - loss: 1.0574 - precision: 0.8301 - recall: 0.6309 - val_NLL: 1.3456 - val_accuracy: 0.5995 - val_f1_score: 0.3364 - val_loss: 1.5497 - val_precision: 0.6864 - val_recall: 0.5262\n",
      "Epoch 14/20\n",
      "1218/1218 - 59s - 48ms/step - NLL: 0.8432 - accuracy: 0.7307 - f1_score: 0.4846 - loss: 1.0487 - precision: 0.8313 - recall: 0.6367 - val_NLL: 1.3622 - val_accuracy: 0.5900 - val_f1_score: 0.3363 - val_loss: 1.5721 - val_precision: 0.6652 - val_recall: 0.5241\n",
      "Epoch 15/20\n",
      "1218/1218 - 59s - 48ms/step - NLL: 0.8352 - accuracy: 0.7319 - f1_score: 0.4891 - loss: 1.0420 - precision: 0.8310 - recall: 0.6391 - val_NLL: 1.3215 - val_accuracy: 0.6064 - val_f1_score: 0.3657 - val_loss: 1.5291 - val_precision: 0.6846 - val_recall: 0.5338\n",
      "Epoch 16/20\n",
      "1218/1218 - 59s - 48ms/step - NLL: 0.8294 - accuracy: 0.7324 - f1_score: 0.4919 - loss: 1.0363 - precision: 0.8324 - recall: 0.6416 - val_NLL: 1.3231 - val_accuracy: 0.6054 - val_f1_score: 0.3622 - val_loss: 1.5351 - val_precision: 0.6807 - val_recall: 0.5407\n",
      "Epoch 17/20\n",
      "1218/1218 - 59s - 48ms/step - NLL: 0.8200 - accuracy: 0.7360 - f1_score: 0.4989 - loss: 1.0284 - precision: 0.8340 - recall: 0.6434 - val_NLL: 1.3128 - val_accuracy: 0.6089 - val_f1_score: 0.3611 - val_loss: 1.5205 - val_precision: 0.6859 - val_recall: 0.5405\n",
      "Epoch 18/20\n",
      "1218/1218 - 59s - 49ms/step - NLL: 0.8155 - accuracy: 0.7367 - f1_score: 0.4996 - loss: 1.0247 - precision: 0.8346 - recall: 0.6461 - val_NLL: 1.3204 - val_accuracy: 0.6049 - val_f1_score: 0.3565 - val_loss: 1.5282 - val_precision: 0.6801 - val_recall: 0.5372\n",
      "Epoch 19/20\n",
      "1218/1218 - 59s - 49ms/step - NLL: 0.8104 - accuracy: 0.7387 - f1_score: 0.5044 - loss: 1.0205 - precision: 0.8353 - recall: 0.6504 - val_NLL: 1.2594 - val_accuracy: 0.6112 - val_f1_score: 0.3802 - val_loss: 1.4710 - val_precision: 0.6969 - val_recall: 0.5384\n",
      "Epoch 20/20\n",
      "1218/1218 - 59s - 49ms/step - NLL: 0.8059 - accuracy: 0.7398 - f1_score: 0.5072 - loss: 1.0166 - precision: 0.8345 - recall: 0.6507 - val_NLL: 1.2967 - val_accuracy: 0.6105 - val_f1_score: 0.3705 - val_loss: 1.5098 - val_precision: 0.6902 - val_recall: 0.5400\n",
      "\u001b[1m2436/2436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 10ms/step\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "NLL: 1.26\n",
      "Validation accuracy: 0.61\n",
      "Validation F1Score: 0.38\n"
     ]
    }
   ],
   "source": [
    "with open(cfg, 'r') as file:\n",
    "    cfgmdl = yaml.safe_load(file)['model']\n",
    "datapath = cwd / '..' / 'Data' / 'DHG2016' / 'concat_sequences'\n",
    "\n",
    "results_valid_labels_list = []\n",
    "results_scores_list_train = []\n",
    "results_scores_list_valid = []\n",
    "\n",
    "for seedidx, n_fold in enumerate(folds):\n",
    "    print('evaluating Fold', n_fold)\n",
    "    seed_val = seeds[seedidx]\n",
    "    #for seed_val in seeds:\n",
    "    fold = pickle.load(open((datapath / ('Fold' + str(n_fold) + '.pkl')).resolve(), 'rb'))\n",
    "    Y_train_oh = fold['train']['Y_oh']\n",
    "    Y_valid_oh = fold['valid']['Y_oh']\n",
    "    X_train = fold['train']['X']\n",
    "    X_valid = fold['valid']['X']\n",
    "\n",
    "    like7 = ConvModel(cfg, 'Test', seed = seed_val)\n",
    "    like7.compile_model()\n",
    "\n",
    "    # Train the model\n",
    "    like7.train_model(X_train, Y_train_oh, X_valid, Y_valid_oh)\n",
    "\n",
    "    Y_prob_train = like7.model.predict(X_train)\n",
    "    Y_prob_valid = like7.model.predict(X_valid)\n",
    "    Y_score_true = np.max(Y_prob_valid, axis=-1)\n",
    "\n",
    "    Y_hat_train = np.argmax(Y_prob_train, axis=-1)\n",
    "    Y_hat_valid = np.argmax(Y_prob_valid, axis=-1)\n",
    "\n",
    "    results_train = like7.model.evaluate(X_train, Y_train_oh, verbose = 0, return_dict=True)\n",
    "    results_valid = like7.model.evaluate(X_valid, Y_valid_oh, verbose = 0, return_dict=True)\n",
    "\n",
    "    print(f'NLL: {results_valid['NLL']:,.2f}')\n",
    "    #print(f'Validation score: {results['loss']:,.2f}')\n",
    "    print(f'Validation accuracy: {results_valid['accuracy']:,.2f}')\n",
    "    print(f'Validation F1Score: {results_valid['f1_score']:,.2f}')\n",
    "\n",
    "    results_valid_labels_list.append(pd.DataFrame({'Fold': n_fold, 'Y': fold['valid']['Y'], 'Y_hat': Y_hat_valid, 'Y_prob': Y_score_true}))\n",
    "    results_scores_list_train.append(pd.DataFrame(results_train, index = [n_fold]))\n",
    "    results_scores_list_valid.append(pd.DataFrame(results_valid, index = [n_fold]))\n",
    "    #results_scores_list.append({'Fold': n_fold, 'Accuracy_train': accuracy_train, 'Accuracy_valid': accuracy_valid, 'F1-Score_train': f1_score_train, 'F1-Score_valid': f1_score_valid, 'NLL_train': nll_train, 'NLL_valid': nll_valid})\n",
    "    \n",
    "results_scores = pd.concat([pd.concat(results_scores_list_train).add_suffix('_train'),pd.concat(results_scores_list_valid).add_suffix('_valid')],axis = 1)\n",
    "results_scores.rename(columns = {'fold_train': 'fold'}, inplace = True)\n",
    "results_valid_labels = pd.concat(results_valid_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_valid_labels.to_pickle(datapath/'results_valid_labels_dcnn.pkl')\n",
    "results_scores.to_pickle(datapath/'results_scores_dcnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data - frames: 76.0% +-  0.8%\n",
      "F1_Score on training data - frames: 54.3% +- 2.3%\n",
      "NLL on training data - frames: 0.73 +- 0.02\n",
      "accuracy on validation data - frames: 69.4% +- 3.2%\n",
      "F1-Score on validation data - frames: 39.6% +- 5.5%\n",
      "NLL on validation data - frames: 1.01 +- 0.12\n"
     ]
    }
   ],
   "source": [
    "mean = results_scores.mean()\n",
    "std = results_scores.std()\n",
    "\n",
    "print(f'accuracy on training data - frames: {mean[\"accuracy_train\"]*100:.1f}% +-  {std[\"accuracy_train\"]*100:.1f}%')\n",
    "print(f'F1_Score on training data - frames: {mean[\"f1_score_train\"]*100:.1f}% +- {std[\"f1_score_train\"]*100:.1f}%')\n",
    "print(f'NLL on training data - frames: {mean[\"NLL_train\"]:.2f} +- {std[\"NLL_train\"]:.2f}')\n",
    "\n",
    "print(f'accuracy on validation data - frames: {mean['accuracy_valid']*100:.1f}% +- {std['accuracy_valid']*100:.1f}%')\n",
    "print(f'F1-Score on validation data - frames: {mean['f1_score_valid']*100:.1f}% +- {std['f1_score_valid']*100:.1f}%')\n",
    "print(f'NLL on validation data - frames: {mean['NLL_valid']:.2f} +- {std['NLL_valid']:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ab hier optionaler Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>padding</th>\n",
       "      <th>fold</th>\n",
       "      <th>seed</th>\n",
       "      <th>NLL</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeros</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1.641951</td>\n",
       "      <td>0.44632</td>\n",
       "      <td>0.392613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  padding  fold  seed       NLL  accuracy  f1_score\n",
       "0   zeros     5    26  1.641951   0.44632  0.392613"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DIlatein factor 2, no padding, meanreference, kernelsize2\n",
    "resultsDFslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>padding</th>\n",
       "      <th>fold</th>\n",
       "      <th>seed</th>\n",
       "      <th>NLL</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeros</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1.573875</td>\n",
       "      <td>0.453778</td>\n",
       "      <td>0.394649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  padding  fold  seed       NLL  accuracy  f1_score\n",
       "0   zeros     5    26  1.573875  0.453778  0.394649"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DIlatein factor 2, no padding, meanreference\n",
    "resultsDFslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>padding</th>\n",
       "      <th>fold</th>\n",
       "      <th>seed</th>\n",
       "      <th>NLL</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeros</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1.646613</td>\n",
       "      <td>0.414686</td>\n",
       "      <td>0.400899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  padding  fold  seed       NLL  accuracy  f1_score\n",
       "0   zeros     5    26  1.646613  0.414686  0.400899"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DIlatein factor 3, no padding, meanreference\n",
    "resultsDFslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>padding</th>\n",
       "      <th>fold</th>\n",
       "      <th>seed</th>\n",
       "      <th>NLL</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeros</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1.654638</td>\n",
       "      <td>0.435338</td>\n",
       "      <td>0.390421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  padding  fold  seed       NLL  accuracy  f1_score\n",
       "0   zeros     5    26  1.654638  0.435338  0.390421"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DIlatein factor 3, no padding, firstframereference\n",
    "resultsDFslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>padding</th>\n",
       "      <th>fold</th>\n",
       "      <th>seed</th>\n",
       "      <th>NLL</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeros</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1.923127</td>\n",
       "      <td>0.378135</td>\n",
       "      <td>0.322695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  padding  fold  seed       NLL  accuracy  f1_score\n",
       "0   zeros     5    26  1.923127  0.378135  0.322695"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DIlatein factor 3, no padding\n",
    "resultsDFslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>padding</th>\n",
       "      <th>fold</th>\n",
       "      <th>seed</th>\n",
       "      <th>NLL</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeros</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>2.011779</td>\n",
       "      <td>0.350352</td>\n",
       "      <td>0.29177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  padding  fold  seed       NLL  accuracy  f1_score\n",
       "0   zeros     5    26  2.011779  0.350352   0.29177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DIlatein factor 3, causal padding\n",
    "resultsDFslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_and_pad_la… │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">142</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReshapeAndPadLaye…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>,   │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)]               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">366</span> │ reshape_and_pad_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">304</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ reshape_and_pad_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │ conv1d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2560</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">512,200</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,015</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m140\u001b[0m, \u001b[38;5;34m27\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_and_pad_la… │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m142\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mReshapeAndPadLaye…\u001b[0m │ \u001b[38;5;34m5\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m140\u001b[0m,   │            │                   │\n",
       "│                     │ \u001b[38;5;34m7\u001b[0m)]               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m140\u001b[0m, \u001b[38;5;34m6\u001b[0m) │        \u001b[38;5;34m366\u001b[0m │ reshape_and_pad_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m140\u001b[0m, \u001b[38;5;34m6\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m138\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │        \u001b[38;5;34m304\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m138\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │        \u001b[38;5;34m352\u001b[0m │ reshape_and_pad_… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m3,136\u001b[0m │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m3,136\u001b[0m │ conv1d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m12,352\u001b[0m │ conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m12,352\u001b[0m │ conv1d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ conv1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2560\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │    \u001b[38;5;34m512,200\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        │      \u001b[38;5;34m3,015\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,715,753</span> (6.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,715,753\u001b[0m (6.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">571,917</span> (2.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m571,917\u001b[0m (2.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,143,836</span> (4.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,143,836\u001b[0m (4.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "like7.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%version_information tensorflow, numpy, matplotlib, plotly, pandas, keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gestclass2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
