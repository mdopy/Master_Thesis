{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import tensorflow.keras\n",
    "import yaml\n",
    "\n",
    "\n",
    "import importlib\n",
    "\n",
    "import Model10_OOP\n",
    "importlib.reload(Model10_OOP)\n",
    "from Model10_OOP import ConvModel\n",
    "\n",
    "import BaseData20Fold\n",
    "importlib.reload(BaseData20Fold)\n",
    "from BaseData20Fold import DataProcessor\n",
    "\n",
    "import Plots\n",
    "importlib.reload(Plots)\n",
    "from Plots import plot_CM\n",
    "\n",
    "# COntains 2stream Neural Network to process fine fatures and coarse features separate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "The version_information extension is already loaded. To reload it, use:\n",
      "  %reload_ext version_information\n"
     ]
    }
   ],
   "source": [
    "cwd = Path.cwd()\n",
    "cfg = 'config_mdl10.yaml'\n",
    "\n",
    "with open(cfg, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "seeds = config['seeds']\n",
    "\n",
    "folds = np.arange(1,21)\n",
    "\n",
    "datapath = cwd / '..' / 'Data' / 'DHG2016' / 'owpg_dcnn'\n",
    "\n",
    "%load_ext tensorboard\n",
    "%load_ext version_information\n",
    "#!rm -rf ./logs/\n",
    "\n",
    "logsdir = cwd / '..' / 'logs'\n",
    "# !rmdir /s /q {logsdir}\n",
    "#!tensorboard --logdir {logsdir} --host localhost --port 6006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plotly.com"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "x=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Train Labels"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.histogram(x=data_processor.Y_test, title='Train Labels').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "permuting Samples using seed 26\n",
      "Make Windows and apply framreferences...\n",
      "Processing subject 1\n",
      "Processing subject 2\n",
      "Processing subject 3\n",
      "Processing subject 4\n",
      "Processing subject 5\n",
      "Processing subject 6\n",
      "Processing subject 7\n",
      "Processing subject 8\n",
      "Processing subject 9\n",
      "Processing subject 10\n",
      "Processing subject 11\n",
      "Processing subject 12\n",
      "Processing subject 13\n",
      "Processing subject 14\n",
      "Processing subject 15\n",
      "Processing subject 16\n",
      "Processing subject 17\n",
      "Processing subject 18\n",
      "Processing subject 19\n",
      "Processing subject 20\n",
      "Using seed 26\n",
      "Fold: 1\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 2\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 3\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 4\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 5\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 6\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 7\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 8\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 9\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 10\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 11\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 12\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 13\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 14\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 15\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 16\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 17\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 18\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 19\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n",
      "Using seed 26\n",
      "Fold: 20\n",
      "Standardize and padding of data...\n",
      "Standardize data...train\n",
      "Write data into windows...\n",
      "Standardize data...valid\n",
      "Write data into windows...\n"
     ]
    }
   ],
   "source": [
    "resultsDFlong = pd.DataFrame()\n",
    "folder = 'owpg_dcnn'\n",
    "data_processor = DataProcessor(cfg)\n",
    "data_processor.load_handgestdata()\n",
    "data_processor.handangles2windows()\n",
    "data_processor.save_config(folder)\n",
    "data_processor.save_windowsets(folder)\n",
    "\n",
    "#folds = [5]\n",
    "    \n",
    "for fold in folds:\n",
    "    data_processor = DataProcessor(cfg, fold = fold)\n",
    "    # data_processor.load_handgestdata()\n",
    "    # data_processor.handangles2windows()\n",
    "    # data_processor.save_windowsets(folder)\n",
    "    data_processor.load_windows(folder)\n",
    "    data_processor.processwindows()\n",
    "    data_processor.save_windowsets_processed(folder, name='Fold'+str(fold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating Fold 1\n",
      "Setting seed to 5\n",
      "Epoch 1/20\n",
      "42/42 - 30s - 707ms/step - NLL: 1.8382 - accuracy: 0.3992 - f1_score: 0.3915 - loss: 2.3304 - precision: 0.7905 - recall: 0.1744 - val_NLL: 1.5124 - val_accuracy: 0.5786 - val_f1_score: 0.5749 - val_loss: 1.9466 - val_precision: 0.8205 - val_recall: 0.2286\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 190ms/step - NLL: 1.0293 - accuracy: 0.6744 - f1_score: 0.6721 - loss: 1.4223 - precision: 0.8369 - recall: 0.5094 - val_NLL: 1.1356 - val_accuracy: 0.6643 - val_f1_score: 0.6545 - val_loss: 1.5529 - val_precision: 0.8333 - val_recall: 0.4643\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.7755 - accuracy: 0.7462 - f1_score: 0.7461 - loss: 1.1429 - precision: 0.8632 - recall: 0.6429 - val_NLL: 1.0379 - val_accuracy: 0.6500 - val_f1_score: 0.6417 - val_loss: 1.3811 - val_precision: 0.7981 - val_recall: 0.5929\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 186ms/step - NLL: 0.6635 - accuracy: 0.7861 - f1_score: 0.7854 - loss: 1.0175 - precision: 0.8769 - recall: 0.7068 - val_NLL: 0.9230 - val_accuracy: 0.7286 - val_f1_score: 0.7180 - val_loss: 1.2536 - val_precision: 0.7895 - val_recall: 0.6429\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 188ms/step - NLL: 0.5653 - accuracy: 0.8113 - f1_score: 0.8118 - loss: 0.9152 - precision: 0.8816 - recall: 0.7477 - val_NLL: 0.9491 - val_accuracy: 0.6571 - val_f1_score: 0.6522 - val_loss: 1.2766 - val_precision: 0.7745 - val_recall: 0.5643\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 182ms/step - NLL: 0.4961 - accuracy: 0.8372 - f1_score: 0.8367 - loss: 0.8431 - precision: 0.8925 - recall: 0.7831 - val_NLL: 0.9400 - val_accuracy: 0.6786 - val_f1_score: 0.6774 - val_loss: 1.2272 - val_precision: 0.7542 - val_recall: 0.6357\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 186ms/step - NLL: 0.4533 - accuracy: 0.8481 - f1_score: 0.8477 - loss: 0.7988 - precision: 0.9028 - recall: 0.7992 - val_NLL: 0.9413 - val_accuracy: 0.6643 - val_f1_score: 0.6586 - val_loss: 1.1734 - val_precision: 0.7627 - val_recall: 0.6429\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 184ms/step - NLL: 0.3900 - accuracy: 0.8729 - f1_score: 0.8730 - loss: 0.7382 - precision: 0.9164 - recall: 0.8244 - val_NLL: 0.9290 - val_accuracy: 0.6857 - val_f1_score: 0.6703 - val_loss: 1.1679 - val_precision: 0.7480 - val_recall: 0.6571\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 185ms/step - NLL: 0.3594 - accuracy: 0.8767 - f1_score: 0.8768 - loss: 0.7107 - precision: 0.9108 - recall: 0.8365 - val_NLL: 1.0514 - val_accuracy: 0.6786 - val_f1_score: 0.6765 - val_loss: 1.2899 - val_precision: 0.7459 - val_recall: 0.6500\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.3138 - accuracy: 0.8895 - f1_score: 0.8894 - loss: 0.6629 - precision: 0.9219 - recall: 0.8568 - val_NLL: 1.0056 - val_accuracy: 0.7071 - val_f1_score: 0.7033 - val_loss: 1.1680 - val_precision: 0.7364 - val_recall: 0.6786\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 182ms/step - NLL: 0.2995 - accuracy: 0.8898 - f1_score: 0.8901 - loss: 0.6470 - precision: 0.9230 - recall: 0.8647 - val_NLL: 1.1390 - val_accuracy: 0.6500 - val_f1_score: 0.6311 - val_loss: 1.2579 - val_precision: 0.6825 - val_recall: 0.6143\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 188ms/step - NLL: 0.2628 - accuracy: 0.9079 - f1_score: 0.9081 - loss: 0.6110 - precision: 0.9350 - recall: 0.8808 - val_NLL: 1.1142 - val_accuracy: 0.6857 - val_f1_score: 0.6637 - val_loss: 1.3252 - val_precision: 0.7317 - val_recall: 0.6429\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.2445 - accuracy: 0.9109 - f1_score: 0.9106 - loss: 0.5958 - precision: 0.9308 - recall: 0.8895 - val_NLL: 0.8520 - val_accuracy: 0.7071 - val_f1_score: 0.7009 - val_loss: 1.1344 - val_precision: 0.7460 - val_recall: 0.6714\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2290 - accuracy: 0.9165 - f1_score: 0.9168 - loss: 0.5809 - precision: 0.9374 - recall: 0.8951 - val_NLL: 0.9163 - val_accuracy: 0.7500 - val_f1_score: 0.7323 - val_loss: 1.1436 - val_precision: 0.7557 - val_recall: 0.7071\n",
      "Epoch 15/20\n",
      "42/42 - 7s - 168ms/step - NLL: 0.2010 - accuracy: 0.9320 - f1_score: 0.9319 - loss: 0.5622 - precision: 0.9472 - recall: 0.9109 - val_NLL: 0.9379 - val_accuracy: 0.7214 - val_f1_score: 0.7261 - val_loss: 1.2298 - val_precision: 0.7734 - val_recall: 0.7071\n",
      "Epoch 16/20\n",
      "42/42 - 5s - 123ms/step - NLL: 0.2120 - accuracy: 0.9308 - f1_score: 0.9308 - loss: 0.5727 - precision: 0.9478 - recall: 0.9086 - val_NLL: 1.0554 - val_accuracy: 0.7143 - val_f1_score: 0.6963 - val_loss: 1.3094 - val_precision: 0.7405 - val_recall: 0.6929\n",
      "Epoch 17/20\n",
      "42/42 - 5s - 117ms/step - NLL: 0.1876 - accuracy: 0.9338 - f1_score: 0.9336 - loss: 0.5444 - precision: 0.9548 - recall: 0.9203 - val_NLL: 0.9069 - val_accuracy: 0.7429 - val_f1_score: 0.7283 - val_loss: 1.0767 - val_precision: 0.7669 - val_recall: 0.7286\n",
      "Epoch 18/20\n",
      "42/42 - 6s - 148ms/step - NLL: 0.1842 - accuracy: 0.9459 - f1_score: 0.9458 - loss: 0.5380 - precision: 0.9581 - recall: 0.9282 - val_NLL: 1.0251 - val_accuracy: 0.7286 - val_f1_score: 0.7074 - val_loss: 1.1668 - val_precision: 0.7481 - val_recall: 0.7000\n",
      "Epoch 19/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.1538 - accuracy: 0.9530 - f1_score: 0.9529 - loss: 0.5049 - precision: 0.9634 - recall: 0.9414 - val_NLL: 0.9557 - val_accuracy: 0.7500 - val_f1_score: 0.7271 - val_loss: 1.2028 - val_precision: 0.7769 - val_recall: 0.7214\n",
      "Epoch 20/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.1460 - accuracy: 0.9470 - f1_score: 0.9467 - loss: 0.4952 - precision: 0.9614 - recall: 0.9372 - val_NLL: 0.9534 - val_accuracy: 0.7429 - val_f1_score: 0.7209 - val_loss: 1.1564 - val_precision: 0.7630 - val_recall: 0.7357\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "NLL: 0.85\n",
      "Validation accuracy: 0.71\n",
      "Validation F1Score: 0.70\n",
      "evaluating Fold 2\n",
      "Setting seed to 26\n",
      "Epoch 1/20\n",
      "42/42 - 32s - 756ms/step - NLL: 1.7776 - accuracy: 0.4357 - f1_score: 0.4223 - loss: 2.2536 - precision: 0.8051 - recall: 0.2019 - val_NLL: 2.0386 - val_accuracy: 0.4500 - val_f1_score: 0.4373 - val_loss: 2.5688 - val_precision: 0.5962 - val_recall: 0.2214\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 198ms/step - NLL: 0.9285 - accuracy: 0.7071 - f1_score: 0.7071 - loss: 1.3213 - precision: 0.8433 - recall: 0.5684 - val_NLL: 1.6899 - val_accuracy: 0.5214 - val_f1_score: 0.5145 - val_loss: 2.1317 - val_precision: 0.6667 - val_recall: 0.3857\n",
      "Epoch 3/20\n",
      "42/42 - 10s - 249ms/step - NLL: 0.6854 - accuracy: 0.7767 - f1_score: 0.7767 - loss: 1.0567 - precision: 0.8646 - recall: 0.6891 - val_NLL: 1.6059 - val_accuracy: 0.5714 - val_f1_score: 0.5638 - val_loss: 1.9349 - val_precision: 0.6923 - val_recall: 0.4500\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.5630 - accuracy: 0.8132 - f1_score: 0.8137 - loss: 0.9238 - precision: 0.8746 - recall: 0.7470 - val_NLL: 1.6674 - val_accuracy: 0.5143 - val_f1_score: 0.4966 - val_loss: 1.9409 - val_precision: 0.6263 - val_recall: 0.4429\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.4921 - accuracy: 0.8365 - f1_score: 0.8365 - loss: 0.8535 - precision: 0.8885 - recall: 0.7789 - val_NLL: 1.7036 - val_accuracy: 0.5786 - val_f1_score: 0.5622 - val_loss: 1.9303 - val_precision: 0.6182 - val_recall: 0.4857\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 179ms/step - NLL: 0.4255 - accuracy: 0.8568 - f1_score: 0.8563 - loss: 0.7822 - precision: 0.9035 - recall: 0.8064 - val_NLL: 1.7025 - val_accuracy: 0.5643 - val_f1_score: 0.5604 - val_loss: 1.9594 - val_precision: 0.6466 - val_recall: 0.5357\n",
      "Epoch 7/20\n",
      "42/42 - 5s - 119ms/step - NLL: 0.3789 - accuracy: 0.8744 - f1_score: 0.8741 - loss: 0.7288 - precision: 0.9113 - recall: 0.8301 - val_NLL: 1.6964 - val_accuracy: 0.5714 - val_f1_score: 0.5704 - val_loss: 1.9361 - val_precision: 0.6396 - val_recall: 0.5071\n",
      "Epoch 8/20\n",
      "42/42 - 5s - 114ms/step - NLL: 0.3510 - accuracy: 0.8812 - f1_score: 0.8809 - loss: 0.7001 - precision: 0.9187 - recall: 0.8372 - val_NLL: 1.8025 - val_accuracy: 0.5286 - val_f1_score: 0.5283 - val_loss: 2.0552 - val_precision: 0.5862 - val_recall: 0.4857\n",
      "Epoch 9/20\n",
      "42/42 - 5s - 115ms/step - NLL: 0.3427 - accuracy: 0.8771 - f1_score: 0.8771 - loss: 0.6970 - precision: 0.9157 - recall: 0.8376 - val_NLL: 1.9090 - val_accuracy: 0.5714 - val_f1_score: 0.5580 - val_loss: 2.0712 - val_precision: 0.6186 - val_recall: 0.5214\n",
      "Epoch 10/20\n",
      "42/42 - 5s - 114ms/step - NLL: 0.2988 - accuracy: 0.8970 - f1_score: 0.8966 - loss: 0.6525 - precision: 0.9288 - recall: 0.8635 - val_NLL: 1.8666 - val_accuracy: 0.5214 - val_f1_score: 0.5217 - val_loss: 2.1710 - val_precision: 0.5763 - val_recall: 0.4857\n",
      "Epoch 11/20\n",
      "42/42 - 5s - 118ms/step - NLL: 0.2741 - accuracy: 0.9071 - f1_score: 0.9073 - loss: 0.6219 - precision: 0.9334 - recall: 0.8793 - val_NLL: 2.0460 - val_accuracy: 0.5571 - val_f1_score: 0.5504 - val_loss: 2.2758 - val_precision: 0.6198 - val_recall: 0.5357\n",
      "Epoch 12/20\n",
      "42/42 - 5s - 116ms/step - NLL: 0.2585 - accuracy: 0.9102 - f1_score: 0.9103 - loss: 0.6044 - precision: 0.9324 - recall: 0.8820 - val_NLL: 1.5953 - val_accuracy: 0.6071 - val_f1_score: 0.6102 - val_loss: 1.8775 - val_precision: 0.6612 - val_recall: 0.5714\n",
      "Epoch 13/20\n",
      "42/42 - 5s - 116ms/step - NLL: 0.2517 - accuracy: 0.9056 - f1_score: 0.9057 - loss: 0.6174 - precision: 0.9297 - recall: 0.8805 - val_NLL: 1.8455 - val_accuracy: 0.5571 - val_f1_score: 0.5549 - val_loss: 2.0855 - val_precision: 0.6218 - val_recall: 0.5286\n",
      "Epoch 14/20\n",
      "42/42 - 6s - 152ms/step - NLL: 0.2140 - accuracy: 0.9320 - f1_score: 0.9319 - loss: 0.5757 - precision: 0.9480 - recall: 0.9109 - val_NLL: 2.2339 - val_accuracy: 0.5857 - val_f1_score: 0.5719 - val_loss: 2.3582 - val_precision: 0.6179 - val_recall: 0.5429\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.1979 - accuracy: 0.9350 - f1_score: 0.9349 - loss: 0.5520 - precision: 0.9505 - recall: 0.9169 - val_NLL: 2.2432 - val_accuracy: 0.5714 - val_f1_score: 0.5553 - val_loss: 2.3629 - val_precision: 0.6000 - val_recall: 0.5357\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 186ms/step - NLL: 0.2145 - accuracy: 0.9229 - f1_score: 0.9229 - loss: 0.5620 - precision: 0.9452 - recall: 0.9019 - val_NLL: 1.9692 - val_accuracy: 0.5714 - val_f1_score: 0.5619 - val_loss: 2.1370 - val_precision: 0.6142 - val_recall: 0.5571\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.1909 - accuracy: 0.9350 - f1_score: 0.9350 - loss: 0.5392 - precision: 0.9483 - recall: 0.9173 - val_NLL: 2.0052 - val_accuracy: 0.5571 - val_f1_score: 0.5835 - val_loss: 2.2803 - val_precision: 0.6016 - val_recall: 0.5286\n",
      "Epoch 18/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.1644 - accuracy: 0.9447 - f1_score: 0.9446 - loss: 0.5079 - precision: 0.9594 - recall: 0.9335 - val_NLL: 1.8474 - val_accuracy: 0.5714 - val_f1_score: 0.5521 - val_loss: 2.0689 - val_precision: 0.6094 - val_recall: 0.5571\n",
      "Epoch 19/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.1564 - accuracy: 0.9485 - f1_score: 0.9484 - loss: 0.4962 - precision: 0.9627 - recall: 0.9327 - val_NLL: 1.9413 - val_accuracy: 0.5643 - val_f1_score: 0.5621 - val_loss: 2.1213 - val_precision: 0.6190 - val_recall: 0.5571\n",
      "Epoch 20/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.1371 - accuracy: 0.9526 - f1_score: 0.9527 - loss: 0.4709 - precision: 0.9632 - recall: 0.9451 - val_NLL: 2.2468 - val_accuracy: 0.5929 - val_f1_score: 0.5719 - val_loss: 2.3998 - val_precision: 0.6357 - val_recall: 0.5857\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "NLL: 1.60\n",
      "Validation accuracy: 0.61\n",
      "Validation F1Score: 0.61\n",
      "evaluating Fold 3\n",
      "Setting seed to 90\n",
      "Epoch 1/20\n",
      "42/42 - 30s - 723ms/step - NLL: 1.8468 - accuracy: 0.4019 - f1_score: 0.3834 - loss: 2.3128 - precision: 0.7848 - recall: 0.1823 - val_NLL: 0.9766 - val_accuracy: 0.6714 - val_f1_score: 0.6472 - val_loss: 1.3819 - val_precision: 0.8352 - val_recall: 0.5429\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 183ms/step - NLL: 1.0443 - accuracy: 0.6579 - f1_score: 0.6556 - loss: 1.4251 - precision: 0.8099 - recall: 0.5030 - val_NLL: 0.6599 - val_accuracy: 0.7714 - val_f1_score: 0.7564 - val_loss: 1.0899 - val_precision: 0.8818 - val_recall: 0.6929\n",
      "Epoch 3/20\n",
      "42/42 - 7s - 166ms/step - NLL: 0.7853 - accuracy: 0.7387 - f1_score: 0.7371 - loss: 1.1517 - precision: 0.8444 - recall: 0.6383 - val_NLL: 0.6361 - val_accuracy: 0.8357 - val_f1_score: 0.8213 - val_loss: 1.0379 - val_precision: 0.8629 - val_recall: 0.7643\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.6615 - accuracy: 0.7816 - f1_score: 0.7814 - loss: 1.0209 - precision: 0.8616 - recall: 0.6906 - val_NLL: 0.5790 - val_accuracy: 0.8000 - val_f1_score: 0.7881 - val_loss: 1.0003 - val_precision: 0.8739 - val_recall: 0.7429\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.5788 - accuracy: 0.8056 - f1_score: 0.8053 - loss: 0.9363 - precision: 0.8711 - recall: 0.7391 - val_NLL: 0.6392 - val_accuracy: 0.8286 - val_f1_score: 0.8184 - val_loss: 1.0688 - val_precision: 0.8640 - val_recall: 0.7714\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.4861 - accuracy: 0.8402 - f1_score: 0.8403 - loss: 0.8419 - precision: 0.8865 - recall: 0.7722 - val_NLL: 0.6529 - val_accuracy: 0.8214 - val_f1_score: 0.8090 - val_loss: 0.9600 - val_precision: 0.8504 - val_recall: 0.7714\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.4543 - accuracy: 0.8436 - f1_score: 0.8437 - loss: 0.8119 - precision: 0.8899 - recall: 0.7932 - val_NLL: 0.7507 - val_accuracy: 0.8429 - val_f1_score: 0.8178 - val_loss: 0.9780 - val_precision: 0.8898 - val_recall: 0.8071\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 200ms/step - NLL: 0.3969 - accuracy: 0.8620 - f1_score: 0.8630 - loss: 0.7570 - precision: 0.9064 - recall: 0.8150 - val_NLL: 0.2976 - val_accuracy: 0.9000 - val_f1_score: 0.8971 - val_loss: 0.6374 - val_precision: 0.9254 - val_recall: 0.8857\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.3645 - accuracy: 0.8692 - f1_score: 0.8694 - loss: 0.7271 - precision: 0.9079 - recall: 0.8301 - val_NLL: 0.7621 - val_accuracy: 0.8500 - val_f1_score: 0.8197 - val_loss: 0.9946 - val_precision: 0.8647 - val_recall: 0.8214\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.3225 - accuracy: 0.8929 - f1_score: 0.8929 - loss: 0.6860 - precision: 0.9211 - recall: 0.8556 - val_NLL: 0.7007 - val_accuracy: 0.8500 - val_f1_score: 0.8379 - val_loss: 0.9812 - val_precision: 0.8797 - val_recall: 0.8357\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.2873 - accuracy: 0.9008 - f1_score: 0.9008 - loss: 0.6507 - precision: 0.9277 - recall: 0.8677 - val_NLL: 0.7582 - val_accuracy: 0.8500 - val_f1_score: 0.8337 - val_loss: 1.0163 - val_precision: 0.8722 - val_recall: 0.8286\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2621 - accuracy: 0.9117 - f1_score: 0.9117 - loss: 0.6281 - precision: 0.9316 - recall: 0.8865 - val_NLL: 0.9320 - val_accuracy: 0.8500 - val_f1_score: 0.8295 - val_loss: 1.0723 - val_precision: 0.8551 - val_recall: 0.8429\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 201ms/step - NLL: 0.2597 - accuracy: 0.9128 - f1_score: 0.9127 - loss: 0.6257 - precision: 0.9309 - recall: 0.8857 - val_NLL: 0.7659 - val_accuracy: 0.8500 - val_f1_score: 0.8332 - val_loss: 0.9689 - val_precision: 0.8593 - val_recall: 0.8286\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.2198 - accuracy: 0.9237 - f1_score: 0.9234 - loss: 0.5891 - precision: 0.9442 - recall: 0.9038 - val_NLL: 0.3939 - val_accuracy: 0.8929 - val_f1_score: 0.8891 - val_loss: 0.7494 - val_precision: 0.8978 - val_recall: 0.8786\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 186ms/step - NLL: 0.2262 - accuracy: 0.9222 - f1_score: 0.9221 - loss: 0.5950 - precision: 0.9345 - recall: 0.9008 - val_NLL: 0.6043 - val_accuracy: 0.8357 - val_f1_score: 0.8092 - val_loss: 0.9274 - val_precision: 0.8406 - val_recall: 0.8286\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.2005 - accuracy: 0.9286 - f1_score: 0.9283 - loss: 0.5754 - precision: 0.9411 - recall: 0.9124 - val_NLL: 0.5027 - val_accuracy: 0.8786 - val_f1_score: 0.8753 - val_loss: 0.8999 - val_precision: 0.8889 - val_recall: 0.8571\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.1880 - accuracy: 0.9380 - f1_score: 0.9381 - loss: 0.5645 - precision: 0.9518 - recall: 0.9195 - val_NLL: 0.4959 - val_accuracy: 0.8786 - val_f1_score: 0.8694 - val_loss: 0.7823 - val_precision: 0.8849 - val_recall: 0.8786\n",
      "Epoch 18/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.1795 - accuracy: 0.9357 - f1_score: 0.9357 - loss: 0.5474 - precision: 0.9478 - recall: 0.9218 - val_NLL: 0.6820 - val_accuracy: 0.8500 - val_f1_score: 0.8374 - val_loss: 0.8847 - val_precision: 0.8686 - val_recall: 0.8500\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "NLL: 0.30\n",
      "Validation accuracy: 0.90\n",
      "Validation F1Score: 0.90\n",
      "evaluating Fold 4\n",
      "Setting seed to 232\n",
      "Epoch 1/20\n",
      "42/42 - 32s - 753ms/step - NLL: 1.9370 - accuracy: 0.3868 - f1_score: 0.3770 - loss: 2.3981 - precision: 0.7782 - recall: 0.1477 - val_NLL: 1.6413 - val_accuracy: 0.4714 - val_f1_score: 0.4060 - val_loss: 2.0789 - val_precision: 0.7442 - val_recall: 0.2286\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 190ms/step - NLL: 1.1110 - accuracy: 0.6477 - f1_score: 0.6482 - loss: 1.4854 - precision: 0.8100 - recall: 0.4695 - val_NLL: 1.1020 - val_accuracy: 0.6571 - val_f1_score: 0.6179 - val_loss: 1.6056 - val_precision: 0.8182 - val_recall: 0.5143\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.8111 - accuracy: 0.7383 - f1_score: 0.7374 - loss: 1.1699 - precision: 0.8593 - recall: 0.6361 - val_NLL: 0.8931 - val_accuracy: 0.7286 - val_f1_score: 0.7103 - val_loss: 1.4056 - val_precision: 0.7736 - val_recall: 0.5857\n",
      "Epoch 4/20\n",
      "42/42 - 10s - 246ms/step - NLL: 0.6493 - accuracy: 0.7914 - f1_score: 0.7912 - loss: 0.9974 - precision: 0.8798 - recall: 0.7102 - val_NLL: 0.8670 - val_accuracy: 0.7071 - val_f1_score: 0.6749 - val_loss: 1.2941 - val_precision: 0.7818 - val_recall: 0.6143\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.5639 - accuracy: 0.8147 - f1_score: 0.8144 - loss: 0.9123 - precision: 0.8902 - recall: 0.7470 - val_NLL: 0.7829 - val_accuracy: 0.7429 - val_f1_score: 0.7133 - val_loss: 1.2047 - val_precision: 0.8584 - val_recall: 0.6929\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.4943 - accuracy: 0.8402 - f1_score: 0.8405 - loss: 0.8478 - precision: 0.8904 - recall: 0.7816 - val_NLL: 0.6904 - val_accuracy: 0.7714 - val_f1_score: 0.7397 - val_loss: 1.0997 - val_precision: 0.8868 - val_recall: 0.6714\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.4427 - accuracy: 0.8530 - f1_score: 0.8530 - loss: 0.7936 - precision: 0.9071 - recall: 0.8071 - val_NLL: 0.7183 - val_accuracy: 0.7786 - val_f1_score: 0.7483 - val_loss: 1.1799 - val_precision: 0.8407 - val_recall: 0.6786\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.3856 - accuracy: 0.8669 - f1_score: 0.8668 - loss: 0.7360 - precision: 0.9120 - recall: 0.8297 - val_NLL: 0.6575 - val_accuracy: 0.8214 - val_f1_score: 0.8051 - val_loss: 1.1530 - val_precision: 0.8974 - val_recall: 0.7500\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.3492 - accuracy: 0.8793 - f1_score: 0.8795 - loss: 0.7047 - precision: 0.9155 - recall: 0.8436 - val_NLL: 0.6307 - val_accuracy: 0.8214 - val_f1_score: 0.8139 - val_loss: 1.0841 - val_precision: 0.8793 - val_recall: 0.7286\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.3200 - accuracy: 0.8857 - f1_score: 0.8858 - loss: 0.6704 - precision: 0.9209 - recall: 0.8620 - val_NLL: 0.6245 - val_accuracy: 0.8214 - val_f1_score: 0.8093 - val_loss: 1.0885 - val_precision: 0.8739 - val_recall: 0.7429\n",
      "Epoch 11/20\n",
      "42/42 - 7s - 171ms/step - NLL: 0.2948 - accuracy: 0.9000 - f1_score: 0.9000 - loss: 0.6429 - precision: 0.9287 - recall: 0.8669 - val_NLL: 0.7321 - val_accuracy: 0.7929 - val_f1_score: 0.7769 - val_loss: 1.1806 - val_precision: 0.8403 - val_recall: 0.7143\n",
      "Epoch 12/20\n",
      "42/42 - 7s - 175ms/step - NLL: 0.2571 - accuracy: 0.9113 - f1_score: 0.9111 - loss: 0.6069 - precision: 0.9345 - recall: 0.8853 - val_NLL: 0.8109 - val_accuracy: 0.7929 - val_f1_score: 0.7671 - val_loss: 1.3060 - val_precision: 0.8583 - val_recall: 0.7357\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2482 - accuracy: 0.9128 - f1_score: 0.9126 - loss: 0.5947 - precision: 0.9372 - recall: 0.8865 - val_NLL: 0.7916 - val_accuracy: 0.8071 - val_f1_score: 0.7955 - val_loss: 1.2867 - val_precision: 0.8279 - val_recall: 0.7214\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.2534 - accuracy: 0.9113 - f1_score: 0.9112 - loss: 0.6015 - precision: 0.9333 - recall: 0.8887 - val_NLL: 0.7563 - val_accuracy: 0.7857 - val_f1_score: 0.7528 - val_loss: 1.1971 - val_precision: 0.8295 - val_recall: 0.7643\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.2342 - accuracy: 0.9203 - f1_score: 0.9205 - loss: 0.5958 - precision: 0.9399 - recall: 0.8940 - val_NLL: 0.6954 - val_accuracy: 0.7857 - val_f1_score: 0.7602 - val_loss: 1.1673 - val_precision: 0.8154 - val_recall: 0.7571\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.1919 - accuracy: 0.9380 - f1_score: 0.9378 - loss: 0.5510 - precision: 0.9546 - recall: 0.9173 - val_NLL: 0.7819 - val_accuracy: 0.7714 - val_f1_score: 0.7603 - val_loss: 1.2824 - val_precision: 0.8000 - val_recall: 0.7429\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.1679 - accuracy: 0.9432 - f1_score: 0.9431 - loss: 0.5192 - precision: 0.9566 - recall: 0.9289 - val_NLL: 0.8296 - val_accuracy: 0.7643 - val_f1_score: 0.7477 - val_loss: 1.1910 - val_precision: 0.8125 - val_recall: 0.7429\n",
      "Epoch 18/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.1924 - accuracy: 0.9372 - f1_score: 0.9371 - loss: 0.5407 - precision: 0.9524 - recall: 0.9184 - val_NLL: 0.8578 - val_accuracy: 0.7429 - val_f1_score: 0.7272 - val_loss: 1.2499 - val_precision: 0.7984 - val_recall: 0.7071\n",
      "Epoch 19/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.1795 - accuracy: 0.9395 - f1_score: 0.9393 - loss: 0.5337 - precision: 0.9534 - recall: 0.9233 - val_NLL: 0.9005 - val_accuracy: 0.7857 - val_f1_score: 0.7691 - val_loss: 1.3991 - val_precision: 0.8077 - val_recall: 0.7500\n",
      "Epoch 20/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.1538 - accuracy: 0.9455 - f1_score: 0.9456 - loss: 0.5035 - precision: 0.9568 - recall: 0.9331 - val_NLL: 0.8606 - val_accuracy: 0.7786 - val_f1_score: 0.7634 - val_loss: 1.2320 - val_precision: 0.8217 - val_recall: 0.7571\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "NLL: 0.62\n",
      "Validation accuracy: 0.82\n",
      "Validation F1Score: 0.81\n",
      "evaluating Fold 5\n",
      "Setting seed to 819\n",
      "Epoch 1/20\n",
      "42/42 - 29s - 701ms/step - NLL: 1.9431 - accuracy: 0.3726 - f1_score: 0.3469 - loss: 2.4000 - precision: 0.7367 - recall: 0.1515 - val_NLL: 1.3725 - val_accuracy: 0.5929 - val_f1_score: 0.5812 - val_loss: 1.8379 - val_precision: 0.9200 - val_recall: 0.3286\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 189ms/step - NLL: 1.1251 - accuracy: 0.6455 - f1_score: 0.6422 - loss: 1.4911 - precision: 0.8380 - recall: 0.4647 - val_NLL: 0.9624 - val_accuracy: 0.7571 - val_f1_score: 0.7435 - val_loss: 1.4241 - val_precision: 0.8554 - val_recall: 0.5071\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.8515 - accuracy: 0.7211 - f1_score: 0.7201 - loss: 1.2023 - precision: 0.8499 - recall: 0.6004 - val_NLL: 0.8189 - val_accuracy: 0.7500 - val_f1_score: 0.7403 - val_loss: 1.3111 - val_precision: 0.9000 - val_recall: 0.6429\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.6879 - accuracy: 0.7714 - f1_score: 0.7716 - loss: 1.0295 - precision: 0.8557 - recall: 0.6823 - val_NLL: 0.7506 - val_accuracy: 0.7643 - val_f1_score: 0.7610 - val_loss: 1.2436 - val_precision: 0.8099 - val_recall: 0.7000\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.6159 - accuracy: 0.8000 - f1_score: 0.7997 - loss: 0.9576 - precision: 0.8678 - recall: 0.7229 - val_NLL: 0.7370 - val_accuracy: 0.7786 - val_f1_score: 0.7726 - val_loss: 1.2289 - val_precision: 0.8475 - val_recall: 0.7143\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.5373 - accuracy: 0.8180 - f1_score: 0.8179 - loss: 0.8786 - precision: 0.8833 - recall: 0.7541 - val_NLL: 0.6397 - val_accuracy: 0.7786 - val_f1_score: 0.7693 - val_loss: 1.0568 - val_precision: 0.8306 - val_recall: 0.7357\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 188ms/step - NLL: 0.4800 - accuracy: 0.8417 - f1_score: 0.8419 - loss: 0.8216 - precision: 0.8990 - recall: 0.7861 - val_NLL: 0.6423 - val_accuracy: 0.8071 - val_f1_score: 0.7987 - val_loss: 1.1750 - val_precision: 0.8203 - val_recall: 0.7500\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.4319 - accuracy: 0.8541 - f1_score: 0.8547 - loss: 0.7729 - precision: 0.8961 - recall: 0.8011 - val_NLL: 0.7087 - val_accuracy: 0.7643 - val_f1_score: 0.7633 - val_loss: 1.2088 - val_precision: 0.8031 - val_recall: 0.7286\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.3946 - accuracy: 0.8632 - f1_score: 0.8636 - loss: 0.7365 - precision: 0.9037 - recall: 0.8113 - val_NLL: 0.6124 - val_accuracy: 0.7929 - val_f1_score: 0.7914 - val_loss: 1.0397 - val_precision: 0.8400 - val_recall: 0.7500\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.3364 - accuracy: 0.8842 - f1_score: 0.8840 - loss: 0.6810 - precision: 0.9178 - recall: 0.8481 - val_NLL: 0.6394 - val_accuracy: 0.7857 - val_f1_score: 0.7842 - val_loss: 1.0233 - val_precision: 0.8120 - val_recall: 0.7714\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.3165 - accuracy: 0.8827 - f1_score: 0.8824 - loss: 0.6616 - precision: 0.9208 - recall: 0.8519 - val_NLL: 0.5987 - val_accuracy: 0.8000 - val_f1_score: 0.7997 - val_loss: 1.0198 - val_precision: 0.8550 - val_recall: 0.8000\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.2791 - accuracy: 0.8977 - f1_score: 0.8979 - loss: 0.6275 - precision: 0.9285 - recall: 0.8688 - val_NLL: 0.6543 - val_accuracy: 0.8071 - val_f1_score: 0.8057 - val_loss: 1.1325 - val_precision: 0.8516 - val_recall: 0.7786\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.2593 - accuracy: 0.9109 - f1_score: 0.9111 - loss: 0.6051 - precision: 0.9314 - recall: 0.8835 - val_NLL: 0.6436 - val_accuracy: 0.8000 - val_f1_score: 0.7981 - val_loss: 1.0720 - val_precision: 0.8168 - val_recall: 0.7643\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 188ms/step - NLL: 0.2344 - accuracy: 0.9128 - f1_score: 0.9127 - loss: 0.5810 - precision: 0.9388 - recall: 0.8883 - val_NLL: 0.6688 - val_accuracy: 0.8214 - val_f1_score: 0.8195 - val_loss: 1.0924 - val_precision: 0.8433 - val_recall: 0.8071\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 186ms/step - NLL: 0.2256 - accuracy: 0.9214 - f1_score: 0.9214 - loss: 0.5732 - precision: 0.9380 - recall: 0.8989 - val_NLL: 0.7002 - val_accuracy: 0.8143 - val_f1_score: 0.8124 - val_loss: 1.1083 - val_precision: 0.8397 - val_recall: 0.7857\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 188ms/step - NLL: 0.2187 - accuracy: 0.9244 - f1_score: 0.9245 - loss: 0.5666 - precision: 0.9406 - recall: 0.9045 - val_NLL: 0.6019 - val_accuracy: 0.8286 - val_f1_score: 0.8295 - val_loss: 1.0713 - val_precision: 0.8615 - val_recall: 0.8000\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 186ms/step - NLL: 0.2148 - accuracy: 0.9256 - f1_score: 0.9257 - loss: 0.5759 - precision: 0.9361 - recall: 0.9083 - val_NLL: 0.6195 - val_accuracy: 0.8071 - val_f1_score: 0.8016 - val_loss: 1.0065 - val_precision: 0.8271 - val_recall: 0.7857\n",
      "Epoch 18/20\n",
      "42/42 - 6s - 134ms/step - NLL: 0.2271 - accuracy: 0.9241 - f1_score: 0.9243 - loss: 0.6000 - precision: 0.9415 - recall: 0.9015 - val_NLL: 0.7011 - val_accuracy: 0.7786 - val_f1_score: 0.7795 - val_loss: 1.0954 - val_precision: 0.7985 - val_recall: 0.7643\n",
      "Epoch 19/20\n",
      "42/42 - 7s - 167ms/step - NLL: 0.1775 - accuracy: 0.9357 - f1_score: 0.9358 - loss: 0.5543 - precision: 0.9490 - recall: 0.9165 - val_NLL: 0.6817 - val_accuracy: 0.7857 - val_f1_score: 0.7810 - val_loss: 1.2397 - val_precision: 0.8030 - val_recall: 0.7571\n",
      "Epoch 20/20\n",
      "42/42 - 11s - 267ms/step - NLL: 0.1484 - accuracy: 0.9511 - f1_score: 0.9512 - loss: 0.5142 - precision: 0.9605 - recall: 0.9331 - val_NLL: 0.6932 - val_accuracy: 0.8214 - val_f1_score: 0.8197 - val_loss: 1.1154 - val_precision: 0.8309 - val_recall: 0.8071\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "NLL: 0.60\n",
      "Validation accuracy: 0.80\n",
      "Validation F1Score: 0.80\n",
      "evaluating Fold 6\n",
      "Setting seed to 1027\n",
      "Epoch 1/20\n",
      "42/42 - 29s - 697ms/step - NLL: 1.9166 - accuracy: 0.3944 - f1_score: 0.3906 - loss: 2.3837 - precision: 0.7130 - recall: 0.1466 - val_NLL: 1.1187 - val_accuracy: 0.7000 - val_f1_score: 0.6857 - val_loss: 1.5670 - val_precision: 0.9180 - val_recall: 0.4000\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 188ms/step - NLL: 1.0332 - accuracy: 0.6733 - f1_score: 0.6716 - loss: 1.4260 - precision: 0.8267 - recall: 0.5184 - val_NLL: 0.9887 - val_accuracy: 0.6714 - val_f1_score: 0.6648 - val_loss: 1.3190 - val_precision: 0.7753 - val_recall: 0.4929\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 185ms/step - NLL: 0.7576 - accuracy: 0.7609 - f1_score: 0.7603 - loss: 1.1313 - precision: 0.8693 - recall: 0.6602 - val_NLL: 0.9633 - val_accuracy: 0.7000 - val_f1_score: 0.6810 - val_loss: 1.3841 - val_precision: 0.7692 - val_recall: 0.5714\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 186ms/step - NLL: 0.6532 - accuracy: 0.7823 - f1_score: 0.7820 - loss: 1.0182 - precision: 0.8676 - recall: 0.7019 - val_NLL: 1.0353 - val_accuracy: 0.6429 - val_f1_score: 0.6204 - val_loss: 1.4788 - val_precision: 0.7500 - val_recall: 0.5571\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.5504 - accuracy: 0.8188 - f1_score: 0.8186 - loss: 0.9103 - precision: 0.8876 - recall: 0.7541 - val_NLL: 0.9629 - val_accuracy: 0.6929 - val_f1_score: 0.6783 - val_loss: 1.2476 - val_precision: 0.7965 - val_recall: 0.6429\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 188ms/step - NLL: 0.4979 - accuracy: 0.8361 - f1_score: 0.8358 - loss: 0.8548 - precision: 0.8947 - recall: 0.7797 - val_NLL: 1.0084 - val_accuracy: 0.6643 - val_f1_score: 0.6321 - val_loss: 1.2928 - val_precision: 0.7699 - val_recall: 0.6214\n",
      "Epoch 7/20\n",
      "42/42 - 7s - 176ms/step - NLL: 0.4546 - accuracy: 0.8451 - f1_score: 0.8445 - loss: 0.8174 - precision: 0.9062 - recall: 0.8023 - val_NLL: 0.9346 - val_accuracy: 0.6786 - val_f1_score: 0.6701 - val_loss: 1.2187 - val_precision: 0.7699 - val_recall: 0.6214\n",
      "Epoch 8/20\n",
      "42/42 - 7s - 172ms/step - NLL: 0.4077 - accuracy: 0.8620 - f1_score: 0.8615 - loss: 0.7671 - precision: 0.9089 - recall: 0.8139 - val_NLL: 1.0914 - val_accuracy: 0.6357 - val_f1_score: 0.6090 - val_loss: 1.2336 - val_precision: 0.7203 - val_recall: 0.6071\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.3876 - accuracy: 0.8579 - f1_score: 0.8577 - loss: 0.7400 - precision: 0.9082 - recall: 0.8180 - val_NLL: 1.0094 - val_accuracy: 0.6714 - val_f1_score: 0.6542 - val_loss: 1.1449 - val_precision: 0.7500 - val_recall: 0.6429\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.3568 - accuracy: 0.8801 - f1_score: 0.8799 - loss: 0.7055 - precision: 0.9225 - recall: 0.8410 - val_NLL: 1.0015 - val_accuracy: 0.6786 - val_f1_score: 0.6637 - val_loss: 1.2225 - val_precision: 0.7500 - val_recall: 0.6214\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.3044 - accuracy: 0.8898 - f1_score: 0.8897 - loss: 0.6521 - precision: 0.9217 - recall: 0.8586 - val_NLL: 1.1312 - val_accuracy: 0.6643 - val_f1_score: 0.6384 - val_loss: 1.2522 - val_precision: 0.7143 - val_recall: 0.6429\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.2859 - accuracy: 0.9083 - f1_score: 0.9080 - loss: 0.6323 - precision: 0.9356 - recall: 0.8741 - val_NLL: 1.2037 - val_accuracy: 0.6571 - val_f1_score: 0.6265 - val_loss: 1.3525 - val_precision: 0.7025 - val_recall: 0.6071\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.2765 - accuracy: 0.9011 - f1_score: 0.9009 - loss: 0.6250 - precision: 0.9328 - recall: 0.8763 - val_NLL: 1.1261 - val_accuracy: 0.6786 - val_f1_score: 0.6570 - val_loss: 1.2197 - val_precision: 0.7131 - val_recall: 0.6214\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 188ms/step - NLL: 0.2485 - accuracy: 0.9135 - f1_score: 0.9135 - loss: 0.5985 - precision: 0.9350 - recall: 0.8917 - val_NLL: 1.1185 - val_accuracy: 0.7357 - val_f1_score: 0.7063 - val_loss: 1.1830 - val_precision: 0.7642 - val_recall: 0.6714\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.2417 - accuracy: 0.9188 - f1_score: 0.9188 - loss: 0.5937 - precision: 0.9405 - recall: 0.8914 - val_NLL: 1.1436 - val_accuracy: 0.6714 - val_f1_score: 0.6563 - val_loss: 1.2407 - val_precision: 0.7087 - val_recall: 0.6429\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 201ms/step - NLL: 0.2449 - accuracy: 0.9177 - f1_score: 0.9177 - loss: 0.6022 - precision: 0.9432 - recall: 0.8929 - val_NLL: 1.1522 - val_accuracy: 0.6286 - val_f1_score: 0.6099 - val_loss: 1.2423 - val_precision: 0.6614 - val_recall: 0.6000\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2244 - accuracy: 0.9199 - f1_score: 0.9198 - loss: 0.5809 - precision: 0.9370 - recall: 0.8951 - val_NLL: 1.1539 - val_accuracy: 0.6500 - val_f1_score: 0.6353 - val_loss: 1.3031 - val_precision: 0.6953 - val_recall: 0.6357\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "NLL: 0.93\n",
      "Validation accuracy: 0.68\n",
      "Validation F1Score: 0.67\n",
      "evaluating Fold 7\n",
      "Setting seed to 5825\n",
      "Epoch 1/20\n",
      "42/42 - 30s - 717ms/step - NLL: 1.9390 - accuracy: 0.3699 - f1_score: 0.3546 - loss: 2.3897 - precision: 0.7608 - recall: 0.1459 - val_NLL: 1.3504 - val_accuracy: 0.5357 - val_f1_score: 0.5035 - val_loss: 2.0532 - val_precision: 0.8500 - val_recall: 0.3643\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 192ms/step - NLL: 1.0680 - accuracy: 0.6538 - f1_score: 0.6538 - loss: 1.4268 - precision: 0.8498 - recall: 0.4786 - val_NLL: 0.9336 - val_accuracy: 0.7000 - val_f1_score: 0.6781 - val_loss: 1.6389 - val_precision: 0.8041 - val_recall: 0.5571\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.7630 - accuracy: 0.7466 - f1_score: 0.7471 - loss: 1.1094 - precision: 0.8602 - recall: 0.6410 - val_NLL: 0.7708 - val_accuracy: 0.7357 - val_f1_score: 0.7208 - val_loss: 1.5372 - val_precision: 0.8108 - val_recall: 0.6429\n",
      "Epoch 4/20\n",
      "42/42 - 9s - 205ms/step - NLL: 0.6417 - accuracy: 0.7891 - f1_score: 0.7893 - loss: 0.9815 - precision: 0.8828 - recall: 0.7083 - val_NLL: 0.7871 - val_accuracy: 0.7571 - val_f1_score: 0.7352 - val_loss: 1.6632 - val_precision: 0.8598 - val_recall: 0.6571\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 200ms/step - NLL: 0.5487 - accuracy: 0.8098 - f1_score: 0.8092 - loss: 0.8865 - precision: 0.8836 - recall: 0.7421 - val_NLL: 0.7504 - val_accuracy: 0.7786 - val_f1_score: 0.7602 - val_loss: 1.4528 - val_precision: 0.8167 - val_recall: 0.7000\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.4751 - accuracy: 0.8398 - f1_score: 0.8397 - loss: 0.8100 - precision: 0.8928 - recall: 0.7857 - val_NLL: 0.7749 - val_accuracy: 0.7571 - val_f1_score: 0.7281 - val_loss: 1.3775 - val_precision: 0.8049 - val_recall: 0.7071\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 200ms/step - NLL: 0.4255 - accuracy: 0.8688 - f1_score: 0.8686 - loss: 0.7587 - precision: 0.9110 - recall: 0.8120 - val_NLL: 0.7159 - val_accuracy: 0.7786 - val_f1_score: 0.7619 - val_loss: 1.3206 - val_precision: 0.8062 - val_recall: 0.7429\n",
      "Epoch 8/20\n",
      "42/42 - 10s - 239ms/step - NLL: 0.3590 - accuracy: 0.8797 - f1_score: 0.8791 - loss: 0.6979 - precision: 0.9133 - recall: 0.8391 - val_NLL: 0.7806 - val_accuracy: 0.7429 - val_f1_score: 0.7176 - val_loss: 1.4002 - val_precision: 0.7967 - val_recall: 0.7000\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 200ms/step - NLL: 0.3665 - accuracy: 0.8782 - f1_score: 0.8781 - loss: 0.7028 - precision: 0.9111 - recall: 0.8395 - val_NLL: 0.7894 - val_accuracy: 0.7571 - val_f1_score: 0.7479 - val_loss: 1.2603 - val_precision: 0.7674 - val_recall: 0.7071\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.3186 - accuracy: 0.8992 - f1_score: 0.8992 - loss: 0.6598 - precision: 0.9253 - recall: 0.8662 - val_NLL: 0.7573 - val_accuracy: 0.7643 - val_f1_score: 0.7587 - val_loss: 1.3237 - val_precision: 0.7939 - val_recall: 0.7429\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.2888 - accuracy: 0.9053 - f1_score: 0.9050 - loss: 0.6247 - precision: 0.9325 - recall: 0.8771 - val_NLL: 0.7945 - val_accuracy: 0.7857 - val_f1_score: 0.7733 - val_loss: 1.3183 - val_precision: 0.8295 - val_recall: 0.7643\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.2724 - accuracy: 0.9083 - f1_score: 0.9080 - loss: 0.6056 - precision: 0.9352 - recall: 0.8789 - val_NLL: 0.7991 - val_accuracy: 0.7643 - val_f1_score: 0.7534 - val_loss: 1.3893 - val_precision: 0.8000 - val_recall: 0.7429\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.2429 - accuracy: 0.9173 - f1_score: 0.9171 - loss: 0.5822 - precision: 0.9377 - recall: 0.8947 - val_NLL: 0.8766 - val_accuracy: 0.7571 - val_f1_score: 0.7433 - val_loss: 1.4682 - val_precision: 0.7803 - val_recall: 0.7357\n",
      "Epoch 14/20\n",
      "42/42 - 10s - 245ms/step - NLL: 0.2314 - accuracy: 0.9165 - f1_score: 0.9163 - loss: 0.5700 - precision: 0.9399 - recall: 0.8996 - val_NLL: 0.9508 - val_accuracy: 0.7429 - val_f1_score: 0.7331 - val_loss: 1.7316 - val_precision: 0.7576 - val_recall: 0.7143\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.2173 - accuracy: 0.9199 - f1_score: 0.9198 - loss: 0.5651 - precision: 0.9386 - recall: 0.9026 - val_NLL: 0.7301 - val_accuracy: 0.7571 - val_f1_score: 0.7435 - val_loss: 1.2180 - val_precision: 0.7984 - val_recall: 0.7357\n",
      "Epoch 16/20\n",
      "42/42 - 7s - 171ms/step - NLL: 0.2007 - accuracy: 0.9316 - f1_score: 0.9317 - loss: 0.5435 - precision: 0.9494 - recall: 0.9094 - val_NLL: 0.7840 - val_accuracy: 0.7714 - val_f1_score: 0.7523 - val_loss: 1.2678 - val_precision: 0.8045 - val_recall: 0.7643\n",
      "Epoch 17/20\n",
      "42/42 - 6s - 142ms/step - NLL: 0.2101 - accuracy: 0.9305 - f1_score: 0.9305 - loss: 0.5529 - precision: 0.9440 - recall: 0.9132 - val_NLL: 0.8800 - val_accuracy: 0.7571 - val_f1_score: 0.7374 - val_loss: 1.3541 - val_precision: 0.7786 - val_recall: 0.7286\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "NLL: 0.72\n",
      "Validation accuracy: 0.78\n",
      "Validation F1Score: 0.76\n",
      "evaluating Fold 8\n",
      "Setting seed to 52408\n",
      "Epoch 1/20\n",
      "42/42 - 30s - 707ms/step - NLL: 1.9044 - accuracy: 0.3962 - f1_score: 0.3903 - loss: 2.3698 - precision: 0.7328 - recall: 0.1598 - val_NLL: 1.1379 - val_accuracy: 0.6286 - val_f1_score: 0.5900 - val_loss: 1.5349 - val_precision: 0.9310 - val_recall: 0.3857\n",
      "Epoch 2/20\n",
      "42/42 - 17s - 415ms/step - NLL: 1.0795 - accuracy: 0.6658 - f1_score: 0.6659 - loss: 1.4505 - precision: 0.8117 - recall: 0.4748 - val_NLL: 0.7997 - val_accuracy: 0.7214 - val_f1_score: 0.6933 - val_loss: 1.2657 - val_precision: 0.8571 - val_recall: 0.6000\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 200ms/step - NLL: 0.7907 - accuracy: 0.7556 - f1_score: 0.7551 - loss: 1.1461 - precision: 0.8619 - recall: 0.6451 - val_NLL: 0.6437 - val_accuracy: 0.7500 - val_f1_score: 0.7358 - val_loss: 1.1169 - val_precision: 0.8376 - val_recall: 0.7000\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.6415 - accuracy: 0.7951 - f1_score: 0.7953 - loss: 0.9913 - precision: 0.8769 - recall: 0.7150 - val_NLL: 0.6049 - val_accuracy: 0.7786 - val_f1_score: 0.7724 - val_loss: 1.0085 - val_precision: 0.8512 - val_recall: 0.7357\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.5454 - accuracy: 0.8256 - f1_score: 0.8256 - loss: 0.8961 - precision: 0.8818 - recall: 0.7575 - val_NLL: 0.5789 - val_accuracy: 0.7786 - val_f1_score: 0.7771 - val_loss: 0.9840 - val_precision: 0.8403 - val_recall: 0.7143\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.4742 - accuracy: 0.8440 - f1_score: 0.8440 - loss: 0.8246 - precision: 0.8942 - recall: 0.7914 - val_NLL: 0.4878 - val_accuracy: 0.8000 - val_f1_score: 0.7960 - val_loss: 0.8901 - val_precision: 0.8400 - val_recall: 0.7500\n",
      "Epoch 7/20\n",
      "42/42 - 7s - 159ms/step - NLL: 0.4204 - accuracy: 0.8575 - f1_score: 0.8575 - loss: 0.7690 - precision: 0.8980 - recall: 0.8109 - val_NLL: 0.5001 - val_accuracy: 0.7929 - val_f1_score: 0.7862 - val_loss: 0.9169 - val_precision: 0.8333 - val_recall: 0.7500\n",
      "Epoch 8/20\n",
      "42/42 - 5s - 126ms/step - NLL: 0.3879 - accuracy: 0.8699 - f1_score: 0.8696 - loss: 0.7371 - precision: 0.9114 - recall: 0.8353 - val_NLL: 0.5571 - val_accuracy: 0.7929 - val_f1_score: 0.7812 - val_loss: 0.9875 - val_precision: 0.8689 - val_recall: 0.7571\n",
      "Epoch 9/20\n",
      "42/42 - 7s - 161ms/step - NLL: 0.3408 - accuracy: 0.8793 - f1_score: 0.8790 - loss: 0.7025 - precision: 0.9134 - recall: 0.8447 - val_NLL: 0.5444 - val_accuracy: 0.8071 - val_f1_score: 0.7966 - val_loss: 1.0004 - val_precision: 0.8618 - val_recall: 0.7571\n",
      "Epoch 10/20\n",
      "42/42 - 7s - 169ms/step - NLL: 0.3296 - accuracy: 0.8868 - f1_score: 0.8866 - loss: 0.6865 - precision: 0.9210 - recall: 0.8590 - val_NLL: 0.5189 - val_accuracy: 0.8071 - val_f1_score: 0.8007 - val_loss: 0.9274 - val_precision: 0.8618 - val_recall: 0.7571\n",
      "Epoch 11/20\n",
      "42/42 - 7s - 171ms/step - NLL: 0.2960 - accuracy: 0.9019 - f1_score: 0.9020 - loss: 0.6564 - precision: 0.9308 - recall: 0.8703 - val_NLL: 0.4234 - val_accuracy: 0.8286 - val_f1_score: 0.8253 - val_loss: 0.8416 - val_precision: 0.8594 - val_recall: 0.7857\n",
      "Epoch 12/20\n",
      "42/42 - 7s - 176ms/step - NLL: 0.2808 - accuracy: 0.9026 - f1_score: 0.9024 - loss: 0.6421 - precision: 0.9306 - recall: 0.8767 - val_NLL: 0.5019 - val_accuracy: 0.8071 - val_f1_score: 0.8055 - val_loss: 0.8994 - val_precision: 0.8333 - val_recall: 0.7857\n",
      "Epoch 13/20\n",
      "42/42 - 7s - 170ms/step - NLL: 0.2409 - accuracy: 0.9233 - f1_score: 0.9230 - loss: 0.5987 - precision: 0.9426 - recall: 0.9008 - val_NLL: 0.5325 - val_accuracy: 0.8143 - val_f1_score: 0.8063 - val_loss: 0.8726 - val_precision: 0.8672 - val_recall: 0.7929\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 179ms/step - NLL: 0.2108 - accuracy: 0.9361 - f1_score: 0.9361 - loss: 0.5593 - precision: 0.9512 - recall: 0.9094 - val_NLL: 0.5036 - val_accuracy: 0.8214 - val_f1_score: 0.8162 - val_loss: 0.8314 - val_precision: 0.8397 - val_recall: 0.7857\n",
      "Epoch 15/20\n",
      "42/42 - 7s - 171ms/step - NLL: 0.1966 - accuracy: 0.9308 - f1_score: 0.9305 - loss: 0.5397 - precision: 0.9444 - recall: 0.9128 - val_NLL: 0.5511 - val_accuracy: 0.8000 - val_f1_score: 0.7977 - val_loss: 0.8539 - val_precision: 0.8485 - val_recall: 0.8000\n",
      "Epoch 16/20\n",
      "42/42 - 7s - 176ms/step - NLL: 0.1874 - accuracy: 0.9372 - f1_score: 0.9372 - loss: 0.5352 - precision: 0.9495 - recall: 0.9252 - val_NLL: 0.5506 - val_accuracy: 0.7929 - val_f1_score: 0.7765 - val_loss: 0.8380 - val_precision: 0.8594 - val_recall: 0.7857\n",
      "Epoch 17/20\n",
      "42/42 - 7s - 172ms/step - NLL: 0.1893 - accuracy: 0.9357 - f1_score: 0.9355 - loss: 0.5418 - precision: 0.9491 - recall: 0.9180 - val_NLL: 0.5130 - val_accuracy: 0.8357 - val_f1_score: 0.8277 - val_loss: 0.9064 - val_precision: 0.8561 - val_recall: 0.8071\n",
      "Epoch 18/20\n",
      "42/42 - 7s - 178ms/step - NLL: 0.2010 - accuracy: 0.9335 - f1_score: 0.9334 - loss: 0.5528 - precision: 0.9453 - recall: 0.9165 - val_NLL: 0.5814 - val_accuracy: 0.8000 - val_f1_score: 0.7987 - val_loss: 0.8797 - val_precision: 0.8258 - val_recall: 0.7786\n",
      "Epoch 19/20\n",
      "42/42 - 7s - 173ms/step - NLL: 0.1831 - accuracy: 0.9365 - f1_score: 0.9365 - loss: 0.5411 - precision: 0.9488 - recall: 0.9192 - val_NLL: 0.4736 - val_accuracy: 0.8214 - val_f1_score: 0.8160 - val_loss: 0.8406 - val_precision: 0.8397 - val_recall: 0.7857\n",
      "Epoch 20/20\n",
      "42/42 - 7s - 173ms/step - NLL: 0.1687 - accuracy: 0.9425 - f1_score: 0.9424 - loss: 0.5321 - precision: 0.9532 - recall: 0.9256 - val_NLL: 0.5807 - val_accuracy: 0.7857 - val_f1_score: 0.7827 - val_loss: 0.9722 - val_precision: 0.8195 - val_recall: 0.7786\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "NLL: 0.42\n",
      "Validation accuracy: 0.83\n",
      "Validation F1Score: 0.83\n",
      "evaluating Fold 9\n",
      "Setting seed to 88243\n",
      "Epoch 1/20\n",
      "42/42 - 22s - 514ms/step - NLL: 1.9718 - accuracy: 0.3391 - f1_score: 0.3275 - loss: 2.4290 - precision: 0.6708 - recall: 0.1211 - val_NLL: 1.4568 - val_accuracy: 0.5429 - val_f1_score: 0.4814 - val_loss: 2.3057 - val_precision: 0.7123 - val_recall: 0.3714\n",
      "Epoch 2/20\n",
      "42/42 - 7s - 160ms/step - NLL: 1.1819 - accuracy: 0.6274 - f1_score: 0.6271 - loss: 1.5441 - precision: 0.8024 - recall: 0.4229 - val_NLL: 1.0152 - val_accuracy: 0.6143 - val_f1_score: 0.5692 - val_loss: 1.7475 - val_precision: 0.7333 - val_recall: 0.5500\n",
      "Epoch 3/20\n",
      "42/42 - 7s - 178ms/step - NLL: 0.8393 - accuracy: 0.7376 - f1_score: 0.7373 - loss: 1.1924 - precision: 0.8576 - recall: 0.6135 - val_NLL: 0.8497 - val_accuracy: 0.7000 - val_f1_score: 0.6734 - val_loss: 1.5572 - val_precision: 0.7455 - val_recall: 0.5857\n",
      "Epoch 4/20\n",
      "42/42 - 6s - 154ms/step - NLL: 0.6554 - accuracy: 0.7838 - f1_score: 0.7842 - loss: 0.9980 - precision: 0.8658 - recall: 0.6985 - val_NLL: 0.8877 - val_accuracy: 0.7429 - val_f1_score: 0.7165 - val_loss: 1.9538 - val_precision: 0.7627 - val_recall: 0.6429\n",
      "Epoch 5/20\n",
      "42/42 - 7s - 160ms/step - NLL: 0.5627 - accuracy: 0.8102 - f1_score: 0.8103 - loss: 0.9020 - precision: 0.8840 - recall: 0.7417 - val_NLL: 0.8722 - val_accuracy: 0.7429 - val_f1_score: 0.7191 - val_loss: 1.8729 - val_precision: 0.8033 - val_recall: 0.7000\n",
      "Epoch 6/20\n",
      "42/42 - 6s - 153ms/step - NLL: 0.4744 - accuracy: 0.8459 - f1_score: 0.8458 - loss: 0.8173 - precision: 0.8976 - recall: 0.7876 - val_NLL: 0.8802 - val_accuracy: 0.7286 - val_f1_score: 0.7168 - val_loss: 1.6153 - val_precision: 0.7619 - val_recall: 0.6857\n",
      "Epoch 7/20\n",
      "42/42 - 6s - 142ms/step - NLL: 0.4294 - accuracy: 0.8549 - f1_score: 0.8549 - loss: 0.7741 - precision: 0.9003 - recall: 0.8045 - val_NLL: 1.0384 - val_accuracy: 0.6714 - val_f1_score: 0.6479 - val_loss: 1.8291 - val_precision: 0.6977 - val_recall: 0.6429\n",
      "Epoch 8/20\n",
      "42/42 - 7s - 161ms/step - NLL: 0.3981 - accuracy: 0.8699 - f1_score: 0.8701 - loss: 0.7401 - precision: 0.9072 - recall: 0.8233 - val_NLL: 0.9258 - val_accuracy: 0.7786 - val_f1_score: 0.7590 - val_loss: 2.0721 - val_precision: 0.8016 - val_recall: 0.7214\n",
      "Epoch 9/20\n",
      "42/42 - 5s - 130ms/step - NLL: 0.3553 - accuracy: 0.8816 - f1_score: 0.8814 - loss: 0.6975 - precision: 0.9172 - recall: 0.8414 - val_NLL: 1.1778 - val_accuracy: 0.7357 - val_f1_score: 0.7188 - val_loss: 2.5104 - val_precision: 0.7752 - val_recall: 0.7143\n",
      "Epoch 10/20\n",
      "42/42 - 5s - 130ms/step - NLL: 0.3118 - accuracy: 0.8917 - f1_score: 0.8915 - loss: 0.6530 - precision: 0.9221 - recall: 0.8594 - val_NLL: 1.1246 - val_accuracy: 0.7214 - val_f1_score: 0.7095 - val_loss: 2.3210 - val_precision: 0.7481 - val_recall: 0.7000\n",
      "Epoch 11/20\n",
      "42/42 - 5s - 125ms/step - NLL: 0.3054 - accuracy: 0.8985 - f1_score: 0.8986 - loss: 0.6440 - precision: 0.9233 - recall: 0.8692 - val_NLL: 1.0158 - val_accuracy: 0.7286 - val_f1_score: 0.7180 - val_loss: 1.8427 - val_precision: 0.7385 - val_recall: 0.6857\n",
      "Epoch 12/20\n",
      "42/42 - 5s - 127ms/step - NLL: 0.2750 - accuracy: 0.8959 - f1_score: 0.8956 - loss: 0.6168 - precision: 0.9260 - recall: 0.8744 - val_NLL: 1.2663 - val_accuracy: 0.7143 - val_f1_score: 0.6984 - val_loss: 2.3515 - val_precision: 0.7597 - val_recall: 0.7000\n",
      "Epoch 13/20\n",
      "42/42 - 5s - 122ms/step - NLL: 0.2571 - accuracy: 0.9158 - f1_score: 0.9156 - loss: 0.5980 - precision: 0.9352 - recall: 0.8895 - val_NLL: 1.1686 - val_accuracy: 0.7500 - val_f1_score: 0.7364 - val_loss: 2.2541 - val_precision: 0.7820 - val_recall: 0.7429\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "NLL: 0.85\n",
      "Validation accuracy: 0.70\n",
      "Validation F1Score: 0.67\n",
      "evaluating Fold 10\n",
      "Setting seed to 419748\n",
      "Epoch 1/20\n",
      "42/42 - 31s - 749ms/step - NLL: 1.9668 - accuracy: 0.3440 - f1_score: 0.3431 - loss: 2.4386 - precision: 0.7341 - recall: 0.1256 - val_NLL: 1.1477 - val_accuracy: 0.6143 - val_f1_score: 0.5893 - val_loss: 1.5707 - val_precision: 0.7750 - val_recall: 0.4429\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 199ms/step - NLL: 1.2225 - accuracy: 0.6147 - f1_score: 0.6140 - loss: 1.6025 - precision: 0.7943 - recall: 0.4079 - val_NLL: 0.8113 - val_accuracy: 0.7357 - val_f1_score: 0.7231 - val_loss: 1.1921 - val_precision: 0.8095 - val_recall: 0.6071\n",
      "Epoch 3/20\n",
      "42/42 - 9s - 203ms/step - NLL: 0.8907 - accuracy: 0.7207 - f1_score: 0.7219 - loss: 1.2504 - precision: 0.8371 - recall: 0.5891 - val_NLL: 0.6148 - val_accuracy: 0.7357 - val_f1_score: 0.7238 - val_loss: 1.0491 - val_precision: 0.8197 - val_recall: 0.7143\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.7258 - accuracy: 0.7620 - f1_score: 0.7624 - loss: 1.0788 - precision: 0.8676 - recall: 0.6624 - val_NLL: 0.6754 - val_accuracy: 0.7500 - val_f1_score: 0.7385 - val_loss: 1.0196 - val_precision: 0.8235 - val_recall: 0.7000\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.6165 - accuracy: 0.8004 - f1_score: 0.8007 - loss: 0.9681 - precision: 0.8733 - recall: 0.7229 - val_NLL: 0.6829 - val_accuracy: 0.7857 - val_f1_score: 0.7726 - val_loss: 1.0426 - val_precision: 0.8293 - val_recall: 0.7286\n",
      "Epoch 6/20\n",
      "42/42 - 10s - 249ms/step - NLL: 0.5292 - accuracy: 0.8252 - f1_score: 0.8257 - loss: 0.8819 - precision: 0.8873 - recall: 0.7579 - val_NLL: 0.6465 - val_accuracy: 0.7714 - val_f1_score: 0.7627 - val_loss: 1.0704 - val_precision: 0.8320 - val_recall: 0.7429\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 200ms/step - NLL: 0.4529 - accuracy: 0.8553 - f1_score: 0.8552 - loss: 0.8034 - precision: 0.8986 - recall: 0.7929 - val_NLL: 0.6260 - val_accuracy: 0.7929 - val_f1_score: 0.7770 - val_loss: 0.9916 - val_precision: 0.8397 - val_recall: 0.7857\n",
      "Epoch 8/20\n",
      "42/42 - 9s - 207ms/step - NLL: 0.4027 - accuracy: 0.8586 - f1_score: 0.8586 - loss: 0.7522 - precision: 0.9038 - recall: 0.8192 - val_NLL: 0.6996 - val_accuracy: 0.7857 - val_f1_score: 0.7738 - val_loss: 1.0515 - val_precision: 0.8030 - val_recall: 0.7571\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 202ms/step - NLL: 0.3741 - accuracy: 0.8729 - f1_score: 0.8731 - loss: 0.7219 - precision: 0.9091 - recall: 0.8350 - val_NLL: 0.5971 - val_accuracy: 0.7929 - val_f1_score: 0.7758 - val_loss: 0.9905 - val_precision: 0.8195 - val_recall: 0.7786\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 181ms/step - NLL: 0.3413 - accuracy: 0.8850 - f1_score: 0.8853 - loss: 0.6872 - precision: 0.9169 - recall: 0.8500 - val_NLL: 0.7441 - val_accuracy: 0.7786 - val_f1_score: 0.7601 - val_loss: 1.0365 - val_precision: 0.8106 - val_recall: 0.7643\n",
      "Epoch 11/20\n",
      "42/42 - 5s - 127ms/step - NLL: 0.3193 - accuracy: 0.8872 - f1_score: 0.8872 - loss: 0.6603 - precision: 0.9194 - recall: 0.8579 - val_NLL: 0.7688 - val_accuracy: 0.7929 - val_f1_score: 0.7826 - val_loss: 1.0947 - val_precision: 0.7971 - val_recall: 0.7857\n",
      "Epoch 12/20\n",
      "42/42 - 7s - 171ms/step - NLL: 0.2857 - accuracy: 0.9034 - f1_score: 0.9035 - loss: 0.6363 - precision: 0.9275 - recall: 0.8759 - val_NLL: 0.7219 - val_accuracy: 0.7643 - val_f1_score: 0.7478 - val_loss: 1.0815 - val_precision: 0.7895 - val_recall: 0.7500\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.2773 - accuracy: 0.9075 - f1_score: 0.9078 - loss: 0.6323 - precision: 0.9341 - recall: 0.8793 - val_NLL: 0.7723 - val_accuracy: 0.8000 - val_f1_score: 0.7843 - val_loss: 1.1393 - val_precision: 0.8148 - val_recall: 0.7857\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.2580 - accuracy: 0.9109 - f1_score: 0.9108 - loss: 0.6098 - precision: 0.9323 - recall: 0.8846 - val_NLL: 0.6733 - val_accuracy: 0.7929 - val_f1_score: 0.7809 - val_loss: 0.9968 - val_precision: 0.8000 - val_recall: 0.7714\n",
      "Epoch 15/20\n",
      "42/42 - 6s - 134ms/step - NLL: 0.2574 - accuracy: 0.9165 - f1_score: 0.9166 - loss: 0.6074 - precision: 0.9380 - recall: 0.8936 - val_NLL: 0.6436 - val_accuracy: 0.8000 - val_f1_score: 0.7810 - val_loss: 0.9937 - val_precision: 0.8162 - val_recall: 0.7929\n",
      "Epoch 16/20\n",
      "42/42 - 7s - 160ms/step - NLL: 0.2163 - accuracy: 0.9282 - f1_score: 0.9282 - loss: 0.5698 - precision: 0.9405 - recall: 0.9094 - val_NLL: 0.7344 - val_accuracy: 0.7857 - val_f1_score: 0.7673 - val_loss: 0.9903 - val_precision: 0.8120 - val_recall: 0.7714\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.2354 - accuracy: 0.9180 - f1_score: 0.9180 - loss: 0.5838 - precision: 0.9359 - recall: 0.8940 - val_NLL: 0.6865 - val_accuracy: 0.8214 - val_f1_score: 0.8042 - val_loss: 1.0630 - val_precision: 0.8248 - val_recall: 0.8071\n",
      "Epoch 18/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.2260 - accuracy: 0.9244 - f1_score: 0.9245 - loss: 0.5770 - precision: 0.9389 - recall: 0.9015 - val_NLL: 0.7940 - val_accuracy: 0.7714 - val_f1_score: 0.7514 - val_loss: 1.1978 - val_precision: 0.7955 - val_recall: 0.7500\n",
      "Epoch 19/20\n",
      "42/42 - 8s - 198ms/step - NLL: 0.2096 - accuracy: 0.9248 - f1_score: 0.9248 - loss: 0.5612 - precision: 0.9385 - recall: 0.9068 - val_NLL: 0.7059 - val_accuracy: 0.7929 - val_f1_score: 0.7838 - val_loss: 1.0432 - val_precision: 0.8120 - val_recall: 0.7714\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "NLL: 0.60\n",
      "Validation accuracy: 0.79\n",
      "Validation F1Score: 0.78\n",
      "evaluating Fold 11\n",
      "Setting seed to 786191\n",
      "Epoch 1/20\n",
      "42/42 - 32s - 752ms/step - NLL: 1.8644 - accuracy: 0.3955 - f1_score: 0.3855 - loss: 2.3230 - precision: 0.7954 - recall: 0.1680 - val_NLL: 0.8369 - val_accuracy: 0.7786 - val_f1_score: 0.7618 - val_loss: 1.2788 - val_precision: 0.9167 - val_recall: 0.4714\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 200ms/step - NLL: 1.0007 - accuracy: 0.6906 - f1_score: 0.6895 - loss: 1.3705 - precision: 0.8390 - recall: 0.5368 - val_NLL: 0.6301 - val_accuracy: 0.8214 - val_f1_score: 0.8129 - val_loss: 1.0700 - val_precision: 0.8644 - val_recall: 0.7286\n",
      "Epoch 3/20\n",
      "42/42 - 7s - 163ms/step - NLL: 0.7747 - accuracy: 0.7526 - f1_score: 0.7515 - loss: 1.1277 - precision: 0.8549 - recall: 0.6466 - val_NLL: 0.6225 - val_accuracy: 0.8286 - val_f1_score: 0.8278 - val_loss: 1.0985 - val_precision: 0.8385 - val_recall: 0.7786\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.6192 - accuracy: 0.7996 - f1_score: 0.8003 - loss: 0.9634 - precision: 0.8763 - recall: 0.7109 - val_NLL: 0.7462 - val_accuracy: 0.8000 - val_f1_score: 0.7929 - val_loss: 1.2985 - val_precision: 0.8182 - val_recall: 0.7714\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.5514 - accuracy: 0.8147 - f1_score: 0.8146 - loss: 0.8931 - precision: 0.8827 - recall: 0.7440 - val_NLL: 0.6885 - val_accuracy: 0.8071 - val_f1_score: 0.7926 - val_loss: 1.2335 - val_precision: 0.8162 - val_recall: 0.7929\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 200ms/step - NLL: 0.4761 - accuracy: 0.8395 - f1_score: 0.8396 - loss: 0.8185 - precision: 0.8987 - recall: 0.7868 - val_NLL: 0.4576 - val_accuracy: 0.8286 - val_f1_score: 0.8285 - val_loss: 0.9553 - val_precision: 0.8507 - val_recall: 0.8143\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.4324 - accuracy: 0.8553 - f1_score: 0.8550 - loss: 0.7760 - precision: 0.9036 - recall: 0.8071 - val_NLL: 0.4877 - val_accuracy: 0.8357 - val_f1_score: 0.8338 - val_loss: 1.0178 - val_precision: 0.8467 - val_recall: 0.8286\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.3785 - accuracy: 0.8718 - f1_score: 0.8719 - loss: 0.7231 - precision: 0.9149 - recall: 0.8282 - val_NLL: 0.5552 - val_accuracy: 0.8286 - val_f1_score: 0.8248 - val_loss: 1.0567 - val_precision: 0.8571 - val_recall: 0.8143\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.3540 - accuracy: 0.8842 - f1_score: 0.8841 - loss: 0.6967 - precision: 0.9200 - recall: 0.8432 - val_NLL: 0.6032 - val_accuracy: 0.8143 - val_f1_score: 0.8000 - val_loss: 1.0088 - val_precision: 0.8550 - val_recall: 0.8000\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.3189 - accuracy: 0.8895 - f1_score: 0.8896 - loss: 0.6607 - precision: 0.9233 - recall: 0.8647 - val_NLL: 0.4994 - val_accuracy: 0.8429 - val_f1_score: 0.8408 - val_loss: 0.9596 - val_precision: 0.8741 - val_recall: 0.8429\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.2988 - accuracy: 0.8947 - f1_score: 0.8944 - loss: 0.6366 - precision: 0.9258 - recall: 0.8632 - val_NLL: 0.4415 - val_accuracy: 0.8643 - val_f1_score: 0.8636 - val_loss: 0.8933 - val_precision: 0.8832 - val_recall: 0.8643\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.2862 - accuracy: 0.9023 - f1_score: 0.9023 - loss: 0.6288 - precision: 0.9270 - recall: 0.8733 - val_NLL: 0.4920 - val_accuracy: 0.8500 - val_f1_score: 0.8481 - val_loss: 0.8093 - val_precision: 0.8657 - val_recall: 0.8286\n",
      "Epoch 13/20\n",
      "42/42 - 10s - 248ms/step - NLL: 0.2746 - accuracy: 0.9128 - f1_score: 0.9128 - loss: 0.6207 - precision: 0.9343 - recall: 0.8880 - val_NLL: 0.4925 - val_accuracy: 0.8500 - val_f1_score: 0.8444 - val_loss: 1.0808 - val_precision: 0.8519 - val_recall: 0.8214\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.2394 - accuracy: 0.9162 - f1_score: 0.9161 - loss: 0.5920 - precision: 0.9399 - recall: 0.8872 - val_NLL: 0.4129 - val_accuracy: 0.8786 - val_f1_score: 0.8770 - val_loss: 0.7089 - val_precision: 0.8786 - val_recall: 0.8786\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.2221 - accuracy: 0.9180 - f1_score: 0.9179 - loss: 0.5689 - precision: 0.9383 - recall: 0.8974 - val_NLL: 0.3322 - val_accuracy: 0.9000 - val_f1_score: 0.8948 - val_loss: 0.6564 - val_precision: 0.9185 - val_recall: 0.8857\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 198ms/step - NLL: 0.2033 - accuracy: 0.9308 - f1_score: 0.9307 - loss: 0.5470 - precision: 0.9466 - recall: 0.9071 - val_NLL: 0.3714 - val_accuracy: 0.8929 - val_f1_score: 0.8814 - val_loss: 0.6266 - val_precision: 0.9191 - val_recall: 0.8929\n",
      "Epoch 17/20\n",
      "42/42 - 10s - 244ms/step - NLL: 0.1968 - accuracy: 0.9308 - f1_score: 0.9308 - loss: 0.5393 - precision: 0.9453 - recall: 0.9090 - val_NLL: 0.3273 - val_accuracy: 0.8643 - val_f1_score: 0.8621 - val_loss: 0.6819 - val_precision: 0.8759 - val_recall: 0.8571\n",
      "Epoch 18/20\n",
      "42/42 - 8s - 198ms/step - NLL: 0.1899 - accuracy: 0.9353 - f1_score: 0.9353 - loss: 0.5407 - precision: 0.9505 - recall: 0.9162 - val_NLL: 0.3892 - val_accuracy: 0.8714 - val_f1_score: 0.8540 - val_loss: 0.6450 - val_precision: 0.8759 - val_recall: 0.8571\n",
      "Epoch 19/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.1948 - accuracy: 0.9308 - f1_score: 0.9307 - loss: 0.5468 - precision: 0.9434 - recall: 0.9147 - val_NLL: 0.3552 - val_accuracy: 0.8857 - val_f1_score: 0.8847 - val_loss: 0.7383 - val_precision: 0.9044 - val_recall: 0.8786\n",
      "Epoch 20/20\n",
      "42/42 - 7s - 164ms/step - NLL: 0.1630 - accuracy: 0.9425 - f1_score: 0.9424 - loss: 0.5162 - precision: 0.9577 - recall: 0.9274 - val_NLL: 0.4246 - val_accuracy: 0.8571 - val_f1_score: 0.8439 - val_loss: 0.8338 - val_precision: 0.8759 - val_recall: 0.8571\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "NLL: 0.33\n",
      "Validation accuracy: 0.86\n",
      "Validation F1Score: 0.86\n",
      "evaluating Fold 12\n",
      "Setting seed to 3907426\n",
      "Epoch 1/20\n",
      "42/42 - 33s - 788ms/step - NLL: 1.9905 - accuracy: 0.3643 - f1_score: 0.3488 - loss: 2.4592 - precision: 0.7246 - recall: 0.1365 - val_NLL: 1.5012 - val_accuracy: 0.5000 - val_f1_score: 0.4631 - val_loss: 1.7727 - val_precision: 0.7907 - val_recall: 0.2429\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 201ms/step - NLL: 1.2181 - accuracy: 0.6259 - f1_score: 0.6238 - loss: 1.5908 - precision: 0.7975 - recall: 0.4293 - val_NLL: 1.1150 - val_accuracy: 0.6071 - val_f1_score: 0.5720 - val_loss: 1.5372 - val_precision: 0.7848 - val_recall: 0.4429\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 200ms/step - NLL: 0.8484 - accuracy: 0.7282 - f1_score: 0.7269 - loss: 1.2085 - precision: 0.8541 - recall: 0.6094 - val_NLL: 0.9504 - val_accuracy: 0.6571 - val_f1_score: 0.6473 - val_loss: 1.4136 - val_precision: 0.7653 - val_recall: 0.5357\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.6881 - accuracy: 0.7793 - f1_score: 0.7794 - loss: 1.0438 - precision: 0.8678 - recall: 0.6910 - val_NLL: 0.9393 - val_accuracy: 0.6643 - val_f1_score: 0.6496 - val_loss: 1.3194 - val_precision: 0.7477 - val_recall: 0.5714\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.5630 - accuracy: 0.8211 - f1_score: 0.8212 - loss: 0.9193 - precision: 0.8827 - recall: 0.7523 - val_NLL: 0.9048 - val_accuracy: 0.6857 - val_f1_score: 0.6685 - val_loss: 1.3243 - val_precision: 0.7522 - val_recall: 0.6071\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.4908 - accuracy: 0.8432 - f1_score: 0.8436 - loss: 0.8490 - precision: 0.9005 - recall: 0.7789 - val_NLL: 0.8429 - val_accuracy: 0.6929 - val_f1_score: 0.6819 - val_loss: 1.2974 - val_precision: 0.7632 - val_recall: 0.6214\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.4163 - accuracy: 0.8545 - f1_score: 0.8543 - loss: 0.7758 - precision: 0.8978 - recall: 0.8056 - val_NLL: 0.8494 - val_accuracy: 0.6857 - val_f1_score: 0.6839 - val_loss: 1.3031 - val_precision: 0.7436 - val_recall: 0.6214\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 182ms/step - NLL: 0.3703 - accuracy: 0.8797 - f1_score: 0.8796 - loss: 0.7288 - precision: 0.9148 - recall: 0.8395 - val_NLL: 0.8558 - val_accuracy: 0.6929 - val_f1_score: 0.6945 - val_loss: 1.2019 - val_precision: 0.7339 - val_recall: 0.6500\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 180ms/step - NLL: 0.3383 - accuracy: 0.8929 - f1_score: 0.8927 - loss: 0.6962 - precision: 0.9267 - recall: 0.8508 - val_NLL: 0.8437 - val_accuracy: 0.6786 - val_f1_score: 0.6807 - val_loss: 1.3226 - val_precision: 0.7355 - val_recall: 0.6357\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.3010 - accuracy: 0.9023 - f1_score: 0.9022 - loss: 0.6605 - precision: 0.9258 - recall: 0.8722 - val_NLL: 0.8213 - val_accuracy: 0.7143 - val_f1_score: 0.7068 - val_loss: 1.2444 - val_precision: 0.7422 - val_recall: 0.6786\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 201ms/step - NLL: 0.2904 - accuracy: 0.9011 - f1_score: 0.9010 - loss: 0.6578 - precision: 0.9273 - recall: 0.8673 - val_NLL: 0.7695 - val_accuracy: 0.7143 - val_f1_score: 0.7064 - val_loss: 1.1831 - val_precision: 0.7231 - val_recall: 0.6714\n",
      "Epoch 12/20\n",
      "42/42 - 10s - 243ms/step - NLL: 0.2466 - accuracy: 0.9180 - f1_score: 0.9180 - loss: 0.6220 - precision: 0.9387 - recall: 0.8868 - val_NLL: 0.8235 - val_accuracy: 0.6857 - val_f1_score: 0.6739 - val_loss: 1.2424 - val_precision: 0.7143 - val_recall: 0.6786\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.2423 - accuracy: 0.9150 - f1_score: 0.9148 - loss: 0.6143 - precision: 0.9352 - recall: 0.8951 - val_NLL: 0.8030 - val_accuracy: 0.7000 - val_f1_score: 0.6897 - val_loss: 1.1761 - val_precision: 0.7231 - val_recall: 0.6714\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.2235 - accuracy: 0.9278 - f1_score: 0.9277 - loss: 0.5906 - precision: 0.9419 - recall: 0.9083 - val_NLL: 0.9792 - val_accuracy: 0.6857 - val_f1_score: 0.6721 - val_loss: 1.2801 - val_precision: 0.7231 - val_recall: 0.6714\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.2041 - accuracy: 0.9323 - f1_score: 0.9323 - loss: 0.5723 - precision: 0.9478 - recall: 0.9086 - val_NLL: 0.8398 - val_accuracy: 0.7143 - val_f1_score: 0.7018 - val_loss: 1.3920 - val_precision: 0.7600 - val_recall: 0.6786\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.1985 - accuracy: 0.9372 - f1_score: 0.9372 - loss: 0.5662 - precision: 0.9483 - recall: 0.9173 - val_NLL: 0.9579 - val_accuracy: 0.7429 - val_f1_score: 0.7249 - val_loss: 1.3501 - val_precision: 0.7652 - val_recall: 0.7214\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.1666 - accuracy: 0.9485 - f1_score: 0.9484 - loss: 0.5374 - precision: 0.9573 - recall: 0.9278 - val_NLL: 0.9142 - val_accuracy: 0.7429 - val_f1_score: 0.7274 - val_loss: 1.3377 - val_precision: 0.7687 - val_recall: 0.7357\n",
      "Epoch 18/20\n",
      "42/42 - 10s - 246ms/step - NLL: 0.1606 - accuracy: 0.9421 - f1_score: 0.9420 - loss: 0.5294 - precision: 0.9560 - recall: 0.9301 - val_NLL: 0.9474 - val_accuracy: 0.7357 - val_f1_score: 0.7141 - val_loss: 1.3449 - val_precision: 0.7462 - val_recall: 0.6929\n",
      "Epoch 19/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.1553 - accuracy: 0.9477 - f1_score: 0.9477 - loss: 0.5247 - precision: 0.9583 - recall: 0.9338 - val_NLL: 0.9374 - val_accuracy: 0.7286 - val_f1_score: 0.7244 - val_loss: 1.5142 - val_precision: 0.7463 - val_recall: 0.7143\n",
      "Epoch 20/20\n",
      "42/42 - 8s - 198ms/step - NLL: 0.1440 - accuracy: 0.9530 - f1_score: 0.9529 - loss: 0.5056 - precision: 0.9609 - recall: 0.9432 - val_NLL: 1.0093 - val_accuracy: 0.7143 - val_f1_score: 0.7044 - val_loss: 1.3115 - val_precision: 0.7287 - val_recall: 0.6714\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "NLL: 0.77\n",
      "Validation accuracy: 0.71\n",
      "Validation F1Score: 0.71\n",
      "evaluating Fold 13\n",
      "Setting seed to 9741265\n",
      "Epoch 1/20\n",
      "42/42 - 29s - 698ms/step - NLL: 1.8903 - accuracy: 0.3868 - f1_score: 0.3825 - loss: 2.3588 - precision: 0.7106 - recall: 0.1541 - val_NLL: 1.5518 - val_accuracy: 0.5429 - val_f1_score: 0.5211 - val_loss: 2.0340 - val_precision: 0.7879 - val_recall: 0.3714\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 196ms/step - NLL: 1.0878 - accuracy: 0.6609 - f1_score: 0.6607 - loss: 1.4728 - precision: 0.8086 - recall: 0.4797 - val_NLL: 1.0638 - val_accuracy: 0.6786 - val_f1_score: 0.6644 - val_loss: 1.4276 - val_precision: 0.7835 - val_recall: 0.5429\n",
      "Epoch 3/20\n",
      "42/42 - 10s - 248ms/step - NLL: 0.8217 - accuracy: 0.7440 - f1_score: 0.7440 - loss: 1.1917 - precision: 0.8416 - recall: 0.6252 - val_NLL: 0.8669 - val_accuracy: 0.7286 - val_f1_score: 0.7059 - val_loss: 1.0566 - val_precision: 0.8246 - val_recall: 0.6714\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.6541 - accuracy: 0.7838 - f1_score: 0.7840 - loss: 1.0214 - precision: 0.8612 - recall: 0.6929 - val_NLL: 0.8225 - val_accuracy: 0.7500 - val_f1_score: 0.7199 - val_loss: 1.1101 - val_precision: 0.8435 - val_recall: 0.6929\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.5513 - accuracy: 0.8214 - f1_score: 0.8220 - loss: 0.9146 - precision: 0.8834 - recall: 0.7545 - val_NLL: 0.7085 - val_accuracy: 0.7714 - val_f1_score: 0.7383 - val_loss: 0.9604 - val_precision: 0.8607 - val_recall: 0.7500\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 198ms/step - NLL: 0.4765 - accuracy: 0.8444 - f1_score: 0.8445 - loss: 0.8407 - precision: 0.8982 - recall: 0.7895 - val_NLL: 0.7555 - val_accuracy: 0.7643 - val_f1_score: 0.7238 - val_loss: 1.0052 - val_precision: 0.8203 - val_recall: 0.7500\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 202ms/step - NLL: 0.4122 - accuracy: 0.8658 - f1_score: 0.8657 - loss: 0.7798 - precision: 0.9045 - recall: 0.8154 - val_NLL: 0.6854 - val_accuracy: 0.7786 - val_f1_score: 0.7504 - val_loss: 1.0055 - val_precision: 0.8560 - val_recall: 0.7643\n",
      "Epoch 8/20\n",
      "42/42 - 9s - 204ms/step - NLL: 0.3665 - accuracy: 0.8744 - f1_score: 0.8742 - loss: 0.7301 - precision: 0.9092 - recall: 0.8357 - val_NLL: 0.7149 - val_accuracy: 0.7714 - val_f1_score: 0.7399 - val_loss: 1.0104 - val_precision: 0.8480 - val_recall: 0.7571\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.3481 - accuracy: 0.8868 - f1_score: 0.8869 - loss: 0.7083 - precision: 0.9115 - recall: 0.8444 - val_NLL: 0.7721 - val_accuracy: 0.7643 - val_f1_score: 0.7245 - val_loss: 1.0964 - val_precision: 0.8268 - val_recall: 0.7500\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.3143 - accuracy: 0.8977 - f1_score: 0.8976 - loss: 0.6787 - precision: 0.9242 - recall: 0.8669 - val_NLL: 0.8163 - val_accuracy: 0.7714 - val_f1_score: 0.7440 - val_loss: 1.0169 - val_precision: 0.8244 - val_recall: 0.7714\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.2774 - accuracy: 0.9041 - f1_score: 0.9042 - loss: 0.6418 - precision: 0.9298 - recall: 0.8718 - val_NLL: 0.8473 - val_accuracy: 0.7857 - val_f1_score: 0.7553 - val_loss: 1.0520 - val_precision: 0.8295 - val_recall: 0.7643\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.2691 - accuracy: 0.9079 - f1_score: 0.9076 - loss: 0.6294 - precision: 0.9352 - recall: 0.8793 - val_NLL: 0.8376 - val_accuracy: 0.7643 - val_f1_score: 0.7244 - val_loss: 1.1222 - val_precision: 0.8125 - val_recall: 0.7429\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.2630 - accuracy: 0.9000 - f1_score: 0.9003 - loss: 0.6276 - precision: 0.9256 - recall: 0.8793 - val_NLL: 0.9825 - val_accuracy: 0.7643 - val_f1_score: 0.7248 - val_loss: 1.1976 - val_precision: 0.7985 - val_recall: 0.7643\n",
      "Epoch 14/20\n",
      "42/42 - 7s - 168ms/step - NLL: 0.2443 - accuracy: 0.9139 - f1_score: 0.9138 - loss: 0.6130 - precision: 0.9332 - recall: 0.8932 - val_NLL: 1.0203 - val_accuracy: 0.7500 - val_f1_score: 0.7114 - val_loss: 1.3121 - val_precision: 0.7761 - val_recall: 0.7429\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.2061 - accuracy: 0.9252 - f1_score: 0.9250 - loss: 0.5757 - precision: 0.9415 - recall: 0.9083 - val_NLL: 0.9769 - val_accuracy: 0.7643 - val_f1_score: 0.7293 - val_loss: 1.1219 - val_precision: 0.8203 - val_recall: 0.7500\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.2059 - accuracy: 0.9259 - f1_score: 0.9257 - loss: 0.5749 - precision: 0.9391 - recall: 0.9105 - val_NLL: 1.0240 - val_accuracy: 0.7714 - val_f1_score: 0.7348 - val_loss: 1.1889 - val_precision: 0.7926 - val_recall: 0.7643\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.1837 - accuracy: 0.9353 - f1_score: 0.9353 - loss: 0.5484 - precision: 0.9477 - recall: 0.9195 - val_NLL: 1.1929 - val_accuracy: 0.7714 - val_f1_score: 0.7386 - val_loss: 1.2324 - val_precision: 0.8000 - val_recall: 0.7714\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "NLL: 0.69\n",
      "Validation accuracy: 0.78\n",
      "Validation F1Score: 0.75\n",
      "evaluating Fold 14\n",
      "Setting seed to 20465670\n",
      "Epoch 1/20\n",
      "42/42 - 31s - 746ms/step - NLL: 1.8966 - accuracy: 0.3917 - f1_score: 0.3893 - loss: 2.3648 - precision: 0.7235 - recall: 0.1515 - val_NLL: 1.6460 - val_accuracy: 0.5286 - val_f1_score: 0.5010 - val_loss: 1.8574 - val_precision: 0.8163 - val_recall: 0.2857\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 193ms/step - NLL: 1.0485 - accuracy: 0.6662 - f1_score: 0.6642 - loss: 1.4180 - precision: 0.8146 - recall: 0.4921 - val_NLL: 1.2165 - val_accuracy: 0.6071 - val_f1_score: 0.5933 - val_loss: 1.4687 - val_precision: 0.7857 - val_recall: 0.4714\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.7662 - accuracy: 0.7508 - f1_score: 0.7504 - loss: 1.1145 - precision: 0.8462 - recall: 0.6451 - val_NLL: 1.0928 - val_accuracy: 0.6429 - val_f1_score: 0.6401 - val_loss: 1.4697 - val_precision: 0.7624 - val_recall: 0.5500\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.6128 - accuracy: 0.7917 - f1_score: 0.7910 - loss: 0.9534 - precision: 0.8676 - recall: 0.7169 - val_NLL: 1.1490 - val_accuracy: 0.6357 - val_f1_score: 0.6363 - val_loss: 1.5561 - val_precision: 0.7196 - val_recall: 0.5500\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.5497 - accuracy: 0.8195 - f1_score: 0.8195 - loss: 0.8848 - precision: 0.8822 - recall: 0.7489 - val_NLL: 1.0360 - val_accuracy: 0.6786 - val_f1_score: 0.6720 - val_loss: 1.3817 - val_precision: 0.7500 - val_recall: 0.5786\n",
      "Epoch 6/20\n",
      "42/42 - 7s - 166ms/step - NLL: 0.5000 - accuracy: 0.8289 - f1_score: 0.8282 - loss: 0.8391 - precision: 0.8845 - recall: 0.7714 - val_NLL: 0.9510 - val_accuracy: 0.6714 - val_f1_score: 0.6685 - val_loss: 1.3354 - val_precision: 0.7321 - val_recall: 0.5857\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.4483 - accuracy: 0.8515 - f1_score: 0.8509 - loss: 0.7881 - precision: 0.8995 - recall: 0.7906 - val_NLL: 0.8942 - val_accuracy: 0.7143 - val_f1_score: 0.7049 - val_loss: 1.2645 - val_precision: 0.7719 - val_recall: 0.6286\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.4033 - accuracy: 0.8590 - f1_score: 0.8588 - loss: 0.7415 - precision: 0.9033 - recall: 0.8184 - val_NLL: 0.9371 - val_accuracy: 0.6643 - val_f1_score: 0.6632 - val_loss: 1.3642 - val_precision: 0.7658 - val_recall: 0.6071\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.3727 - accuracy: 0.8703 - f1_score: 0.8703 - loss: 0.7109 - precision: 0.9115 - recall: 0.8323 - val_NLL: 0.9777 - val_accuracy: 0.6857 - val_f1_score: 0.6854 - val_loss: 1.3755 - val_precision: 0.7117 - val_recall: 0.5643\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.3532 - accuracy: 0.8744 - f1_score: 0.8742 - loss: 0.6939 - precision: 0.9126 - recall: 0.8361 - val_NLL: 0.9440 - val_accuracy: 0.6857 - val_f1_score: 0.6690 - val_loss: 1.3363 - val_precision: 0.7436 - val_recall: 0.6214\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.3060 - accuracy: 0.8910 - f1_score: 0.8908 - loss: 0.6451 - precision: 0.9198 - recall: 0.8583 - val_NLL: 0.8856 - val_accuracy: 0.6714 - val_f1_score: 0.6645 - val_loss: 1.2552 - val_precision: 0.7311 - val_recall: 0.6214\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.2717 - accuracy: 0.9053 - f1_score: 0.9049 - loss: 0.6055 - precision: 0.9274 - recall: 0.8786 - val_NLL: 1.0699 - val_accuracy: 0.6857 - val_f1_score: 0.6833 - val_loss: 1.4698 - val_precision: 0.7087 - val_recall: 0.6429\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2595 - accuracy: 0.9083 - f1_score: 0.9082 - loss: 0.5922 - precision: 0.9300 - recall: 0.8838 - val_NLL: 0.8414 - val_accuracy: 0.7500 - val_f1_score: 0.7446 - val_loss: 1.2247 - val_precision: 0.7600 - val_recall: 0.6786\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.2522 - accuracy: 0.9150 - f1_score: 0.9151 - loss: 0.5904 - precision: 0.9321 - recall: 0.8883 - val_NLL: 1.0837 - val_accuracy: 0.6857 - val_f1_score: 0.6874 - val_loss: 1.6148 - val_precision: 0.7165 - val_recall: 0.6500\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.2344 - accuracy: 0.9188 - f1_score: 0.9186 - loss: 0.5724 - precision: 0.9297 - recall: 0.8996 - val_NLL: 1.1420 - val_accuracy: 0.6643 - val_f1_score: 0.6585 - val_loss: 1.7843 - val_precision: 0.6846 - val_recall: 0.6357\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.2317 - accuracy: 0.9169 - f1_score: 0.9166 - loss: 0.5726 - precision: 0.9330 - recall: 0.8947 - val_NLL: 1.0085 - val_accuracy: 0.6929 - val_f1_score: 0.6907 - val_loss: 1.4827 - val_precision: 0.7402 - val_recall: 0.6714\n",
      "Epoch 17/20\n",
      "42/42 - 10s - 243ms/step - NLL: 0.2209 - accuracy: 0.9229 - f1_score: 0.9228 - loss: 0.5666 - precision: 0.9430 - recall: 0.9026 - val_NLL: 1.0724 - val_accuracy: 0.7143 - val_f1_score: 0.7020 - val_loss: 1.7398 - val_precision: 0.7559 - val_recall: 0.6857\n",
      "Epoch 18/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.1905 - accuracy: 0.9387 - f1_score: 0.9386 - loss: 0.5375 - precision: 0.9523 - recall: 0.9222 - val_NLL: 1.0343 - val_accuracy: 0.6929 - val_f1_score: 0.6833 - val_loss: 1.4145 - val_precision: 0.7073 - val_recall: 0.6214\n",
      "Epoch 19/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.1862 - accuracy: 0.9350 - f1_score: 0.9352 - loss: 0.5304 - precision: 0.9486 - recall: 0.9154 - val_NLL: 1.1523 - val_accuracy: 0.6786 - val_f1_score: 0.6631 - val_loss: 1.5528 - val_precision: 0.7154 - val_recall: 0.6643\n",
      "Epoch 20/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.1817 - accuracy: 0.9395 - f1_score: 0.9392 - loss: 0.5221 - precision: 0.9527 - recall: 0.9241 - val_NLL: 1.0522 - val_accuracy: 0.7000 - val_f1_score: 0.6877 - val_loss: 1.5124 - val_precision: 0.7054 - val_recall: 0.6500\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "NLL: 0.84\n",
      "Validation accuracy: 0.75\n",
      "Validation F1Score: 0.74\n",
      "evaluating Fold 15\n",
      "Setting seed to 80337754\n",
      "Epoch 1/20\n",
      "42/42 - 33s - 789ms/step - NLL: 1.8946 - accuracy: 0.4015 - f1_score: 0.3850 - loss: 2.3495 - precision: 0.7904 - recall: 0.1673 - val_NLL: 0.7908 - val_accuracy: 0.7571 - val_f1_score: 0.7387 - val_loss: 1.4129 - val_precision: 0.9101 - val_recall: 0.5786\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 201ms/step - NLL: 1.1209 - accuracy: 0.6429 - f1_score: 0.6408 - loss: 1.4829 - precision: 0.7982 - recall: 0.4639 - val_NLL: 0.5950 - val_accuracy: 0.7929 - val_f1_score: 0.7817 - val_loss: 1.1561 - val_precision: 0.8807 - val_recall: 0.6857\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.8227 - accuracy: 0.7368 - f1_score: 0.7363 - loss: 1.1639 - precision: 0.8527 - recall: 0.6135 - val_NLL: 0.3460 - val_accuracy: 0.8857 - val_f1_score: 0.8824 - val_loss: 0.8947 - val_precision: 0.9286 - val_recall: 0.8357\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.6718 - accuracy: 0.7771 - f1_score: 0.7757 - loss: 1.0054 - precision: 0.8638 - recall: 0.6917 - val_NLL: 0.3007 - val_accuracy: 0.9000 - val_f1_score: 0.8944 - val_loss: 0.8443 - val_precision: 0.9516 - val_recall: 0.8429\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.5558 - accuracy: 0.8154 - f1_score: 0.8160 - loss: 0.8880 - precision: 0.8853 - recall: 0.7459 - val_NLL: 0.3107 - val_accuracy: 0.9000 - val_f1_score: 0.8914 - val_loss: 0.8583 - val_precision: 0.9462 - val_recall: 0.8786\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 201ms/step - NLL: 0.5238 - accuracy: 0.8222 - f1_score: 0.8221 - loss: 0.8514 - precision: 0.8789 - recall: 0.7504 - val_NLL: 0.2408 - val_accuracy: 0.9357 - val_f1_score: 0.9325 - val_loss: 0.8060 - val_precision: 0.9545 - val_recall: 0.9000\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.4666 - accuracy: 0.8410 - f1_score: 0.8411 - loss: 0.7998 - precision: 0.8918 - recall: 0.7838 - val_NLL: 0.2418 - val_accuracy: 0.9286 - val_f1_score: 0.9247 - val_loss: 0.7339 - val_precision: 0.9764 - val_recall: 0.8857\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 202ms/step - NLL: 0.4212 - accuracy: 0.8492 - f1_score: 0.8492 - loss: 0.7565 - precision: 0.8977 - recall: 0.7947 - val_NLL: 0.2329 - val_accuracy: 0.9286 - val_f1_score: 0.9242 - val_loss: 0.7427 - val_precision: 0.9692 - val_recall: 0.9000\n",
      "Epoch 9/20\n",
      "42/42 - 7s - 165ms/step - NLL: 0.3782 - accuracy: 0.8699 - f1_score: 0.8701 - loss: 0.7094 - precision: 0.9130 - recall: 0.8282 - val_NLL: 0.2050 - val_accuracy: 0.9357 - val_f1_score: 0.9322 - val_loss: 0.6917 - val_precision: 0.9697 - val_recall: 0.9143\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.3615 - accuracy: 0.8692 - f1_score: 0.8689 - loss: 0.6975 - precision: 0.9077 - recall: 0.8357 - val_NLL: 0.2366 - val_accuracy: 0.9214 - val_f1_score: 0.9176 - val_loss: 0.7685 - val_precision: 0.9535 - val_recall: 0.8786\n",
      "Epoch 11/20\n",
      "42/42 - 10s - 245ms/step - NLL: 0.3283 - accuracy: 0.8786 - f1_score: 0.8786 - loss: 0.6654 - precision: 0.9127 - recall: 0.8410 - val_NLL: 0.3300 - val_accuracy: 0.9071 - val_f1_score: 0.8998 - val_loss: 0.9207 - val_precision: 0.9242 - val_recall: 0.8714\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 200ms/step - NLL: 0.2850 - accuracy: 0.9041 - f1_score: 0.9043 - loss: 0.6176 - precision: 0.9357 - recall: 0.8752 - val_NLL: 0.3060 - val_accuracy: 0.9000 - val_f1_score: 0.8895 - val_loss: 0.9008 - val_precision: 0.9237 - val_recall: 0.8643\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.2690 - accuracy: 0.9049 - f1_score: 0.9045 - loss: 0.6028 - precision: 0.9316 - recall: 0.8812 - val_NLL: 0.2402 - val_accuracy: 0.9357 - val_f1_score: 0.9330 - val_loss: 0.6553 - val_precision: 0.9559 - val_recall: 0.9286\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2595 - accuracy: 0.9056 - f1_score: 0.9058 - loss: 0.5949 - precision: 0.9306 - recall: 0.8827 - val_NLL: 0.2567 - val_accuracy: 0.9357 - val_f1_score: 0.9311 - val_loss: 0.7265 - val_precision: 0.9549 - val_recall: 0.9071\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.2377 - accuracy: 0.9139 - f1_score: 0.9140 - loss: 0.5781 - precision: 0.9340 - recall: 0.8932 - val_NLL: 0.2750 - val_accuracy: 0.9143 - val_f1_score: 0.9091 - val_loss: 0.6914 - val_precision: 0.9470 - val_recall: 0.8929\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.2281 - accuracy: 0.9162 - f1_score: 0.9159 - loss: 0.5624 - precision: 0.9389 - recall: 0.8947 - val_NLL: 0.2407 - val_accuracy: 0.9286 - val_f1_score: 0.9245 - val_loss: 0.6948 - val_precision: 0.9485 - val_recall: 0.9214\n",
      "Epoch 17/20\n",
      "42/42 - 10s - 246ms/step - NLL: 0.2215 - accuracy: 0.9214 - f1_score: 0.9216 - loss: 0.5612 - precision: 0.9380 - recall: 0.8992 - val_NLL: 0.2974 - val_accuracy: 0.8929 - val_f1_score: 0.8855 - val_loss: 0.8326 - val_precision: 0.9313 - val_recall: 0.8714\n",
      "Epoch 18/20\n",
      "42/42 - 8s - 198ms/step - NLL: 0.2108 - accuracy: 0.9274 - f1_score: 0.9272 - loss: 0.5469 - precision: 0.9438 - recall: 0.9090 - val_NLL: 0.2594 - val_accuracy: 0.9357 - val_f1_score: 0.9292 - val_loss: 0.6619 - val_precision: 0.9489 - val_recall: 0.9286\n",
      "Epoch 19/20\n",
      "42/42 - 8s - 200ms/step - NLL: 0.2355 - accuracy: 0.9132 - f1_score: 0.9130 - loss: 0.5876 - precision: 0.9301 - recall: 0.8910 - val_NLL: 0.2545 - val_accuracy: 0.9286 - val_f1_score: 0.9252 - val_loss: 0.7705 - val_precision: 0.9627 - val_recall: 0.9214\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "NLL: 0.20\n",
      "Validation accuracy: 0.94\n",
      "Validation F1Score: 0.93\n",
      "evaluating Fold 16\n",
      "Setting seed to 123456789\n",
      "Epoch 1/20\n",
      "42/42 - 29s - 681ms/step - NLL: 1.9118 - accuracy: 0.3707 - f1_score: 0.3672 - loss: 2.3696 - precision: 0.7657 - recall: 0.1511 - val_NLL: 1.1084 - val_accuracy: 0.6786 - val_f1_score: 0.6565 - val_loss: 1.5802 - val_precision: 0.9130 - val_recall: 0.4500\n",
      "Epoch 2/20\n",
      "42/42 - 9s - 203ms/step - NLL: 1.0789 - accuracy: 0.6560 - f1_score: 0.6542 - loss: 1.4463 - precision: 0.8214 - recall: 0.4910 - val_NLL: 0.7696 - val_accuracy: 0.7500 - val_f1_score: 0.7456 - val_loss: 1.3131 - val_precision: 0.9195 - val_recall: 0.5714\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.8063 - accuracy: 0.7414 - f1_score: 0.7405 - loss: 1.1604 - precision: 0.8551 - recall: 0.6301 - val_NLL: 0.5255 - val_accuracy: 0.8429 - val_f1_score: 0.8449 - val_loss: 0.9983 - val_precision: 0.9725 - val_recall: 0.7571\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.6662 - accuracy: 0.7925 - f1_score: 0.7917 - loss: 1.0145 - precision: 0.8767 - recall: 0.6974 - val_NLL: 0.4768 - val_accuracy: 0.8643 - val_f1_score: 0.8645 - val_loss: 0.9541 - val_precision: 0.9412 - val_recall: 0.8000\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.5398 - accuracy: 0.8203 - f1_score: 0.8203 - loss: 0.8845 - precision: 0.8808 - recall: 0.7556 - val_NLL: 0.4319 - val_accuracy: 0.8357 - val_f1_score: 0.8357 - val_loss: 0.9143 - val_precision: 0.9244 - val_recall: 0.7857\n",
      "Epoch 6/20\n",
      "42/42 - 10s - 240ms/step - NLL: 0.5051 - accuracy: 0.8331 - f1_score: 0.8329 - loss: 0.8491 - precision: 0.8924 - recall: 0.7699 - val_NLL: 0.4317 - val_accuracy: 0.8357 - val_f1_score: 0.8303 - val_loss: 0.9111 - val_precision: 0.9350 - val_recall: 0.8214\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.4630 - accuracy: 0.8474 - f1_score: 0.8473 - loss: 0.8103 - precision: 0.8960 - recall: 0.7970 - val_NLL: 0.3909 - val_accuracy: 0.8429 - val_f1_score: 0.8374 - val_loss: 0.8343 - val_precision: 0.9180 - val_recall: 0.8000\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.3910 - accuracy: 0.8699 - f1_score: 0.8695 - loss: 0.7356 - precision: 0.9112 - recall: 0.8256 - val_NLL: 0.4073 - val_accuracy: 0.8571 - val_f1_score: 0.8517 - val_loss: 0.8737 - val_precision: 0.9127 - val_recall: 0.8214\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.3559 - accuracy: 0.8771 - f1_score: 0.8764 - loss: 0.7036 - precision: 0.9159 - recall: 0.8391 - val_NLL: 0.4510 - val_accuracy: 0.8357 - val_f1_score: 0.8298 - val_loss: 0.9377 - val_precision: 0.8915 - val_recall: 0.8214\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.3430 - accuracy: 0.8778 - f1_score: 0.8778 - loss: 0.6912 - precision: 0.9099 - recall: 0.8395 - val_NLL: 0.3649 - val_accuracy: 0.8786 - val_f1_score: 0.8790 - val_loss: 0.8842 - val_precision: 0.9070 - val_recall: 0.8357\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.2958 - accuracy: 0.8962 - f1_score: 0.8962 - loss: 0.6427 - precision: 0.9238 - recall: 0.8654 - val_NLL: 0.3861 - val_accuracy: 0.8714 - val_f1_score: 0.8720 - val_loss: 0.8635 - val_precision: 0.8931 - val_recall: 0.8357\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2531 - accuracy: 0.9079 - f1_score: 0.9076 - loss: 0.6044 - precision: 0.9344 - recall: 0.8842 - val_NLL: 0.3823 - val_accuracy: 0.8857 - val_f1_score: 0.8848 - val_loss: 0.8754 - val_precision: 0.8955 - val_recall: 0.8571\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.2766 - accuracy: 0.9071 - f1_score: 0.9072 - loss: 0.6239 - precision: 0.9316 - recall: 0.8853 - val_NLL: 0.3916 - val_accuracy: 0.8786 - val_f1_score: 0.8777 - val_loss: 0.9469 - val_precision: 0.8955 - val_recall: 0.8571\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.2203 - accuracy: 0.9263 - f1_score: 0.9262 - loss: 0.5707 - precision: 0.9463 - recall: 0.9075 - val_NLL: 0.4118 - val_accuracy: 0.8500 - val_f1_score: 0.8472 - val_loss: 0.9808 - val_precision: 0.8864 - val_recall: 0.8357\n",
      "Epoch 15/20\n",
      "42/42 - 7s - 171ms/step - NLL: 0.2131 - accuracy: 0.9289 - f1_score: 0.9288 - loss: 0.5653 - precision: 0.9461 - recall: 0.9098 - val_NLL: 0.4068 - val_accuracy: 0.8714 - val_f1_score: 0.8697 - val_loss: 0.9742 - val_precision: 0.8768 - val_recall: 0.8643\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.1950 - accuracy: 0.9387 - f1_score: 0.9387 - loss: 0.5431 - precision: 0.9530 - recall: 0.9226 - val_NLL: 0.3956 - val_accuracy: 0.8500 - val_f1_score: 0.8455 - val_loss: 0.9667 - val_precision: 0.8947 - val_recall: 0.8500\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.1833 - accuracy: 0.9447 - f1_score: 0.9448 - loss: 0.5311 - precision: 0.9565 - recall: 0.9252 - val_NLL: 0.4845 - val_accuracy: 0.8571 - val_f1_score: 0.8517 - val_loss: 1.0361 - val_precision: 0.8750 - val_recall: 0.8500\n",
      "Epoch 18/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.1928 - accuracy: 0.9338 - f1_score: 0.9339 - loss: 0.5444 - precision: 0.9461 - recall: 0.9173 - val_NLL: 0.3864 - val_accuracy: 0.8786 - val_f1_score: 0.8779 - val_loss: 0.9311 - val_precision: 0.9084 - val_recall: 0.8500\n",
      "Epoch 19/20\n",
      "42/42 - 8s - 202ms/step - NLL: 0.1700 - accuracy: 0.9372 - f1_score: 0.9372 - loss: 0.5211 - precision: 0.9496 - recall: 0.9274 - val_NLL: 0.4578 - val_accuracy: 0.8643 - val_f1_score: 0.8547 - val_loss: 1.0711 - val_precision: 0.8939 - val_recall: 0.8429\n",
      "Epoch 20/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.1740 - accuracy: 0.9387 - f1_score: 0.9387 - loss: 0.5249 - precision: 0.9543 - recall: 0.9263 - val_NLL: 0.4066 - val_accuracy: 0.8786 - val_f1_score: 0.8771 - val_loss: 0.9987 - val_precision: 0.9084 - val_recall: 0.8500\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "NLL: 0.36\n",
      "Validation accuracy: 0.88\n",
      "Validation F1Score: 0.88\n",
      "evaluating Fold 17\n",
      "Setting seed to 966726221\n",
      "Epoch 1/20\n",
      "42/42 - 32s - 773ms/step - NLL: 1.7827 - accuracy: 0.4256 - f1_score: 0.4161 - loss: 2.2429 - precision: 0.7982 - recall: 0.1947 - val_NLL: 1.4706 - val_accuracy: 0.5857 - val_f1_score: 0.5860 - val_loss: 1.7371 - val_precision: 0.7069 - val_recall: 0.2929\n",
      "Epoch 2/20\n",
      "42/42 - 17s - 395ms/step - NLL: 0.9376 - accuracy: 0.7098 - f1_score: 0.7083 - loss: 1.3117 - precision: 0.8334 - recall: 0.5568 - val_NLL: 1.1492 - val_accuracy: 0.6500 - val_f1_score: 0.6337 - val_loss: 1.4111 - val_precision: 0.7800 - val_recall: 0.5571\n",
      "Epoch 3/20\n",
      "42/42 - 11s - 262ms/step - NLL: 0.6938 - accuracy: 0.7688 - f1_score: 0.7684 - loss: 1.0515 - precision: 0.8640 - recall: 0.6857 - val_NLL: 1.1590 - val_accuracy: 0.6643 - val_f1_score: 0.6683 - val_loss: 1.4204 - val_precision: 0.7500 - val_recall: 0.6000\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.5933 - accuracy: 0.8083 - f1_score: 0.8083 - loss: 0.9435 - precision: 0.8708 - recall: 0.7297 - val_NLL: 1.1660 - val_accuracy: 0.6643 - val_f1_score: 0.6681 - val_loss: 1.4074 - val_precision: 0.7232 - val_recall: 0.5786\n",
      "Epoch 5/20\n",
      "42/42 - 11s - 253ms/step - NLL: 0.4926 - accuracy: 0.8365 - f1_score: 0.8365 - loss: 0.8375 - precision: 0.8959 - recall: 0.7827 - val_NLL: 1.1322 - val_accuracy: 0.6857 - val_f1_score: 0.6860 - val_loss: 1.3886 - val_precision: 0.7456 - val_recall: 0.6071\n",
      "Epoch 6/20\n",
      "42/42 - 10s - 244ms/step - NLL: 0.4496 - accuracy: 0.8417 - f1_score: 0.8413 - loss: 0.7915 - precision: 0.8953 - recall: 0.7944 - val_NLL: 1.0443 - val_accuracy: 0.7071 - val_f1_score: 0.7086 - val_loss: 1.3400 - val_precision: 0.8165 - val_recall: 0.6357\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.3965 - accuracy: 0.8620 - f1_score: 0.8623 - loss: 0.7396 - precision: 0.9052 - recall: 0.8188 - val_NLL: 1.1217 - val_accuracy: 0.6571 - val_f1_score: 0.6518 - val_loss: 1.3872 - val_precision: 0.7589 - val_recall: 0.6071\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 195ms/step - NLL: 0.3560 - accuracy: 0.8868 - f1_score: 0.8868 - loss: 0.6953 - precision: 0.9155 - recall: 0.8474 - val_NLL: 1.1314 - val_accuracy: 0.6643 - val_f1_score: 0.6562 - val_loss: 1.4402 - val_precision: 0.7459 - val_recall: 0.6500\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.3248 - accuracy: 0.8846 - f1_score: 0.8844 - loss: 0.6707 - precision: 0.9167 - recall: 0.8519 - val_NLL: 1.0513 - val_accuracy: 0.7000 - val_f1_score: 0.6964 - val_loss: 1.2454 - val_precision: 0.7863 - val_recall: 0.6571\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 198ms/step - NLL: 0.3088 - accuracy: 0.8921 - f1_score: 0.8921 - loss: 0.6550 - precision: 0.9165 - recall: 0.8586 - val_NLL: 1.0330 - val_accuracy: 0.6929 - val_f1_score: 0.6774 - val_loss: 1.2314 - val_precision: 0.7931 - val_recall: 0.6571\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 198ms/step - NLL: 0.2940 - accuracy: 0.8989 - f1_score: 0.8986 - loss: 0.6470 - precision: 0.9257 - recall: 0.8707 - val_NLL: 1.0020 - val_accuracy: 0.7357 - val_f1_score: 0.7259 - val_loss: 1.2876 - val_precision: 0.8136 - val_recall: 0.6857\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2562 - accuracy: 0.9090 - f1_score: 0.9089 - loss: 0.6086 - precision: 0.9335 - recall: 0.8812 - val_NLL: 1.0466 - val_accuracy: 0.6857 - val_f1_score: 0.6853 - val_loss: 1.2855 - val_precision: 0.7583 - val_recall: 0.6500\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2187 - accuracy: 0.9195 - f1_score: 0.9195 - loss: 0.5689 - precision: 0.9378 - recall: 0.9019 - val_NLL: 1.1256 - val_accuracy: 0.6857 - val_f1_score: 0.6853 - val_loss: 1.3812 - val_precision: 0.7381 - val_recall: 0.6643\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2209 - accuracy: 0.9218 - f1_score: 0.9218 - loss: 0.5767 - precision: 0.9430 - recall: 0.9023 - val_NLL: 1.1721 - val_accuracy: 0.6929 - val_f1_score: 0.6846 - val_loss: 1.3477 - val_precision: 0.7344 - val_recall: 0.6714\n",
      "Epoch 15/20\n",
      "42/42 - 11s - 252ms/step - NLL: 0.2227 - accuracy: 0.9229 - f1_score: 0.9228 - loss: 0.5756 - precision: 0.9367 - recall: 0.9019 - val_NLL: 1.2223 - val_accuracy: 0.6643 - val_f1_score: 0.6593 - val_loss: 1.4412 - val_precision: 0.7188 - val_recall: 0.6571\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.1839 - accuracy: 0.9365 - f1_score: 0.9364 - loss: 0.5331 - precision: 0.9464 - recall: 0.9233 - val_NLL: 1.2612 - val_accuracy: 0.6500 - val_f1_score: 0.6474 - val_loss: 1.4958 - val_precision: 0.6870 - val_recall: 0.6429\n",
      "Epoch 17/20\n",
      "42/42 - 11s - 252ms/step - NLL: 0.1923 - accuracy: 0.9335 - f1_score: 0.9335 - loss: 0.5367 - precision: 0.9463 - recall: 0.9150 - val_NLL: 1.2239 - val_accuracy: 0.6643 - val_f1_score: 0.6662 - val_loss: 1.4592 - val_precision: 0.7077 - val_recall: 0.6571\n",
      "Epoch 18/20\n",
      "42/42 - 9s - 206ms/step - NLL: 0.1726 - accuracy: 0.9414 - f1_score: 0.9415 - loss: 0.5177 - precision: 0.9537 - recall: 0.9286 - val_NLL: 1.2811 - val_accuracy: 0.7143 - val_f1_score: 0.7056 - val_loss: 1.4102 - val_precision: 0.7578 - val_recall: 0.6929\n",
      "Epoch 19/20\n",
      "42/42 - 11s - 258ms/step - NLL: 0.1728 - accuracy: 0.9398 - f1_score: 0.9398 - loss: 0.5179 - precision: 0.9527 - recall: 0.9248 - val_NLL: 1.2262 - val_accuracy: 0.7000 - val_f1_score: 0.6922 - val_loss: 1.3663 - val_precision: 0.7252 - val_recall: 0.6786\n",
      "Epoch 20/20\n",
      "42/42 - 9s - 216ms/step - NLL: 0.1770 - accuracy: 0.9395 - f1_score: 0.9394 - loss: 0.5204 - precision: 0.9492 - recall: 0.9267 - val_NLL: 1.2085 - val_accuracy: 0.7000 - val_f1_score: 0.6979 - val_loss: 1.4685 - val_precision: 0.7287 - val_recall: 0.6714\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "NLL: 1.00\n",
      "Validation accuracy: 0.74\n",
      "Validation F1Score: 0.73\n",
      "evaluating Fold 18\n",
      "Setting seed to 1625494306\n",
      "Epoch 1/20\n",
      "42/42 - 30s - 714ms/step - NLL: 1.9912 - accuracy: 0.3376 - f1_score: 0.3199 - loss: 2.4438 - precision: 0.6848 - recall: 0.1274 - val_NLL: 1.4940 - val_accuracy: 0.4929 - val_f1_score: 0.4620 - val_loss: 1.9487 - val_precision: 0.8125 - val_recall: 0.1857\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 193ms/step - NLL: 1.1913 - accuracy: 0.6173 - f1_score: 0.6177 - loss: 1.5523 - precision: 0.8041 - recall: 0.4229 - val_NLL: 1.0639 - val_accuracy: 0.6571 - val_f1_score: 0.6401 - val_loss: 1.5680 - val_precision: 0.8378 - val_recall: 0.4429\n",
      "Epoch 3/20\n",
      "42/42 - 10s - 246ms/step - NLL: 0.8705 - accuracy: 0.7293 - f1_score: 0.7294 - loss: 1.2132 - precision: 0.8542 - recall: 0.5902 - val_NLL: 0.8598 - val_accuracy: 0.6929 - val_f1_score: 0.6914 - val_loss: 1.2274 - val_precision: 0.7524 - val_recall: 0.5643\n",
      "Epoch 4/20\n",
      "42/42 - 7s - 162ms/step - NLL: 0.7152 - accuracy: 0.7778 - f1_score: 0.7778 - loss: 1.0485 - precision: 0.8700 - recall: 0.6816 - val_NLL: 0.7045 - val_accuracy: 0.7929 - val_f1_score: 0.7951 - val_loss: 1.0575 - val_precision: 0.8393 - val_recall: 0.6714\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.6136 - accuracy: 0.8060 - f1_score: 0.8062 - loss: 0.9401 - precision: 0.8854 - recall: 0.7289 - val_NLL: 0.6727 - val_accuracy: 0.7643 - val_f1_score: 0.7646 - val_loss: 1.0077 - val_precision: 0.8182 - val_recall: 0.7071\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.5218 - accuracy: 0.8342 - f1_score: 0.8347 - loss: 0.8467 - precision: 0.8934 - recall: 0.7718 - val_NLL: 0.6413 - val_accuracy: 0.7714 - val_f1_score: 0.7626 - val_loss: 1.0406 - val_precision: 0.8067 - val_recall: 0.6857\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.4784 - accuracy: 0.8440 - f1_score: 0.8440 - loss: 0.8014 - precision: 0.8991 - recall: 0.7906 - val_NLL: 0.5951 - val_accuracy: 0.8071 - val_f1_score: 0.8063 - val_loss: 0.9140 - val_precision: 0.8320 - val_recall: 0.7429\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.4688 - accuracy: 0.8492 - f1_score: 0.8493 - loss: 0.7948 - precision: 0.8982 - recall: 0.7929 - val_NLL: 0.5548 - val_accuracy: 0.7929 - val_f1_score: 0.7906 - val_loss: 0.9152 - val_precision: 0.8504 - val_recall: 0.7714\n",
      "Epoch 9/20\n",
      "42/42 - 11s - 252ms/step - NLL: 0.4082 - accuracy: 0.8617 - f1_score: 0.8619 - loss: 0.7364 - precision: 0.9091 - recall: 0.8124 - val_NLL: 0.5853 - val_accuracy: 0.7929 - val_f1_score: 0.7904 - val_loss: 0.8961 - val_precision: 0.8512 - val_recall: 0.7357\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.3768 - accuracy: 0.8726 - f1_score: 0.8725 - loss: 0.7082 - precision: 0.9126 - recall: 0.8323 - val_NLL: 0.5799 - val_accuracy: 0.7714 - val_f1_score: 0.7736 - val_loss: 0.8911 - val_precision: 0.8320 - val_recall: 0.7429\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.3487 - accuracy: 0.8868 - f1_score: 0.8870 - loss: 0.6824 - precision: 0.9210 - recall: 0.8508 - val_NLL: 0.6016 - val_accuracy: 0.7714 - val_f1_score: 0.7642 - val_loss: 0.9499 - val_precision: 0.8268 - val_recall: 0.7500\n",
      "Epoch 12/20\n",
      "42/42 - 9s - 207ms/step - NLL: 0.3087 - accuracy: 0.9004 - f1_score: 0.9003 - loss: 0.6418 - precision: 0.9253 - recall: 0.8613 - val_NLL: 0.6878 - val_accuracy: 0.7714 - val_f1_score: 0.7723 - val_loss: 1.0208 - val_precision: 0.8065 - val_recall: 0.7143\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.2835 - accuracy: 0.9056 - f1_score: 0.9057 - loss: 0.6193 - precision: 0.9314 - recall: 0.8774 - val_NLL: 0.6406 - val_accuracy: 0.7357 - val_f1_score: 0.7309 - val_loss: 0.9465 - val_precision: 0.7760 - val_recall: 0.6929\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.2639 - accuracy: 0.9120 - f1_score: 0.9121 - loss: 0.5985 - precision: 0.9371 - recall: 0.8846 - val_NLL: 0.6062 - val_accuracy: 0.8000 - val_f1_score: 0.7980 - val_loss: 0.9128 - val_precision: 0.8189 - val_recall: 0.7429\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2352 - accuracy: 0.9192 - f1_score: 0.9193 - loss: 0.5686 - precision: 0.9399 - recall: 0.8944 - val_NLL: 0.5629 - val_accuracy: 0.7429 - val_f1_score: 0.7380 - val_loss: 0.8823 - val_precision: 0.7953 - val_recall: 0.7214\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 198ms/step - NLL: 0.2296 - accuracy: 0.9226 - f1_score: 0.9224 - loss: 0.5646 - precision: 0.9412 - recall: 0.9023 - val_NLL: 0.7006 - val_accuracy: 0.7643 - val_f1_score: 0.7650 - val_loss: 0.9791 - val_precision: 0.7969 - val_recall: 0.7286\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.2130 - accuracy: 0.9286 - f1_score: 0.9285 - loss: 0.5471 - precision: 0.9443 - recall: 0.9053 - val_NLL: 0.6201 - val_accuracy: 0.7714 - val_f1_score: 0.7655 - val_loss: 0.9225 - val_precision: 0.8175 - val_recall: 0.7357\n",
      "Epoch 18/20\n",
      "42/42 - 8s - 181ms/step - NLL: 0.1949 - accuracy: 0.9365 - f1_score: 0.9365 - loss: 0.5326 - precision: 0.9522 - recall: 0.9211 - val_NLL: 0.6362 - val_accuracy: 0.7786 - val_f1_score: 0.7737 - val_loss: 0.8778 - val_precision: 0.8140 - val_recall: 0.7500\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "NLL: 0.55\n",
      "Validation accuracy: 0.79\n",
      "Validation F1Score: 0.79\n",
      "evaluating Fold 19\n",
      "Setting seed to 3063573539\n",
      "Epoch 1/20\n",
      "42/42 - 29s - 689ms/step - NLL: 1.8916 - accuracy: 0.4041 - f1_score: 0.3897 - loss: 2.3558 - precision: 0.7705 - recall: 0.1692 - val_NLL: 1.1424 - val_accuracy: 0.7071 - val_f1_score: 0.6772 - val_loss: 1.7743 - val_precision: 0.8816 - val_recall: 0.4786\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 191ms/step - NLL: 1.1025 - accuracy: 0.6538 - f1_score: 0.6510 - loss: 1.4727 - precision: 0.8356 - recall: 0.4680 - val_NLL: 0.7282 - val_accuracy: 0.7714 - val_f1_score: 0.7673 - val_loss: 1.1789 - val_precision: 0.8318 - val_recall: 0.6357\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 188ms/step - NLL: 0.7993 - accuracy: 0.7526 - f1_score: 0.7509 - loss: 1.1492 - precision: 0.8621 - recall: 0.6323 - val_NLL: 0.6350 - val_accuracy: 0.7929 - val_f1_score: 0.7896 - val_loss: 1.0568 - val_precision: 0.8559 - val_recall: 0.7214\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 185ms/step - NLL: 0.6553 - accuracy: 0.7865 - f1_score: 0.7857 - loss: 0.9951 - precision: 0.8754 - recall: 0.6970 - val_NLL: 0.6264 - val_accuracy: 0.8143 - val_f1_score: 0.8096 - val_loss: 1.1565 - val_precision: 0.8689 - val_recall: 0.7571\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 186ms/step - NLL: 0.5785 - accuracy: 0.8090 - f1_score: 0.8090 - loss: 0.9138 - precision: 0.8824 - recall: 0.7365 - val_NLL: 0.5553 - val_accuracy: 0.8429 - val_f1_score: 0.8433 - val_loss: 0.9760 - val_precision: 0.8710 - val_recall: 0.7714\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 188ms/step - NLL: 0.5102 - accuracy: 0.8316 - f1_score: 0.8313 - loss: 0.8501 - precision: 0.8933 - recall: 0.7647 - val_NLL: 0.6333 - val_accuracy: 0.7929 - val_f1_score: 0.7712 - val_loss: 1.1844 - val_precision: 0.8468 - val_recall: 0.7500\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 184ms/step - NLL: 0.4378 - accuracy: 0.8586 - f1_score: 0.8582 - loss: 0.7822 - precision: 0.9098 - recall: 0.8004 - val_NLL: 0.7745 - val_accuracy: 0.7643 - val_f1_score: 0.7639 - val_loss: 1.2287 - val_precision: 0.8145 - val_recall: 0.7214\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.3923 - accuracy: 0.8677 - f1_score: 0.8673 - loss: 0.7322 - precision: 0.9151 - recall: 0.8263 - val_NLL: 0.7368 - val_accuracy: 0.8000 - val_f1_score: 0.7918 - val_loss: 1.2350 - val_precision: 0.8438 - val_recall: 0.7714\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.3456 - accuracy: 0.8880 - f1_score: 0.8879 - loss: 0.6839 - precision: 0.9216 - recall: 0.8440 - val_NLL: 0.7544 - val_accuracy: 0.8071 - val_f1_score: 0.8002 - val_loss: 1.1888 - val_precision: 0.8106 - val_recall: 0.7643\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.3203 - accuracy: 0.8955 - f1_score: 0.8954 - loss: 0.6571 - precision: 0.9294 - recall: 0.8564 - val_NLL: 0.5308 - val_accuracy: 0.8357 - val_f1_score: 0.8302 - val_loss: 0.9066 - val_precision: 0.8561 - val_recall: 0.8071\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 184ms/step - NLL: 0.2976 - accuracy: 0.8929 - f1_score: 0.8927 - loss: 0.6383 - precision: 0.9219 - recall: 0.8609 - val_NLL: 0.6647 - val_accuracy: 0.7500 - val_f1_score: 0.7400 - val_loss: 1.1704 - val_precision: 0.7923 - val_recall: 0.7357\n",
      "Epoch 12/20\n",
      "42/42 - 7s - 159ms/step - NLL: 0.2568 - accuracy: 0.9135 - f1_score: 0.9137 - loss: 0.5995 - precision: 0.9375 - recall: 0.8850 - val_NLL: 0.6129 - val_accuracy: 0.8286 - val_f1_score: 0.8236 - val_loss: 0.9989 - val_precision: 0.8538 - val_recall: 0.7929\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.2452 - accuracy: 0.9147 - f1_score: 0.9145 - loss: 0.5855 - precision: 0.9338 - recall: 0.8962 - val_NLL: 1.1468 - val_accuracy: 0.7429 - val_f1_score: 0.7399 - val_loss: 1.6586 - val_precision: 0.7615 - val_recall: 0.7071\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.2331 - accuracy: 0.9233 - f1_score: 0.9232 - loss: 0.5775 - precision: 0.9392 - recall: 0.8940 - val_NLL: 0.7471 - val_accuracy: 0.7929 - val_f1_score: 0.7853 - val_loss: 1.1203 - val_precision: 0.8397 - val_recall: 0.7857\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.2263 - accuracy: 0.9267 - f1_score: 0.9266 - loss: 0.5712 - precision: 0.9444 - recall: 0.9011 - val_NLL: 0.7288 - val_accuracy: 0.7857 - val_f1_score: 0.7851 - val_loss: 1.1037 - val_precision: 0.7926 - val_recall: 0.7643\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 193ms/step - NLL: 0.2091 - accuracy: 0.9316 - f1_score: 0.9316 - loss: 0.5600 - precision: 0.9501 - recall: 0.9090 - val_NLL: 0.6515 - val_accuracy: 0.8000 - val_f1_score: 0.7947 - val_loss: 1.2628 - val_precision: 0.8409 - val_recall: 0.7929\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.1729 - accuracy: 0.9414 - f1_score: 0.9415 - loss: 0.5287 - precision: 0.9556 - recall: 0.9301 - val_NLL: 0.7251 - val_accuracy: 0.8214 - val_f1_score: 0.8188 - val_loss: 1.1722 - val_precision: 0.8346 - val_recall: 0.7929\n",
      "Epoch 18/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.1539 - accuracy: 0.9489 - f1_score: 0.9488 - loss: 0.5048 - precision: 0.9632 - recall: 0.9350 - val_NLL: 0.6913 - val_accuracy: 0.8071 - val_f1_score: 0.7964 - val_loss: 1.2582 - val_precision: 0.8358 - val_recall: 0.8000\n",
      "Epoch 19/20\n",
      "42/42 - 8s - 186ms/step - NLL: 0.1598 - accuracy: 0.9459 - f1_score: 0.9459 - loss: 0.5043 - precision: 0.9561 - recall: 0.9335 - val_NLL: 0.6832 - val_accuracy: 0.8000 - val_f1_score: 0.7869 - val_loss: 1.2601 - val_precision: 0.8088 - val_recall: 0.7857\n",
      "Epoch 20/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.1451 - accuracy: 0.9519 - f1_score: 0.9518 - loss: 0.4832 - precision: 0.9568 - recall: 0.9414 - val_NLL: 0.7445 - val_accuracy: 0.7500 - val_f1_score: 0.7379 - val_loss: 1.3361 - val_precision: 0.7687 - val_recall: 0.7357\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "NLL: 0.53\n",
      "Validation accuracy: 0.84\n",
      "Validation F1Score: 0.83\n",
      "evaluating Fold 20\n",
      "Setting seed to 1898784207\n",
      "Epoch 1/20\n",
      "42/42 - 29s - 700ms/step - NLL: 2.0023 - accuracy: 0.3410 - f1_score: 0.3308 - loss: 2.4642 - precision: 0.7082 - recall: 0.1241 - val_NLL: 1.5168 - val_accuracy: 0.5286 - val_f1_score: 0.4873 - val_loss: 2.0463 - val_precision: 0.7895 - val_recall: 0.3214\n",
      "Epoch 2/20\n",
      "42/42 - 8s - 196ms/step - NLL: 1.2789 - accuracy: 0.5744 - f1_score: 0.5728 - loss: 1.6402 - precision: 0.7778 - recall: 0.3737 - val_NLL: 1.2771 - val_accuracy: 0.6000 - val_f1_score: 0.5712 - val_loss: 1.7584 - val_precision: 0.7683 - val_recall: 0.4500\n",
      "Epoch 3/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.8931 - accuracy: 0.7053 - f1_score: 0.7042 - loss: 1.2394 - precision: 0.8351 - recall: 0.5789 - val_NLL: 1.0880 - val_accuracy: 0.7000 - val_f1_score: 0.6642 - val_loss: 1.5465 - val_precision: 0.8039 - val_recall: 0.5857\n",
      "Epoch 4/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.7011 - accuracy: 0.7789 - f1_score: 0.7792 - loss: 1.0478 - precision: 0.8645 - recall: 0.6835 - val_NLL: 1.0383 - val_accuracy: 0.7357 - val_f1_score: 0.7151 - val_loss: 1.4841 - val_precision: 0.7895 - val_recall: 0.6429\n",
      "Epoch 5/20\n",
      "42/42 - 8s - 190ms/step - NLL: 0.5686 - accuracy: 0.8177 - f1_score: 0.8178 - loss: 0.9137 - precision: 0.8814 - recall: 0.7432 - val_NLL: 1.0612 - val_accuracy: 0.7143 - val_f1_score: 0.6864 - val_loss: 1.4639 - val_precision: 0.8087 - val_recall: 0.6643\n",
      "Epoch 6/20\n",
      "42/42 - 8s - 188ms/step - NLL: 0.4860 - accuracy: 0.8496 - f1_score: 0.8496 - loss: 0.8274 - precision: 0.8982 - recall: 0.7865 - val_NLL: 1.0127 - val_accuracy: 0.7500 - val_f1_score: 0.7357 - val_loss: 1.3798 - val_precision: 0.7966 - val_recall: 0.6714\n",
      "Epoch 7/20\n",
      "42/42 - 8s - 194ms/step - NLL: 0.4345 - accuracy: 0.8575 - f1_score: 0.8579 - loss: 0.7760 - precision: 0.9065 - recall: 0.8019 - val_NLL: 0.9593 - val_accuracy: 0.7500 - val_f1_score: 0.7374 - val_loss: 1.3285 - val_precision: 0.8017 - val_recall: 0.6929\n",
      "Epoch 8/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.3987 - accuracy: 0.8662 - f1_score: 0.8659 - loss: 0.7443 - precision: 0.9073 - recall: 0.8282 - val_NLL: 0.9532 - val_accuracy: 0.7429 - val_f1_score: 0.7296 - val_loss: 1.2301 - val_precision: 0.8136 - val_recall: 0.6857\n",
      "Epoch 9/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.3425 - accuracy: 0.8857 - f1_score: 0.8852 - loss: 0.6905 - precision: 0.9215 - recall: 0.8519 - val_NLL: 0.9076 - val_accuracy: 0.7500 - val_f1_score: 0.7377 - val_loss: 1.2378 - val_precision: 0.8226 - val_recall: 0.7286\n",
      "Epoch 10/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.3071 - accuracy: 0.9000 - f1_score: 0.8998 - loss: 0.6591 - precision: 0.9268 - recall: 0.8665 - val_NLL: 1.0433 - val_accuracy: 0.7500 - val_f1_score: 0.7355 - val_loss: 1.3671 - val_precision: 0.7920 - val_recall: 0.7071\n",
      "Epoch 11/20\n",
      "42/42 - 8s - 196ms/step - NLL: 0.2795 - accuracy: 0.9023 - f1_score: 0.9020 - loss: 0.6299 - precision: 0.9268 - recall: 0.8752 - val_NLL: 0.9729 - val_accuracy: 0.7643 - val_f1_score: 0.7528 - val_loss: 1.4237 - val_precision: 0.7752 - val_recall: 0.7143\n",
      "Epoch 12/20\n",
      "42/42 - 8s - 199ms/step - NLL: 0.2535 - accuracy: 0.9128 - f1_score: 0.9124 - loss: 0.6023 - precision: 0.9404 - recall: 0.8842 - val_NLL: 1.0550 - val_accuracy: 0.7500 - val_f1_score: 0.7381 - val_loss: 1.2713 - val_precision: 0.7969 - val_recall: 0.7286\n",
      "Epoch 13/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.2441 - accuracy: 0.9195 - f1_score: 0.9194 - loss: 0.5874 - precision: 0.9390 - recall: 0.8970 - val_NLL: 0.8522 - val_accuracy: 0.7929 - val_f1_score: 0.7833 - val_loss: 1.1005 - val_precision: 0.8168 - val_recall: 0.7643\n",
      "Epoch 14/20\n",
      "42/42 - 8s - 192ms/step - NLL: 0.2170 - accuracy: 0.9259 - f1_score: 0.9257 - loss: 0.5605 - precision: 0.9433 - recall: 0.9064 - val_NLL: 0.9776 - val_accuracy: 0.7714 - val_f1_score: 0.7627 - val_loss: 1.1812 - val_precision: 0.7836 - val_recall: 0.7500\n",
      "Epoch 15/20\n",
      "42/42 - 8s - 191ms/step - NLL: 0.2084 - accuracy: 0.9278 - f1_score: 0.9280 - loss: 0.5525 - precision: 0.9419 - recall: 0.9083 - val_NLL: 1.0080 - val_accuracy: 0.7714 - val_f1_score: 0.7655 - val_loss: 1.2075 - val_precision: 0.8047 - val_recall: 0.7357\n",
      "Epoch 16/20\n",
      "42/42 - 8s - 189ms/step - NLL: 0.2070 - accuracy: 0.9214 - f1_score: 0.9214 - loss: 0.5640 - precision: 0.9367 - recall: 0.9019 - val_NLL: 1.0709 - val_accuracy: 0.7571 - val_f1_score: 0.7511 - val_loss: 1.2326 - val_precision: 0.7721 - val_recall: 0.7500\n",
      "Epoch 17/20\n",
      "42/42 - 8s - 187ms/step - NLL: 0.1763 - accuracy: 0.9372 - f1_score: 0.9372 - loss: 0.5237 - precision: 0.9532 - recall: 0.9188 - val_NLL: 0.9848 - val_accuracy: 0.7643 - val_f1_score: 0.7519 - val_loss: 1.2357 - val_precision: 0.7836 - val_recall: 0.7500\n",
      "Epoch 18/20\n",
      "42/42 - 7s - 159ms/step - NLL: 0.1723 - accuracy: 0.9417 - f1_score: 0.9417 - loss: 0.5202 - precision: 0.9546 - recall: 0.9241 - val_NLL: 1.2860 - val_accuracy: 0.7571 - val_f1_score: 0.7341 - val_loss: 1.3500 - val_precision: 0.7829 - val_recall: 0.7214\n",
      "Epoch 19/20\n",
      "42/42 - 8s - 188ms/step - NLL: 0.1864 - accuracy: 0.9335 - f1_score: 0.9335 - loss: 0.5400 - precision: 0.9469 - recall: 0.9188 - val_NLL: 0.9294 - val_accuracy: 0.7857 - val_f1_score: 0.7755 - val_loss: 1.1633 - val_precision: 0.8060 - val_recall: 0.7714\n",
      "Epoch 20/20\n",
      "42/42 - 8s - 197ms/step - NLL: 0.1869 - accuracy: 0.9338 - f1_score: 0.9337 - loss: 0.5432 - precision: 0.9436 - recall: 0.9188 - val_NLL: 0.9524 - val_accuracy: 0.7786 - val_f1_score: 0.7687 - val_loss: 1.2364 - val_precision: 0.7923 - val_recall: 0.7357\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "NLL: 0.85\n",
      "Validation accuracy: 0.79\n",
      "Validation F1Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "datapath = cwd / '..' / 'Data' / 'DHG2016' / 'owpg_dcnn'\n",
    "\n",
    "results_valid_labels_list = []\n",
    "results_scores_list_valid = []\n",
    "results_scores_list_train = []\n",
    "\n",
    "for seedidx, n_fold in enumerate(folds):\n",
    "    print('evaluating Fold', n_fold)\n",
    "    seed_val = seeds[seedidx]\n",
    "\n",
    "    fold = pickle.load(open((datapath / ('Fold' + str(n_fold) + '.pkl')).resolve(), 'rb'))\n",
    "    Y_train_oh = fold['train']['Y_oh']\n",
    "    Y_valid_oh = fold['valid']['Y_oh']\n",
    "    X_train = fold['train']['X']\n",
    "    X_valid = fold['valid']['X']\n",
    "\n",
    "\n",
    "    like7 = ConvModel(cfg, 'Test', seed = seed_val)\n",
    "    like7.compile_model()\n",
    "\n",
    "    # Train the model\n",
    "    like7.train_model(X_train, Y_train_oh, X_valid, Y_valid_oh)\n",
    "\n",
    "    #check size of Y_oh to see if 14 and 15 class differentiation is necessary\n",
    "    # check numbe rof datasets to see if sucessfully just used one window per gesture\n",
    "    Y_prob_train = like7.model.predict(X_train)\n",
    "    Y_prob_valid = like7.model.predict(X_valid)\n",
    "    Y_score_true = np.max(Y_prob_valid, axis=-1)\n",
    "\n",
    "    Y_hat_train = np.argmax(Y_prob_train, axis=-1) + 1 # +1 ino rder to have the same labels fo rclasses 1-14 as with a 15 class problems\n",
    "    Y_hat_valid = np.argmax(Y_prob_valid, axis=-1) + 1\n",
    "\n",
    "    results_train = like7.model.evaluate(X_train, Y_train_oh, verbose = 0, return_dict=True)\n",
    "    results_valid = like7.model.evaluate(X_valid, Y_valid_oh, verbose = 0, return_dict=True)\n",
    "\n",
    "    print(f'NLL: {results_valid['NLL']:,.2f}')\n",
    "    #print(f'Validation score: {results['loss']:,.2f}')\n",
    "    print(f'Validation accuracy: {results_valid['accuracy']:,.2f}')\n",
    "    print(f'Validation F1Score: {results_valid['f1_score']:,.2f}')\n",
    "\n",
    "    results_valid_labels_list.append(pd.DataFrame({'Fold': n_fold, 'Y': fold['valid']['Y'], 'Y_hat': Y_hat_valid, 'Y_prob': Y_score_true}))\n",
    "    results_scores_list_train.append(pd.DataFrame(results_train, index = [n_fold]))\n",
    "    results_scores_list_valid.append(pd.DataFrame(results_valid, index = [n_fold]))\n",
    "    #results_scores_list.append({'Fold': n_fold, 'Accuracy_train': accuracy_train, 'Accuracy_valid': accuracy_valid, 'F1-Score_train': f1_score_train, 'F1-Score_valid': f1_score_valid, 'NLL_train': nll_train, 'NLL_valid': nll_valid})\n",
    "    \n",
    "results_scores = pd.concat([pd.concat(results_scores_list_train).add_suffix('_train'),pd.concat(results_scores_list_valid).add_suffix('_valid')],axis = 1)\n",
    "results_scores.rename(columns = {'fold_train': 'fold'}, inplace = True)\n",
    "results_valid_labels = pd.concat(results_valid_labels_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_valid_labels.to_pickle(datapath/'results_valid_labels_dcnn.pkl')\n",
    "results_scores.to_pickle(datapath/'results_scores_dcnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data - frames: 93.0% +-  3.3%\n",
      "F1_Score on training data - frames: 92.9% +- 3.3%\n",
      "NLL on training data - frames: 0.23 +- 0.10\n",
      "accuracy on validation data - frames: 78.5% +- 8.0%\n",
      "F1-Score on validation data - frames: 77.6% +- 8.2%\n",
      "NLL on validation data - frames: 0.68 +- 0.31\n"
     ]
    }
   ],
   "source": [
    "mean = results_scores.mean()\n",
    "std = results_scores.std()\n",
    "\n",
    "print(f'accuracy on training data - frames: {mean[\"accuracy_train\"]*100:.1f}% +-  {std[\"accuracy_train\"]*100:.1f}%')\n",
    "print(f'F1_Score on training data - frames: {mean[\"f1_score_train\"]*100:.1f}% +- {std[\"f1_score_train\"]*100:.1f}%')\n",
    "print(f'NLL on training data - frames: {mean[\"NLL_train\"]:.2f} +- {std[\"NLL_train\"]:.2f}')\n",
    "\n",
    "print(f'accuracy on validation data - frames: {mean['accuracy_valid']*100:.1f}% +- {std['accuracy_valid']*100:.1f}%')\n",
    "print(f'F1-Score on validation data - frames: {mean['f1_score_valid']*100:.1f}% +- {std['f1_score_valid']*100:.1f}%')\n",
    "print(f'NLL on validation data - frames: {mean['NLL_valid']:.2f} +- {std['NLL_valid']:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ab hier optionaler Code\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>padding</th>\n",
       "      <th>fold</th>\n",
       "      <th>seed</th>\n",
       "      <th>NLL</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zeros</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1.085798</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.668352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zeros</td>\n",
       "      <td>1</td>\n",
       "      <td>1027</td>\n",
       "      <td>1.104139</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.645547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zeros</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.685636</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.768051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zeros</td>\n",
       "      <td>2</td>\n",
       "      <td>1027</td>\n",
       "      <td>0.750157</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.764804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zeros</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>1.217961</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.633530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zeros</td>\n",
       "      <td>3</td>\n",
       "      <td>1027</td>\n",
       "      <td>1.166725</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.583506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zeros</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.833712</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.757152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zeros</td>\n",
       "      <td>4</td>\n",
       "      <td>1027</td>\n",
       "      <td>0.792932</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.753700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zeros</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>0.914476</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.763380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zeros</td>\n",
       "      <td>5</td>\n",
       "      <td>1027</td>\n",
       "      <td>1.090410</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.719685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zeros</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>1.448356</td>\n",
       "      <td>0.596429</td>\n",
       "      <td>0.580588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>zeros</td>\n",
       "      <td>6</td>\n",
       "      <td>1027</td>\n",
       "      <td>1.539500</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.494385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zeros</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>0.984249</td>\n",
       "      <td>0.646429</td>\n",
       "      <td>0.659175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>zeros</td>\n",
       "      <td>7</td>\n",
       "      <td>1027</td>\n",
       "      <td>1.474559</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.584140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zeros</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>0.852802</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.697123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>zeros</td>\n",
       "      <td>8</td>\n",
       "      <td>1027</td>\n",
       "      <td>1.039811</td>\n",
       "      <td>0.646429</td>\n",
       "      <td>0.648378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   padding  fold  seed       NLL  accuracy  f1_score\n",
       "0    zeros     1    26  1.085798  0.692857  0.668352\n",
       "1    zeros     1  1027  1.104139  0.650000  0.645547\n",
       "2    zeros     2    26  0.685636  0.764286  0.768051\n",
       "3    zeros     2  1027  0.750157  0.764286  0.764804\n",
       "4    zeros     3    26  1.217961  0.642857  0.633530\n",
       "5    zeros     3  1027  1.166725  0.592857  0.583506\n",
       "6    zeros     4    26  0.833712  0.757143  0.757152\n",
       "7    zeros     4  1027  0.792932  0.757143  0.753700\n",
       "8    zeros     5    26  0.914476  0.775000  0.763380\n",
       "9    zeros     5  1027  1.090410  0.725000  0.719685\n",
       "10   zeros     6    26  1.448356  0.596429  0.580588\n",
       "11   zeros     6  1027  1.539500  0.525000  0.494385\n",
       "12   zeros     7    26  0.984249  0.646429  0.659175\n",
       "13   zeros     7  1027  1.474559  0.589286  0.584140\n",
       "14   zeros     8    26  0.852802  0.714286  0.697123\n",
       "15   zeros     8  1027  1.039811  0.646429  0.648378"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDFlong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                  \n",
      "zeros     4.5  2.292545e+08  0.757024  0.784375  0.780361\n",
      "            fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                     \n",
      "zeros    2.44949  5.661250e+08  0.282956  0.088701  0.092379\n"
     ]
    }
   ],
   "source": [
    "# valid padding and 200 outputneurons dilation factor 3\n",
    "print(resultsDFlong.groupby(['padding']).mean())\n",
    "print(resultsDFlong.groupby(['padding']).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                  \n",
      "zeros     4.5  2.292545e+08  0.756668  0.780357  0.778716\n",
      "            fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                     \n",
      "zeros    2.44949  5.661250e+08  0.268416  0.079057  0.081608\n"
     ]
    }
   ],
   "source": [
    "# valid padding and 200 outputneurons\n",
    "print(resultsDFlong.groupby(['padding']).mean())\n",
    "print(resultsDFlong.groupby(['padding']).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                  \n",
      "zeros     4.5  2.292545e+08  0.759772  0.780804  0.778895\n",
      "            fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                     \n",
      "zeros    2.44949  5.661250e+08  0.257969  0.086391  0.089062\n"
     ]
    }
   ],
   "source": [
    "# causal padding and 200 outputneurons\n",
    "print(resultsDFlong.groupby(['padding']).mean())\n",
    "print(resultsDFlong.groupby(['padding']).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                  \n",
      "zeros     4.5  2.292545e+08  0.758842  0.777232  0.775612\n",
      "            fold          seed      NLL  accuracy  f1_score\n",
      "padding                                                    \n",
      "zeros    2.44949  5.661250e+08  0.28643  0.089295  0.092065\n"
     ]
    }
   ],
   "source": [
    "# causal padding\n",
    "print(resultsDFlong.groupby(['padding']).mean())\n",
    "print(resultsDFlong.groupby(['padding']).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                  \n",
      "zeros     4.5  2.292545e+08  0.722857  0.787946  0.785496\n",
      "            fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                     \n",
      "zeros    2.44949  5.661250e+08  0.287925  0.094355  0.101989\n"
     ]
    }
   ],
   "source": [
    "print(resultsDFlong.groupby(['padding']).mean())\n",
    "print(resultsDFlong.groupby(['padding']).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         fold          seed      NLL  accuracy  f1_score\n",
      "padding                                                 \n",
      "zeros     4.5  2.292545e+08  0.75984  0.775893  0.772963\n",
      "            fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                     \n",
      "zeros    2.44949  5.661250e+08  0.304002  0.085836  0.089565\n"
     ]
    }
   ],
   "source": [
    "# 100 neuronen im klassifikator\n",
    "print(resultsDFlong.groupby(['padding']).mean())\n",
    "print(resultsDFlong.groupby(['padding']).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                  \n",
      "zeros     4.5  2.292545e+08  0.756668  0.780357  0.778716\n",
      "            fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                     \n",
      "zeros    2.44949  5.661250e+08  0.268416  0.079057  0.081608\n"
     ]
    }
   ],
   "source": [
    "# nur 1 maxpooling layer\n",
    "\n",
    "print(resultsDFlong.groupby(['padding']).mean())\n",
    "print(resultsDFlong.groupby(['padding']).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                  \n",
      "zeros     4.5  2.292545e+08  0.707225  0.801339   0.79808\n",
      "            fold          seed       NLL  accuracy  f1_score\n",
      "padding                                                     \n",
      "zeros    2.44949  5.661250e+08  0.287982  0.085798   0.08959\n"
     ]
    }
   ],
   "source": [
    "print(resultsDFlong.groupby(['padding']).mean())\n",
    "print(resultsDFlong.groupby(['padding']).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              fold       NLL  accuracy  f1_score\n",
      "padding seed                                    \n",
      "zeros   26     4.5  0.763702  0.784375  0.782688\n",
      "        1027   4.5  0.726717  0.788839  0.787662\n",
      "                 fold       NLL  accuracy  f1_score\n",
      "padding seed                                       \n",
      "zeros   26    2.44949  0.317027  0.086243  0.087903\n",
      "        1027  2.44949  0.254232  0.065282  0.065067\n"
     ]
    }
   ],
   "source": [
    "# firstframe reference\n",
    "print(resultsDFlong.groupby(['padding', 'seed']).mean())\n",
    "print(resultsDFlong.groupby(['padding', 'seed']).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              fold       NLL  accuracy  f1_score\n",
      "padding seed                                    \n",
      "zeros   26     4.5  1.082803  0.692857  0.685068\n",
      "        1027   4.5  1.196937  0.658036  0.654548\n",
      "                 fold       NLL  accuracy  f1_score\n",
      "padding seed                                       \n",
      "zeros   26    2.44949  0.293481  0.073615  0.073758\n",
      "        1027  2.44949  0.258127  0.070239  0.068022\n"
     ]
    }
   ],
   "source": [
    "# witohout quaternion standardization\n",
    "\n",
    "print(resultsDFlong.groupby(['padding', 'seed']).mean())\n",
    "print(resultsDFlong.groupby(['padding', 'seed']).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              fold       NLL  accuracy  f1_score\n",
      "padding seed                                    \n",
      "zeros   26     4.5  1.002874  0.698661  0.690919\n",
      "        1027   4.5  1.119779  0.656250  0.649268\n",
      "                 fold       NLL  accuracy  f1_score\n",
      "padding seed                                       \n",
      "zeros   26    2.44949  0.242467  0.065603  0.068252\n",
      "        1027  2.44949  0.281625  0.086555  0.093948\n"
     ]
    }
   ],
   "source": [
    "# standardize quaternion as well\n",
    "\n",
    "print(resultsDFlong.groupby(['padding', 'seed']).mean())\n",
    "print(resultsDFlong.groupby(['padding', 'seed']).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%version_information tensorflow, numpy, matplotlib, plotly, pandas, keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gestclass2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
